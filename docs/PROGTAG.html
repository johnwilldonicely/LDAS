
<!DOCTYPE html>
<html>
<head>
<style>
h2,h3, h4, h5, h6{  margin-top:20px;  margin-bottom:0px; }
table, th, td { pading: 5px; border: 5px solid white; border-collapse: collapse; background-color:#dddddd; vertical-align: top; }
</style>
</head>


<body>
<font face="helvetica">
<hr id="TOP">
<h1 align="center"><font color="SteelBlue">LDAS Components</font></h1>

This guide is generated by the <a href="#code-xs-progtag"><b><font color="Black">xs-progtag</font></b></a> tool, which makes use of the
&#60<b>TAGS</b>&#62 label in the LDAS source code. Tags in the code
indicate the categories the code belongs to - for example statistics, or
plotting. These categories are entered when the code is created, and are
subject to change.
<br><br>
The rest of this guide is divided into three sections:
<ul style="list-style-type:disc">
<li><b><a href="#CATEGORIES">CATEGORIES</a></b></li>
<li><b><a href="#CODE-LINKS">CATEGORICAL CODE-LINKS</a></b></li>
<li><b><a href="#CODE">CODE</a></b></li>
</ul>


<br><br>
<hr id="CATEGORIES">
<h2><font color="SteelBlue"><a href="#TOP">&#8679</a> CATEGORIES</font></h2>

<br>
LDAS uses tags to help you find code to perform particular tasks. A given script, program or function may have multiple tags, as they may have overlapping functions. This is a list of every category-tag found in the LDAS code:
<br><br>

<a href="#tag-behaviour">behaviour</a> 
<a href="#tag-database">database</a> 
<a href="#tag-detect">detect</a> 
<a href="#tag-electrophysiology">electrophysiology</a> 
<a href="#tag-ethovision">ethovision</a> 
<a href="#tag-file">file</a> 
<a href="#tag-filter">filter</a> 
<a href="#tag-laser">laser</a> 
<a href="#tag-ldas">ldas</a> 
<a href="#tag-math">math</a> 
<a href="#tag-matrix">matrix</a> 
<a href="#tag-MEA">MEA</a> 
<a href="#tag-MED">MED</a> 
<a href="#tag-misc">misc</a> 
<a href="#tag-neuralynx">neuralynx</a> 
<a href="#tag-noise">noise</a> 
<a href="#tag-O2">O2</a> 
<a href="#tag-plot">plot</a> 
<a href="#tag-programming">programming</a> 
<a href="#tag-SCORE">SCORE</a> 
<a href="#tag-screen">screen</a> 
<a href="#tag-signal_processing">signal_processing</a> 
<a href="#tag-slice">slice</a> 
<a href="#tag-SLICE">SLICE</a> 
<a href="#tag-spectra">spectra</a> 
<a href="#tag-spikes">spikes</a> 
<a href="#tag-stats">stats</a> 
<a href="#tag-string">string</a> 
<a href="#tag-synthetic_data">synthetic_data</a> 
<a href="#tag-taini">taini</a> 
<a href="#tag-time">time</a> 
<a href="#tag-transform">transform</a> 

<h3><font color="SteelBlue">files</font></h3>
<blockquote>
<b>database</b>: working with database tables<br>
<b>file</b>: reading and converting files of different formats<br>
<b>matrix</b>: working with 2D matrices of numbers<br>
</blockquote>

<h3><font color="SteelBlue">describe data</font></h3>
<blockquote>
<b>detect</b>: detect events, features, etc. in a signal<br>
<b>math</b>: get descriptive values (cartesian, means, etc.)<br>
<b>stats</b>: calculating summary statistics for data<br>
<b>spectra</b>: FFT-based timeseries analysis (spectral power, coherence, PAC etc)<br>
</blockquote>

<h3><font color="SteelBlue">transform data</font></h3>
<blockquote>
<b>transform</b>: binning, rotating, or other changes to data format<br>
<b>signal_processing</b>: transformation of a series (filter,bin,rectify, etc.)<br>
<b>screen</b>: extract subsets of data<br>
<b>filter</b>: remove components of a signal: filtering, interpolating, de-meaning etc.<br>
<b>time</b>: working with time-series, timestamps, dates, etc<br>
<b>noise</b>: removing noise from data<br>
</blockquote>

<h3><font color="SteelBlue">miscelaneous</font></h3>
<blockquote>
<b>misc</b>:<br>
<b>plot</b>: generate, modify or transform postscript plots<br>
<b>programming</b>: development tools for LDAS<br>
<b>spikes</b>: analysis of discrete events like action-potentials<br>
<b>string</b>: character-string detecting and processing<br>
<b>electrophysiology</b>: relating to neuronal electrical signal processing<br>
<b>synthetic_data</b>: create numbers, datasets, timestamps etc.<br>
</blockquote>

<h3><font color="SteelBlue">platform-specific</font></h3>
<blockquote>
<b>ldas</b>: code assuming an LDAS data structure and folder contents<br>
<b>SLICE</b>: for slice electrophysiology experiments (WinLTP software)<br>
<b>O2</b>: for oxygen-amperometry experiments (CHART software)<br>
<b>MEA</b>: for slice multi-electrode-array electrophysiology (MES software)<br>
<b>taini</b>: Taini wireless transmitter data (TainiLive software)<br>
<b>MED</b>: MED-PC data processing<br>
<b>SCORE</b>: SCORE data processing (CLB files from 3EG)<br>
<b>neuralynx</b>: Neuralynx file processing (.ncs)<br>
</blockquote>


<br><br>
<hr id="CODE-LINKS">
<h2><font color="SteelBlue"><a href="#TOP">&#8679</a> CATEGORICAL CODE-LINKS</font></h2>

<br>
This section provides links to any code containing one or more of the
possible category-tags. The links are organised in one column for each
of scripts, programs, and functions.
<br>

<h3 id="tag-behaviour"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: behaviour</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas2-pathstats2">xe-ldas2-pathstats2</a><br>
<a href="#code-xe-ldas3-escapelatency1">xe-ldas3-escapelatency1</a><br>
<a href="#code-xe-ldas5-readxyd1">xe-ldas5-readxyd1</a><br>
</td></table></tr>
<h3 id="tag-database"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: database</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-batch1">xs-batch1</a><br>
<a href="#code-xs-checkkeys">xs-checkkeys</a><br>
<a href="#code-xs-collate1">xs-collate1</a><br>
<a href="#code-xs-collect1">xs-collect1</a><br>
<a href="#code-xs-dbcheck1">xs-dbcheck1</a><br>
<a href="#code-xs-dbcomp1">xs-dbcomp1</a><br>
<a href="#code-xs-dbmake1">xs-dbmake1</a><br>
<a href="#code-xs-dbmatch1">xs-dbmatch1</a><br>
<a href="#code-xs-dbmatch2">xs-dbmatch2</a><br>
<a href="#code-xs-getgroupnames1">xs-getgroupnames1</a><br>
<a href="#code-xs-getheader">xs-getheader</a><br>
<a href="#code-xs-ldas5-XSERIES1b">xs-ldas5-XSERIES1b</a><br>
<a href="#code-xs-ldas-gettrials1">xs-ldas-gettrials1</a><br>
<a href="#code-xs-ldas-gettrials2">xs-ldas-gettrials2</a><br>
<a href="#code-xs-ldas-updatenotes">xs-ldas-updatenotes</a><br>
<a href="#code-xs-ldas-updatenotes2">xs-ldas-updatenotes2</a><br>
<a href="#code-xs-makelink1">xs-makelink1</a><br>
<a href="#code-xs-plotcollate">xs-plotcollate</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-cut1">xe-cut1</a><br>
<a href="#code-xe-cut2">xe-cut2</a><br>
<a href="#code-xe-dbmatch1">xe-dbmatch1</a><br>
<a href="#code-xe-dbmatch2">xe-dbmatch2</a><br>
<a href="#code-xe-getkey2">xe-getkey2</a><br>
<a href="#code-xe-getkey">xe-getkey</a><br>
<a href="#code-xe-getkeycol">xe-getkeycol</a><br>
<a href="#code-xe-getkeyline1">xe-getkeyline1</a><br>
<a href="#code-xe-getsequence1">xe-getsequence1</a><br>
<a href="#code-xe-keyupdate1">xe-keyupdate1</a><br>
<a href="#code-xe-matchlist">xe-matchlist</a><br>
<a href="#code-xe-matchtimes1">xe-matchtimes1</a><br>
<a href="#code-xe-matchtimes2">xe-matchtimes2</a><br>
<a href="#code-xe-stripcomments">xe-stripcomments</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_getheader1">xf_getheader1</a><br>
<a href="#code-xf_linereadblock1">xf_linereadblock1</a><br>
<a href="#code-xf_strkey1">xf_strkey1</a><br>
</td></table></tr>
<h3 id="tag-detect"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: detect</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-O2-EVENT1">xs-O2-EVENT1</a><br>
<a href="#code-xs-O2-EVENT1b">xs-O2-EVENT1b</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-curveinflect1">xe-curveinflect1</a><br>
<a href="#code-xe-ldas5-packetloss1">xe-ldas5-packetloss1</a><br>
<a href="#code-xe-ldas5-ripdet1">xe-ldas5-ripdet1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_detectcycles2_f">xf_detectcycles2_f</a><br>
<a href="#code-xf_detectevents1_f">xf_detectevents1_f</a><br>
<a href="#code-xf_detectevents2_f">xf_detectevents2_f</a><br>
<a href="#code-xf_detectevents3_lf">xf_detectevents3_lf</a><br>
<a href="#code-xf_detectinflect1_f">xf_detectinflect1_f</a><br>
</td></table></tr>
<h3 id="tag-electrophysiology"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: electrophysiology</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-TAINI-hargreaves0">xs-TAINI-hargreaves0</a><br>
<a href="#code-xs-TAINI-legacy0">xs-TAINI-legacy0</a><br>
<a href="#code-xs-TAINI-legacy1">xs-TAINI-legacy1</a><br>
<a href="#code-xs-TAINI-legacy2">xs-TAINI-legacy2</a><br>
<a href="#code-xs-TAINI-legacy3">xs-TAINI-legacy3</a><br>
<a href="#code-xs-TAINI-preproc1">xs-TAINI-preproc1</a><br>
</td></table></tr>
<h3 id="tag-ethovision"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: ethovision</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas2-makecmt1">xe-ldas2-makecmt1</a><br>
</td></table></tr>
<h3 id="tag-file"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: file</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-dat2bin">xs-dat2bin</a><br>
<a href="#code-xs-ldas-killbadchans1">xs-ldas-killbadchans1</a><br>
<a href="#code-xs-ldas-zipexpt">xs-ldas-zipexpt</a><br>
<a href="#code-xs-makelink1">xs-makelink1</a><br>
<a href="#code-xs-MEA-hdf5">xs-MEA-hdf5</a><br>
<a href="#code-xs-O2-checktxt">xs-O2-checktxt</a><br>
<a href="#code-xs-O2-preproc1">xs-O2-preproc1</a><br>
<a href="#code-xs-rega">xs-rega</a><br>
<a href="#code-xs-rega2">xs-rega2</a><br>
<a href="#code-xs-rename">xs-rename</a><br>
<a href="#code-xs-renamespace">xs-renamespace</a><br>
<a href="#code-xs-strsub">xs-strsub</a><br>
<a href="#code-xs-strsubfile">xs-strsubfile</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-axona2dat">xe-axona2dat</a><br>
<a href="#code-xe-cut2">xe-cut2</a><br>
<a href="#code-xe-dbmatch1">xe-dbmatch1</a><br>
<a href="#code-xe-elp-readscore1">xe-elp-readscore1</a><br>
<a href="#code-xe-filesize1">xe-filesize1</a><br>
<a href="#code-xe-ldas5-interp2">xe-ldas5-interp2</a><br>
<a href="#code-xe-ldas5-readdat1">xe-ldas5-readdat1</a><br>
<a href="#code-xe-ldas5-readdat2">xe-ldas5-readdat2</a><br>
<a href="#code-xe-ldas5-readwave1">xe-ldas5-readwave1</a><br>
<a href="#code-xe-ldas5-readxyd1">xe-ldas5-readxyd1</a><br>
<a href="#code-xe-ldas5-screentxt1">xe-ldas5-screentxt1</a><br>
<a href="#code-xe-ldas5-sliceEPSP">xe-ldas5-sliceEPSP</a><br>
<a href="#code-xe-ldas5-slicePOP">xe-ldas5-slicePOP</a><br>
<a href="#code-xe-ldas-medcmt1">xe-ldas-medcmt1</a><br>
<a href="#code-xe-ldas-readchart1">xe-ldas-readchart1</a><br>
<a href="#code-xe-ldas-txt2clb1">xe-ldas-txt2clb1</a><br>
<a href="#code-xe-nlx2bin">xe-nlx2bin</a><br>
<a href="#code-xe-O2-readchart2">xe-O2-readchart2</a><br>
<a href="#code-xe-O2-readmed1">xe-O2-readmed1</a><br>
<a href="#code-xe-O2-readmed2">xe-O2-readmed2</a><br>
<a href="#code-xe-readbinary1">xe-readbinary1</a><br>
<a href="#code-xe-readbinary2">xe-readbinary2</a><br>
<a href="#code-xe-readbinary3">xe-readbinary3</a><br>
<a href="#code-xe-readscore1">xe-readscore1</a><br>
<a href="#code-xe-readscore2">xe-readscore2</a><br>
<a href="#code-xe-repeated1">xe-repeated1</a><br>
<a href="#code-xe-splitfile1">xe-splitfile1</a><br>
<a href="#code-xe-transpose1">xe-transpose1</a><br>
<a href="#code-xe-transpose2">xe-transpose2</a><br>
<a href="#code-xe-winsplit1">xe-winsplit1</a><br>
<a href="#code-xe-writebinary1">xe-writebinary1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_filesize">xf_filesize</a><br>
<a href="#code-xf_getheader1">xf_getheader1</a><br>
<a href="#code-xf_lineparse1">xf_lineparse1</a><br>
<a href="#code-xf_lineparse2">xf_lineparse2</a><br>
<a href="#code-xf_lineread1">xf_lineread1</a><br>
<a href="#code-xf_linereadblock1">xf_linereadblock1</a><br>
<a href="#code-xf_matrixread1_d">xf_matrixread1_d</a><br>
<a href="#code-xf_matrixread2_d">xf_matrixread2_d</a><br>
<a href="#code-xf_matrixread3_d">xf_matrixread3_d</a><br>
<a href="#code-xf_readbin1_d">xf_readbin1_d</a><br>
<a href="#code-xf_readbin1_f">xf_readbin1_f</a><br>
<a href="#code-xf_readbin1_i">xf_readbin1_i</a><br>
<a href="#code-xf_readbin1_l">xf_readbin1_l</a><br>
<a href="#code-xf_readbin1_s">xf_readbin1_s</a><br>
<a href="#code-xf_readbin1_v">xf_readbin1_v</a><br>
<a href="#code-xf_readbin2_f">xf_readbin2_f</a><br>
<a href="#code-xf_readbin2_i">xf_readbin2_i</a><br>
<a href="#code-xf_readbin2_v">xf_readbin2_v</a><br>
<a href="#code-xf_readbin3_v">xf_readbin3_v</a><br>
<a href="#code-xf_readbinx1">xf_readbinx1</a><br>
<a href="#code-xf_readclub1">xf_readclub1</a><br>
<a href="#code-xf_readnlx_ncs">xf_readnlx_ncs</a><br>
<a href="#code-xf_readscore1">xf_readscore1</a><br>
<a href="#code-xf_readscore_raw1">xf_readscore_raw1</a><br>
<a href="#code-xf_readssp1">xf_readssp1</a><br>
<a href="#code-xf_readwave1_f">xf_readwave1_f</a><br>
<a href="#code-xf_readwinltp1_f">xf_readwinltp1_f</a><br>
<a href="#code-xf_readxyd1">xf_readxyd1</a><br>
<a href="#code-xf_writebin1_v">xf_writebin1_v</a><br>
<a href="#code-xf_writebin2_v">xf_writebin2_v</a><br>
<a href="#code-xf_writebinx1">xf_writebinx1</a><br>
<a href="#code-xf_writewave1_f">xf_writewave1_f</a><br>
</td></table></tr>
<h3 id="tag-filter"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: filter</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-checkisnum2">xe-checkisnum2</a><br>
<a href="#code-xe-demean1">xe-demean1</a><br>
<a href="#code-xe-densitymatrix2">xe-densitymatrix2</a><br>
<a href="#code-xe-detrend1">xe-detrend1</a><br>
<a href="#code-xe-fftfilt1">xe-fftfilt1</a><br>
<a href="#code-xe-filter_butterworth1">xe-filter_butterworth1</a><br>
<a href="#code-xe-filter_clip1">xe-filter_clip1</a><br>
<a href="#code-xe-filter_FIR1">xe-filter_FIR1</a><br>
<a href="#code-xe-filter_notch1">xe-filter_notch1</a><br>
<a href="#code-xe-interp1">xe-interp1</a><br>
<a href="#code-xe-interpspectrum1">xe-interpspectrum1</a><br>
<a href="#code-xe-ldas5-interp2">xe-ldas5-interp2</a><br>
<a href="#code-xe-ldas5-readdat1">xe-ldas5-readdat1</a><br>
<a href="#code-xe-ldas5-readdat2">xe-ldas5-readdat2</a><br>
<a href="#code-xe-ldas5-sliceEPSP">xe-ldas5-sliceEPSP</a><br>
<a href="#code-xe-ldas5-slicePOP">xe-ldas5-slicePOP</a><br>
<a href="#code-xe-ldas5-spectproc1">xe-ldas5-spectproc1</a><br>
<a href="#code-xe-ldas-align1">xe-ldas-align1</a><br>
<a href="#code-xe-ldas-align2">xe-ldas-align2</a><br>
<a href="#code-xe-oversample1">xe-oversample1</a><br>
<a href="#code-xe-smoothbox1">xe-smoothbox1</a><br>
<a href="#code-xe-smoothgauss1">xe-smoothgauss1</a><br>
<a href="#code-xe-trimoutliers1">xe-trimoutliers1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_dejump2_f">xf_dejump2_f</a><br>
<a href="#code-xf_demean1_d">xf_demean1_d</a><br>
<a href="#code-xf_demean1_f">xf_demean1_f</a><br>
<a href="#code-xf_demean1_s">xf_demean1_s</a><br>
<a href="#code-xf_detrend1_d">xf_detrend1_d</a><br>
<a href="#code-xf_detrend1_f">xf_detrend1_f</a><br>
<a href="#code-xf_filter_bworth1_d">xf_filter_bworth1_d</a><br>
<a href="#code-xf_filter_bworth1_f">xf_filter_bworth1_f</a><br>
<a href="#code-xf_filter_bworth2_f">xf_filter_bworth2_f</a><br>
<a href="#code-xf_filter_bworth_matrix1_d">xf_filter_bworth_matrix1_d</a><br>
<a href="#code-xf_filter_clip1_f">xf_filter_clip1_f</a><br>
<a href="#code-xf_filter_FIRapply1_f">xf_filter_FIRapply1_f</a><br>
<a href="#code-xf_filter_FIRapply1_s">xf_filter_FIRapply1_s</a><br>
<a href="#code-xf_filter_FIRapply2_f">xf_filter_FIRapply2_f</a><br>
<a href="#code-xf_filter_FIRcoef1">xf_filter_FIRcoef1</a><br>
<a href="#code-xf_filter_mingood2_f">xf_filter_mingood2_f</a><br>
<a href="#code-xf_filter_mingood2_s">xf_filter_mingood2_s</a><br>
<a href="#code-xf_filter_notch1_f">xf_filter_notch1_f</a><br>
<a href="#code-xf_filter_notch2_f">xf_filter_notch2_f</a><br>
<a href="#code-xf_fishertransform2_d">xf_fishertransform2_d</a><br>
<a href="#code-xf_fishertransformrev2_d">xf_fishertransformrev2_d</a><br>
<a href="#code-xf_interp3_d">xf_interp3_d</a><br>
<a href="#code-xf_interp3_f">xf_interp3_f</a><br>
<a href="#code-xf_interp3max_f">xf_interp3max_f</a><br>
<a href="#code-xf_interp4_d">xf_interp4_d</a><br>
<a href="#code-xf_interp4_f">xf_interp4_f</a><br>
<a href="#code-xf_interp4_s">xf_interp4_s</a><br>
<a href="#code-xf_matrixbin1_d">xf_matrixbin1_d</a><br>
<a href="#code-xf_matrixcontig1_l">xf_matrixcontig1_l</a><br>
<a href="#code-xf_matrixresample1_d">xf_matrixresample1_d</a><br>
<a href="#code-xf_smooth2d_gaussd">xf_smooth2d_gaussd</a><br>
<a href="#code-xf_smoothbox1_d">xf_smoothbox1_d</a><br>
<a href="#code-xf_smoothbox1_f">xf_smoothbox1_f</a><br>
<a href="#code-xf_smoothbox2_d">xf_smoothbox2_d</a><br>
<a href="#code-xf_smoothbox2_f">xf_smoothbox2_f</a><br>
<a href="#code-xf_smoothgauss0_d">xf_smoothgauss0_d</a><br>
<a href="#code-xf_smoothgauss0_f">xf_smoothgauss0_f</a><br>
<a href="#code-xf_smoothgauss1_d">xf_smoothgauss1_d</a><br>
<a href="#code-xf_smoothgauss1_f">xf_smoothgauss1_f</a><br>
<a href="#code-xf_smoothgauss2_d">xf_smoothgauss2_d</a><br>
<a href="#code-xf_smoothgaussd">xf_smoothgaussd</a><br>
<a href="#code-xf_wavefilt1_f">xf_wavefilt1_f</a><br>
</td></table></tr>
<h3 id="tag-laser"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: laser</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-TAINI-laser1">xs-TAINI-laser1</a><br>
</td></table></tr>
<h3 id="tag-ldas"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: ldas</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-dat2bin">xs-dat2bin</a><br>
<a href="#code-xs-getgroupnames1">xs-getgroupnames1</a><br>
<a href="#code-xs-ldas-getchannel">xs-ldas-getchannel</a><br>
<a href="#code-xs-ldas-gettrials1">xs-ldas-gettrials1</a><br>
<a href="#code-xs-ldas-gettrials2">xs-ldas-gettrials2</a><br>
<a href="#code-xs-ldas-killbadchans1">xs-ldas-killbadchans1</a><br>
<a href="#code-xs-ldas-parsename">xs-ldas-parsename</a><br>
<a href="#code-xs-ldas-trials2cmt">xs-ldas-trials2cmt</a><br>
<a href="#code-xs-ldas-updatenotes">xs-ldas-updatenotes</a><br>
<a href="#code-xs-ldas-updatenotes2">xs-ldas-updatenotes2</a><br>
<a href="#code-xs-ldas-XLASER1">xs-ldas-XLASER1</a><br>
<a href="#code-xs-ldas-XLASER1b">xs-ldas-XLASER1b</a><br>
<a href="#code-xs-ldas-zipexpt">xs-ldas-zipexpt</a><br>
<a href="#code-xs-manual">xs-manual</a><br>
<a href="#code-xs-template">xs-template</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas5-clucombine1">xe-ldas5-clucombine1</a><br>
<a href="#code-xe-ldas5-clucombinelist1">xe-ldas5-clucombinelist1</a><br>
<a href="#code-xe-ldas5-clukiller1">xe-ldas5-clukiller1</a><br>
<a href="#code-xe-ldas5-clukillerlist1">xe-ldas5-clukillerlist1</a><br>
<a href="#code-xe-ldas5-clumatch1">xe-ldas5-clumatch1</a><br>
<a href="#code-xe-ldas5-datwavemean1">xe-ldas5-datwavemean1</a><br>
<a href="#code-xe-ldas5-expandclub1">xe-ldas5-expandclub1</a><br>
<a href="#code-xe-ldas5-wavestats1">xe-ldas5-wavestats1</a><br>
<a href="#code-xe-ldas-align1">xe-ldas-align1</a><br>
<a href="#code-xe-ldas-align2">xe-ldas-align2</a><br>
<a href="#code-xe-ldas-invalidcmt1">xe-ldas-invalidcmt1</a><br>
<a href="#code-xe-ldas-medcmt1">xe-ldas-medcmt1</a><br>
<a href="#code-xe-ldas-readchart1">xe-ldas-readchart1</a><br>
<a href="#code-xe-ldas-txt2clb1">xe-ldas-txt2clb1</a><br>
<a href="#code-xe-template">xe-template</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_template">xf_template</a><br>
</td></table></tr>
<h3 id="tag-math"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: math</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-autocor">xs-autocor</a><br>
<a href="#code-xs-dbcomp1">xs-dbcomp1</a><br>
<a href="#code-xs-getmedian1">xs-getmedian1</a><br>
<a href="#code-xs-plotcor2">xs-plotcor2</a><br>
<a href="#code-xs-plotmeans1">xs-plotmeans1</a><br>
<a href="#code-xs-plotmeans2">xs-plotmeans2</a><br>
<a href="#code-xs-plotmeans3">xs-plotmeans3</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-convolve1">xe-convolve1</a><br>
<a href="#code-xe-distvel3">xe-distvel3</a><br>
<a href="#code-xe-getdelta1">xe-getdelta1</a><br>
<a href="#code-xe-getdelta2">xe-getdelta2</a><br>
<a href="#code-xe-getsamplefreq1">xe-getsamplefreq1</a><br>
<a href="#code-xe-ldas5-datwavemean1">xe-ldas5-datwavemean1</a><br>
<a href="#code-xe-math_abs1">xe-math_abs1</a><br>
<a href="#code-xe-math_add1">xe-math_add1</a><br>
<a href="#code-xe-math_div1">xe-math_div1</a><br>
<a href="#code-xe-math_doublet">xe-math_doublet</a><br>
<a href="#code-xe-math_index1">xe-math_index1</a><br>
<a href="#code-xe-math_mult1">xe-math_mult1</a><br>
<a href="#code-xe-math_power1">xe-math_power1</a><br>
<a href="#code-xe-math_round1">xe-math_round1</a><br>
<a href="#code-xe-math_round2">xe-math_round2</a><br>
<a href="#code-xe-math_sum1">xe-math_sum1</a><br>
<a href="#code-xe-matrixavg2">xe-matrixavg2</a><br>
<a href="#code-xe-matrixdiff1">xe-matrixdiff1</a><br>
<a href="#code-xe-matrixsub1">xe-matrixsub1</a><br>
<a href="#code-xe-random1">xe-random1</a><br>
<a href="#code-xe-statscol1">xe-statscol1</a><br>
<a href="#code-xe-statsd1">xe-statsd1</a><br>
<a href="#code-xe-statsgrp0">xe-statsgrp0</a><br>
<a href="#code-xe-statsgrp1">xe-statsgrp1</a><br>
<a href="#code-xe-statsgrp2">xe-statsgrp2</a><br>
<a href="#code-xe-statsgrp3">xe-statsgrp3</a><br>
<a href="#code-xe-statsrow1">xe-statsrow1</a><br>
<a href="#code-xe-test1">xe-test1</a><br>
<a href="#code-xe-transpose4">xe-transpose4</a><br>
<a href="#code-xe-wint1">xe-wint1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_compare1_d">xf_compare1_d</a><br>
<a href="#code-xf_compare1_f">xf_compare1_f</a><br>
<a href="#code-xf_compare1_l">xf_compare1_l</a><br>
<a href="#code-xf_conv1_f">xf_conv1_f</a><br>
<a href="#code-xf_conv2_f">xf_conv2_f</a><br>
<a href="#code-xf_geom_angle1_f">xf_geom_angle1_f</a><br>
<a href="#code-xf_geom_dist1">xf_geom_dist1</a><br>
<a href="#code-xf_geom_distangle">xf_geom_distangle</a><br>
<a href="#code-xf_geom_linear1_f">xf_geom_linear1_f</a><br>
<a href="#code-xf_geom_offset1_d">xf_geom_offset1_d</a><br>
<a href="#code-xf_geom_offset1_f">xf_geom_offset1_f</a><br>
<a href="#code-xf_geom_slope2_f">xf_geom_slope2_f</a><br>
<a href="#code-xf_getindex1_d">xf_getindex1_d</a><br>
<a href="#code-xf_jitter1_d">xf_jitter1_d</a><br>
<a href="#code-xf_mae1_f">xf_mae1_f</a><br>
<a href="#code-xf_matrixavg1_d">xf_matrixavg1_d</a><br>
<a href="#code-xf_matrixavg1_f">xf_matrixavg1_f</a><br>
<a href="#code-xf_precision_c">xf_precision_c</a><br>
<a href="#code-xf_precision_d">xf_precision_d</a><br>
<a href="#code-xf_qsortindex1_f">xf_qsortindex1_f</a><br>
<a href="#code-xf_qsortindex1_l">xf_qsortindex1_l</a><br>
<a href="#code-xf_qsortindex1_s">xf_qsortindex1_s</a><br>
<a href="#code-xf_rms1_d">xf_rms1_d</a><br>
<a href="#code-xf_rms1_f">xf_rms1_f</a><br>
<a href="#code-xf_rms2_d">xf_rms2_d</a><br>
<a href="#code-xf_rms2_f">xf_rms2_f</a><br>
<a href="#code-xf_round1_d">xf_round1_d</a><br>
<a href="#code-xf_round1_f">xf_round1_f</a><br>
<a href="#code-xf_round2_d">xf_round2_d</a><br>
<a href="#code-xf_trimdigits_d">xf_trimdigits_d</a><br>
<a href="#code-xf_unique_d">xf_unique_d</a><br>
<a href="#code-xf_velocity1">xf_velocity1</a><br>
</td></table></tr>
<h3 id="tag-matrix"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: matrix</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-plotmatrixsplit1">xs-plotmatrixsplit1</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-matrixavg2">xe-matrixavg2</a><br>
<a href="#code-xe-matrixcut1">xe-matrixcut1</a><br>
<a href="#code-xe-matrixcut2">xe-matrixcut2</a><br>
<a href="#code-xe-matrixcut2_inprogress">xe-matrixcut2_inprogress</a><br>
<a href="#code-xe-matrixdiff1">xe-matrixdiff1</a><br>
<a href="#code-xe-matrixmod1">xe-matrixmod1</a><br>
<a href="#code-xe-matrixpeak1">xe-matrixpeak1</a><br>
<a href="#code-xe-matrixsplit1">xe-matrixsplit1</a><br>
<a href="#code-xe-matrixstats1">xe-matrixstats1</a><br>
<a href="#code-xe-matrixsub1">xe-matrixsub1</a><br>
<a href="#code-xe-mxcor2">xe-mxcor2</a><br>
<a href="#code-xe-plotmatrix1">xe-plotmatrix1</a><br>
<a href="#code-xe-spectdenoise1">xe-spectdenoise1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_densitymatrix1_l">xf_densitymatrix1_l</a><br>
<a href="#code-xf_densitymatrix2_l">xf_densitymatrix2_l</a><br>
<a href="#code-xf_filter_bworth_matrix1_d">xf_filter_bworth_matrix1_d</a><br>
<a href="#code-xf_matrixavg1_d">xf_matrixavg1_d</a><br>
<a href="#code-xf_matrixavg1_f">xf_matrixavg1_f</a><br>
<a href="#code-xf_matrixbin1_d">xf_matrixbin1_d</a><br>
<a href="#code-xf_matrixcoh1_d">xf_matrixcoh1_d</a><br>
<a href="#code-xf_matrixcontig1_l">xf_matrixcontig1_l</a><br>
<a href="#code-xf_matrixexpand1_d">xf_matrixexpand1_d</a><br>
<a href="#code-xf_matrixflipx_d">xf_matrixflipx_d</a><br>
<a href="#code-xf_matrixflipy_d">xf_matrixflipy_d</a><br>
<a href="#code-xf_matrixpeak1_d">xf_matrixpeak1_d</a><br>
<a href="#code-xf_matrixread1_d">xf_matrixread1_d</a><br>
<a href="#code-xf_matrixread2_d">xf_matrixread2_d</a><br>
<a href="#code-xf_matrixread3_d">xf_matrixread3_d</a><br>
<a href="#code-xf_matrixresample1_d">xf_matrixresample1_d</a><br>
<a href="#code-xf_matrixrotate1_d">xf_matrixrotate1_d</a><br>
<a href="#code-xf_matrixrotate1_f">xf_matrixrotate1_f</a><br>
<a href="#code-xf_matrixrotate2_d">xf_matrixrotate2_d</a><br>
<a href="#code-xf_matrixtrans1_d">xf_matrixtrans1_d</a><br>
<a href="#code-xf_mullerize_d10">xf_mullerize_d10</a><br>
<a href="#code-xf_placeinfo1_l">xf_placeinfo1_l</a><br>
<a href="#code-xf_placestats1_d">xf_placestats1_d</a><br>
<a href="#code-xf_spectdenoise1_d">xf_spectdenoise1_d</a><br>
</td></table></tr>
<h3 id="tag-MEA"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: MEA</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-MEA-amp1">xs-MEA-amp1</a><br>
<a href="#code-xs-MEA-detect1">xs-MEA-detect1</a><br>
<a href="#code-xs-MEA-detect2">xs-MEA-detect2</a><br>
<a href="#code-xs-MEA-detect2b">xs-MEA-detect2b</a><br>
<a href="#code-xs-MEA-detect3">xs-MEA-detect3</a><br>
<a href="#code-xs-MEA-hdf5">xs-MEA-hdf5</a><br>
<a href="#code-xs-MEA-merge1">xs-MEA-merge1</a><br>
<a href="#code-xs-MEA-plotflip">xs-MEA-plotflip</a><br>
<a href="#code-xs-MEA-pow1">xs-MEA-pow1</a><br>
<a href="#code-xs-MEA-rate1">xs-MEA-rate1</a><br>
<a href="#code-xs-MEA-rate1b">xs-MEA-rate1b</a><br>
<a href="#code-xs-MEA-xcor1">xs-MEA-xcor1</a><br>
</td></table></tr>
<h3 id="tag-MED"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: MED</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas-medcmt1">xe-ldas-medcmt1</a><br>
</td></table></tr>
<h3 id="tag-misc"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: misc</font></h3>
<table><tr>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_pause1">xf_pause1</a><br>
<a href="#code-xf_rollbuffer1_f">xf_rollbuffer1_f</a><br>
</td></table></tr>
<h3 id="tag-neuralynx"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: neuralynx</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-nlx2bin">xe-nlx2bin</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_readnlx_ncs">xf_readnlx_ncs</a><br>
</td></table></tr>
<h3 id="tag-noise"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: noise</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-matrixavg2">xe-matrixavg2</a><br>
<a href="#code-xe-spectdenoise1">xe-spectdenoise1</a><br>
</td></table></tr>
<h3 id="tag-O2"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: O2</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-O2-blockcurve1">xs-O2-blockcurve1</a><br>
<a href="#code-xs-O2-checkchansb">xs-O2-checkchansb</a><br>
<a href="#code-xs-O2-checktxt">xs-O2-checktxt</a><br>
<a href="#code-xs-O2-copycomments">xs-O2-copycomments</a><br>
<a href="#code-xs-O2-COR1">xs-O2-COR1</a><br>
<a href="#code-xs-O2-COR1b">xs-O2-COR1b</a><br>
<a href="#code-xs-O2-COR2b">xs-O2-COR2b</a><br>
<a href="#code-xs-O2-COR4b">xs-O2-COR4b</a><br>
<a href="#code-xs-O2-CORSUMMARIZE1">xs-O2-CORSUMMARIZE1</a><br>
<a href="#code-xs-O2-DIF1b">xs-O2-DIF1b</a><br>
<a href="#code-xs-O2-EVENT1">xs-O2-EVENT1</a><br>
<a href="#code-xs-O2-EVENT1b">xs-O2-EVENT1b</a><br>
<a href="#code-xs-O2-makelink">xs-O2-makelink</a><br>
<a href="#code-xs-O2-makex5b">xs-O2-makex5b</a><br>
<a href="#code-xs-O2-makex6b">xs-O2-makex6b</a><br>
<a href="#code-xs-O2-plot1">xs-O2-plot1</a><br>
<a href="#code-xs-O2-plot1b">xs-O2-plot1b</a><br>
<a href="#code-xs-O2-plotaligned2">xs-O2-plotaligned2</a><br>
<a href="#code-xs-O2-POW1">xs-O2-POW1</a><br>
<a href="#code-xs-O2-POW1b">xs-O2-POW1b</a><br>
<a href="#code-xs-O2-preproc1">xs-O2-preproc1</a><br>
<a href="#code-xs-O2-trimtime1">xs-O2-trimtime1</a><br>
<a href="#code-xs-O2-X1">xs-O2-X1</a><br>
<a href="#code-xs-O2-X1b">xs-O2-X1b</a><br>
<a href="#code-xs-O2-X2b">xs-O2-X2b</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas-readchart1">xe-ldas-readchart1</a><br>
<a href="#code-xe-O2-readchart2">xe-O2-readchart2</a><br>
<a href="#code-xe-O2-readmed1">xe-O2-readmed1</a><br>
<a href="#code-xe-O2-readmed2">xe-O2-readmed2</a><br>
</td></table></tr>
<h3 id="tag-plot"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: plot</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-ldas5-plotdata1">xs-ldas5-plotdata1</a><br>
<a href="#code-xs-ldas5-plothist1">xs-ldas5-plothist1</a><br>
<a href="#code-xs-ldas5-plothistwave1">xs-ldas5-plothistwave1</a><br>
<a href="#code-xs-ldas5-plotplace1">xs-ldas5-plotplace1</a><br>
<a href="#code-xs-ldas5-plotthetadelta1">xs-ldas5-plotthetadelta1</a><br>
<a href="#code-xs-ldas5-plotwave1">xs-ldas5-plotwave1</a><br>
<a href="#code-xs-MEA-plotflip">xs-MEA-plotflip</a><br>
<a href="#code-xs-O2-plot1">xs-O2-plot1</a><br>
<a href="#code-xs-O2-plot1b">xs-O2-plot1b</a><br>
<a href="#code-xs-O2-plotaligned2">xs-O2-plotaligned2</a><br>
<a href="#code-xs-plotbydate">xs-plotbydate</a><br>
<a href="#code-xs-plotcollate">xs-plotcollate</a><br>
<a href="#code-xs-plotcolours">xs-plotcolours</a><br>
<a href="#code-xs-plotconvert1">xs-plotconvert1</a><br>
<a href="#code-xs-plotcor2">xs-plotcor2</a><br>
<a href="#code-xs-plotmatrixsplit1">xs-plotmatrixsplit1</a><br>
<a href="#code-xs-plotmeans1">xs-plotmeans1</a><br>
<a href="#code-xs-plotmeans2">xs-plotmeans2</a><br>
<a href="#code-xs-plotmeans3">xs-plotmeans3</a><br>
<a href="#code-xs-plotmod1">xs-plotmod1</a><br>
<a href="#code-xs-plotmodlegend">xs-plotmodlegend</a><br>
<a href="#code-xs-plotmodtics">xs-plotmodtics</a><br>
<a href="#code-xs-plotmulti">xs-plotmulti</a><br>
<a href="#code-xs-plotsignal">xs-plotsignal</a><br>
<a href="#code-xs-plotsubgrptime">xs-plotsubgrptime</a><br>
<a href="#code-xs-rega">xs-rega</a><br>
<a href="#code-xs-rega2">xs-rega2</a><br>
<a href="#code-xs-TAINI-tools">xs-TAINI-tools</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-plotmatrix1">xe-plotmatrix1</a><br>
<a href="#code-xe-plotmerge1">xe-plotmerge1</a><br>
<a href="#code-xe-plotmerge2">xe-plotmerge2</a><br>
<a href="#code-xe-plottable1">xe-plottable1</a><br>
</td></table></tr>
<h3 id="tag-programming"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: programming</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-ldas5-packet2b">xs-ldas5-packet2b</a><br>
<a href="#code-xs-ldas5-XHAR2">xs-ldas5-XHAR2</a><br>
<a href="#code-xs-ldas-trials2cmt">xs-ldas-trials2cmt</a><br>
<a href="#code-xs-manual">xs-manual</a><br>
<a href="#code-xs-paste1">xs-paste1</a><br>
<a href="#code-xs-plotcolours">xs-plotcolours</a><br>
<a href="#code-xs-progbackup2">xs-progbackup2</a><br>
<a href="#code-xs-progclean1">xs-progclean1</a><br>
<a href="#code-xs-progcompile">xs-progcompile</a><br>
<a href="#code-xs-progdep">xs-progdep</a><br>
<a href="#code-xs-progfindcopies">xs-progfindcopies</a><br>
<a href="#code-xs-proggit1">xs-proggit1</a><br>
<a href="#code-xs-progheader1">xs-progheader1</a><br>
<a href="#code-xs-proglicence">xs-proglicence</a><br>
<a href="#code-xs-proglist">xs-proglist</a><br>
<a href="#code-xs-progpath1">xs-progpath1</a><br>
<a href="#code-xs-progpermission">xs-progpermission</a><br>
<a href="#code-xs-progps">xs-progps</a><br>
<a href="#code-xs-progsync1">xs-progsync1</a><br>
<a href="#code-xs-progtag">xs-progtag</a><br>
<a href="#code-xs-template">xs-template</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-progdep">xe-progdep</a><br>
<a href="#code-xe-sizes1">xe-sizes1</a><br>
<a href="#code-xe-template">xe-template</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_err1">xf_err1</a><br>
<a href="#code-xf_template">xf_template</a><br>
</td></table></tr>
<h3 id="tag-SCORE"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: SCORE</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas-txt2clb1">xe-ldas-txt2clb1</a><br>
</td></table></tr>
<h3 id="tag-screen"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: screen</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-cut1">xe-cut1</a><br>
<a href="#code-xe-cut2">xe-cut2</a><br>
<a href="#code-xe-getintervals1">xe-getintervals1</a><br>
<a href="#code-xe-ldas5-screentxt1">xe-ldas5-screentxt1</a><br>
<a href="#code-xe-ldas-invalidcmt1">xe-ldas-invalidcmt1</a><br>
<a href="#code-xe-matchlist">xe-matchlist</a><br>
<a href="#code-xe-matchtimes1">xe-matchtimes1</a><br>
<a href="#code-xe-matchtimes2">xe-matchtimes2</a><br>
<a href="#code-xe-math_index1">xe-math_index1</a><br>
<a href="#code-xe-repeated1">xe-repeated1</a><br>
<a href="#code-xe-splitfile1">xe-splitfile1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_screen_club">xf_screen_club</a><br>
<a href="#code-xf_screen_lf">xf_screen_lf</a><br>
<a href="#code-xf_screen_ls">xf_screen_ls</a><br>
<a href="#code-xf_screen_ssp1">xf_screen_ssp1</a><br>
<a href="#code-xf_screen_ssp2">xf_screen_ssp2</a><br>
<a href="#code-xf_screen_xyd">xf_screen_xyd</a><br>
</td></table></tr>
<h3 id="tag-signal_processing"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: signal_processing</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-autocor">xs-autocor</a><br>
<a href="#code-xs-crunch2">xs-crunch2</a><br>
<a href="#code-xs-ldas-coh1">xs-ldas-coh1</a><br>
<a href="#code-xs-ldas-pow1">xs-ldas-pow1</a><br>
<a href="#code-xs-ldas5-XHAR1">xs-ldas5-XHAR1</a><br>
<a href="#code-xs-ldas5-XHAR1b">xs-ldas5-XHAR1b</a><br>
<a href="#code-xs-ldas-XLASER1">xs-ldas-XLASER1</a><br>
<a href="#code-xs-ldas-XLASER1b">xs-ldas-XLASER1b</a><br>
<a href="#code-xs-noise1">xs-noise1</a><br>
<a href="#code-xs-O2-blockcurve1">xs-O2-blockcurve1</a><br>
<a href="#code-xs-O2-COR1">xs-O2-COR1</a><br>
<a href="#code-xs-O2-COR1b">xs-O2-COR1b</a><br>
<a href="#code-xs-O2-COR2b">xs-O2-COR2b</a><br>
<a href="#code-xs-O2-COR4b">xs-O2-COR4b</a><br>
<a href="#code-xs-O2-CORSUMMARIZE1">xs-O2-CORSUMMARIZE1</a><br>
<a href="#code-xs-O2-DIF1b">xs-O2-DIF1b</a><br>
<a href="#code-xs-O2-EVENT1">xs-O2-EVENT1</a><br>
<a href="#code-xs-O2-EVENT1b">xs-O2-EVENT1b</a><br>
<a href="#code-xs-O2-POW1">xs-O2-POW1</a><br>
<a href="#code-xs-O2-POW1b">xs-O2-POW1b</a><br>
<a href="#code-xs-O2-trimtime1">xs-O2-trimtime1</a><br>
<a href="#code-xs-O2-X1">xs-O2-X1</a><br>
<a href="#code-xs-O2-X1b">xs-O2-X1b</a><br>
<a href="#code-xs-O2-X2b">xs-O2-X2b</a><br>
<a href="#code-xs-plotsignal">xs-plotsignal</a><br>
<a href="#code-xs-thetadelta1">xs-thetadelta1</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-autocor1">xe-autocor1</a><br>
<a href="#code-xe-axona2dat">xe-axona2dat</a><br>
<a href="#code-xe-bin1">xe-bin1</a><br>
<a href="#code-xe-bin2">xe-bin2</a><br>
<a href="#code-xe-cofiring1">xe-cofiring1</a><br>
<a href="#code-xe-convolve1">xe-convolve1</a><br>
<a href="#code-xe-csd1">xe-csd1</a><br>
<a href="#code-xe-curveinflect1">xe-curveinflect1</a><br>
<a href="#code-xe-curvestats1">xe-curvestats1</a><br>
<a href="#code-xe-curvestats2">xe-curvestats2</a><br>
<a href="#code-xe-decimate1">xe-decimate1</a><br>
<a href="#code-xe-demean1">xe-demean1</a><br>
<a href="#code-xe-density1">xe-density1</a><br>
<a href="#code-xe-densitymatrix1">xe-densitymatrix1</a><br>
<a href="#code-xe-detectcycles2">xe-detectcycles2</a><br>
<a href="#code-xe-detectevents1">xe-detectevents1</a><br>
<a href="#code-xe-detectnoise1">xe-detectnoise1</a><br>
<a href="#code-xe-detectsync1">xe-detectsync1</a><br>
<a href="#code-xe-detrend1">xe-detrend1</a><br>
<a href="#code-xe-distvel3">xe-distvel3</a><br>
<a href="#code-xe-elp-readscore1">xe-elp-readscore1</a><br>
<a href="#code-xe-energyvec1">xe-energyvec1</a><br>
<a href="#code-xe-energyvec2">xe-energyvec2</a><br>
<a href="#code-xe-fftcoh3">xe-fftcoh3</a><br>
<a href="#code-xe-fftfilt1">xe-fftfilt1</a><br>
<a href="#code-xe-fftpow1">xe-fftpow1</a><br>
<a href="#code-xe-fftpow2">xe-fftpow2</a><br>
<a href="#code-xe-filter_butterworth1">xe-filter_butterworth1</a><br>
<a href="#code-xe-filter_clip1">xe-filter_clip1</a><br>
<a href="#code-xe-filter_FIR1">xe-filter_FIR1</a><br>
<a href="#code-xe-filter_notch1">xe-filter_notch1</a><br>
<a href="#code-xe-getsamplefreq1">xe-getsamplefreq1</a><br>
<a href="#code-xe-hist1">xe-hist1</a><br>
<a href="#code-xe-interp1">xe-interp1</a><br>
<a href="#code-xe-interpspectrum1">xe-interpspectrum1</a><br>
<a href="#code-xe-ldas2-pathstats2">xe-ldas2-pathstats2</a><br>
<a href="#code-xe-ldas3-escapelatency1">xe-ldas3-escapelatency1</a><br>
<a href="#code-xe-ldas5-interp2">xe-ldas5-interp2</a><br>
<a href="#code-xe-ldas5-packetloss2">xe-ldas5-packetloss2</a><br>
<a href="#code-xe-ldas5-packetloss3">xe-ldas5-packetloss3</a><br>
<a href="#code-xe-ldas5-readdat1">xe-ldas5-readdat1</a><br>
<a href="#code-xe-ldas5-readdat2">xe-ldas5-readdat2</a><br>
<a href="#code-xe-ldas5-ripdet1">xe-ldas5-ripdet1</a><br>
<a href="#code-xe-ldas5-sliceEPSP">xe-ldas5-sliceEPSP</a><br>
<a href="#code-xe-ldas5-slicePOP">xe-ldas5-slicePOP</a><br>
<a href="#code-xe-ldas5-spectproc1">xe-ldas5-spectproc1</a><br>
<a href="#code-xe-ldas-align1">xe-ldas-align1</a><br>
<a href="#code-xe-ldas-align2">xe-ldas-align2</a><br>
<a href="#code-xe-lombscargle1">xe-lombscargle1</a><br>
<a href="#code-xe-matrixmod1">xe-matrixmod1</a><br>
<a href="#code-xe-matrixsplit1">xe-matrixsplit1</a><br>
<a href="#code-xe-mxcor2">xe-mxcor2</a><br>
<a href="#code-xe-oversample1">xe-oversample1</a><br>
<a href="#code-xe-pac2">xe-pac2</a><br>
<a href="#code-xe-pad1">xe-pad1</a><br>
<a href="#code-xe-rms2">xe-rms2</a><br>
<a href="#code-xe-smoothbox1">xe-smoothbox1</a><br>
<a href="#code-xe-smoothgauss1">xe-smoothgauss1</a><br>
<a href="#code-xe-spectdenoise1">xe-spectdenoise1</a><br>
<a href="#code-xe-timestamp1">xe-timestamp1</a><br>
<a href="#code-xe-timestamp2">xe-timestamp2</a><br>
<a href="#code-xe-trimoutliers1">xe-trimoutliers1</a><br>
<a href="#code-xe-winsplit1">xe-winsplit1</a><br>
<a href="#code-xe-wint1">xe-wint1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_bin1a_d">xf_bin1a_d</a><br>
<a href="#code-xf_bin1a_f">xf_bin1a_f</a><br>
<a href="#code-xf_bin1b_d">xf_bin1b_d</a><br>
<a href="#code-xf_bin1b_f">xf_bin1b_f</a><br>
<a href="#code-xf_bin1b_s">xf_bin1b_s</a><br>
<a href="#code-xf_bin2_d">xf_bin2_d</a><br>
<a href="#code-xf_binpeak1_f">xf_binpeak1_f</a><br>
<a href="#code-xf_binpeak4">xf_binpeak4</a><br>
<a href="#code-xf_blockrealign1_ls">xf_blockrealign1_ls</a><br>
<a href="#code-xf_blockrealign2">xf_blockrealign2</a><br>
<a href="#code-xf_conv1_f">xf_conv1_f</a><br>
<a href="#code-xf_conv2_f">xf_conv2_f</a><br>
<a href="#code-xf_decimate_f">xf_decimate_f</a><br>
<a href="#code-xf_decimate_s">xf_decimate_s</a><br>
<a href="#code-xf_dejump2_f">xf_dejump2_f</a><br>
<a href="#code-xf_demean1_d">xf_demean1_d</a><br>
<a href="#code-xf_demean1_f">xf_demean1_f</a><br>
<a href="#code-xf_demean1_s">xf_demean1_s</a><br>
<a href="#code-xf_density1_l">xf_density1_l</a><br>
<a href="#code-xf_density2_l">xf_density2_l</a><br>
<a href="#code-xf_densitymatrix1_l">xf_densitymatrix1_l</a><br>
<a href="#code-xf_densitymatrix2_l">xf_densitymatrix2_l</a><br>
<a href="#code-xf_detectcycles2_f">xf_detectcycles2_f</a><br>
<a href="#code-xf_detectevents1_f">xf_detectevents1_f</a><br>
<a href="#code-xf_detectevents2_f">xf_detectevents2_f</a><br>
<a href="#code-xf_detectevents3_lf">xf_detectevents3_lf</a><br>
<a href="#code-xf_detectinflect1_f">xf_detectinflect1_f</a><br>
<a href="#code-xf_detrend1_d">xf_detrend1_d</a><br>
<a href="#code-xf_detrend1_f">xf_detrend1_f</a><br>
<a href="#code-xf_eventadjust1_f">xf_eventadjust1_f</a><br>
<a href="#code-xf_expand1_d">xf_expand1_d</a><br>
<a href="#code-xf_expand1_f">xf_expand1_f</a><br>
<a href="#code-xf_fillinterp_itime">xf_fillinterp_itime</a><br>
<a href="#code-xf_fillinterp_lf">xf_fillinterp_lf</a><br>
<a href="#code-xf_filter_bworth1_d">xf_filter_bworth1_d</a><br>
<a href="#code-xf_filter_bworth1_f">xf_filter_bworth1_f</a><br>
<a href="#code-xf_filter_bworth2_f">xf_filter_bworth2_f</a><br>
<a href="#code-xf_filter_bworth_matrix1_d">xf_filter_bworth_matrix1_d</a><br>
<a href="#code-xf_filter_clip1_f">xf_filter_clip1_f</a><br>
<a href="#code-xf_filter_FIRapply1_f">xf_filter_FIRapply1_f</a><br>
<a href="#code-xf_filter_FIRapply1_s">xf_filter_FIRapply1_s</a><br>
<a href="#code-xf_filter_FIRapply2_f">xf_filter_FIRapply2_f</a><br>
<a href="#code-xf_filter_FIRcoef1">xf_filter_FIRcoef1</a><br>
<a href="#code-xf_filter_mingood2_f">xf_filter_mingood2_f</a><br>
<a href="#code-xf_filter_mingood2_s">xf_filter_mingood2_s</a><br>
<a href="#code-xf_filter_notch1_f">xf_filter_notch1_f</a><br>
<a href="#code-xf_filter_notch2_f">xf_filter_notch2_f</a><br>
<a href="#code-xf_fishertransform2_d">xf_fishertransform2_d</a><br>
<a href="#code-xf_fishertransformrev2_d">xf_fishertransformrev2_d</a><br>
<a href="#code-xf_histburst1_d">xf_histburst1_d</a><br>
<a href="#code-xf_histratio1_d">xf_histratio1_d</a><br>
<a href="#code-xf_histratio2_d">xf_histratio2_d</a><br>
<a href="#code-xf_histrefract1_d">xf_histrefract1_d</a><br>
<a href="#code-xf_histtheta1d">xf_histtheta1d</a><br>
<a href="#code-xf_interp3_d">xf_interp3_d</a><br>
<a href="#code-xf_interp3_f">xf_interp3_f</a><br>
<a href="#code-xf_interp3max_f">xf_interp3max_f</a><br>
<a href="#code-xf_interp4_d">xf_interp4_d</a><br>
<a href="#code-xf_interp4_f">xf_interp4_f</a><br>
<a href="#code-xf_interp4_s">xf_interp4_s</a><br>
<a href="#code-xf_kissfft1">xf_kissfft1</a><br>
<a href="#code-xf_lombscargle">xf_lombscargle</a><br>
<a href="#code-xf_mae1_f">xf_mae1_f</a><br>
<a href="#code-xf_matchclub1_ls">xf_matchclub1_ls</a><br>
<a href="#code-xf_morletwavelet1_f">xf_morletwavelet1_f</a><br>
<a href="#code-xf_morletwavelet2_f">xf_morletwavelet2_f</a><br>
<a href="#code-xf_mtm_F">xf_mtm_F</a><br>
<a href="#code-xf_mtm_slepian1">xf_mtm_slepian1</a><br>
<a href="#code-xf_mtm_spectavg1">xf_mtm_spectavg1</a><br>
<a href="#code-xf_mullerize_d10">xf_mullerize_d10</a><br>
<a href="#code-xf_padarray0_f">xf_padarray0_f</a><br>
<a href="#code-xf_padarray1_f">xf_padarray1_f</a><br>
<a href="#code-xf_padarray2_f">xf_padarray2_f</a><br>
<a href="#code-xf_padarray3_f">xf_padarray3_f</a><br>
<a href="#code-xf_padarray4_f">xf_padarray4_f</a><br>
<a href="#code-xf_padcos2_f">xf_padcos2_f</a><br>
<a href="#code-xf_power_goertzel1_d">xf_power_goertzel1_d</a><br>
<a href="#code-xf_power_goertzel1_f">xf_power_goertzel1_f</a><br>
<a href="#code-xf_power_goertzel2_d">xf_power_goertzel2_d</a><br>
<a href="#code-xf_power_goertzel2_f">xf_power_goertzel2_f</a><br>
<a href="#code-xf_resample1">xf_resample1</a><br>
<a href="#code-xf_resample1_d">xf_resample1_d</a><br>
<a href="#code-xf_rewindow2_ls">xf_rewindow2_ls</a><br>
<a href="#code-xf_samplefreq1_d">xf_samplefreq1_d</a><br>
<a href="#code-xf_screen_club">xf_screen_club</a><br>
<a href="#code-xf_screen_lf">xf_screen_lf</a><br>
<a href="#code-xf_screen_ls">xf_screen_ls</a><br>
<a href="#code-xf_screen_ssp1">xf_screen_ssp1</a><br>
<a href="#code-xf_screen_ssp2">xf_screen_ssp2</a><br>
<a href="#code-xf_screen_xyd">xf_screen_xyd</a><br>
<a href="#code-xf_smooth2d_gaussd">xf_smooth2d_gaussd</a><br>
<a href="#code-xf_smoothbox1_d">xf_smoothbox1_d</a><br>
<a href="#code-xf_smoothbox1_f">xf_smoothbox1_f</a><br>
<a href="#code-xf_smoothbox2_d">xf_smoothbox2_d</a><br>
<a href="#code-xf_smoothbox2_f">xf_smoothbox2_f</a><br>
<a href="#code-xf_smoothgauss0_d">xf_smoothgauss0_d</a><br>
<a href="#code-xf_smoothgauss0_f">xf_smoothgauss0_f</a><br>
<a href="#code-xf_smoothgauss1_d">xf_smoothgauss1_d</a><br>
<a href="#code-xf_smoothgauss1_f">xf_smoothgauss1_f</a><br>
<a href="#code-xf_smoothgauss2_d">xf_smoothgauss2_d</a><br>
<a href="#code-xf_smoothgaussd">xf_smoothgaussd</a><br>
<a href="#code-xf_spectdenoise1_d">xf_spectdenoise1_d</a><br>
<a href="#code-xf_spline1_d">xf_spline1_d</a><br>
<a href="#code-xf_sspsplit1_l">xf_sspsplit1_l</a><br>
<a href="#code-xf_taperhann_d">xf_taperhann_d</a><br>
<a href="#code-xf_wavecor1_f">xf_wavecor1_f</a><br>
<a href="#code-xf_wavecor2_f">xf_wavecor2_f</a><br>
<a href="#code-xf_wavefilt1_f">xf_wavefilt1_f</a><br>
<a href="#code-xf_wavepeak1_f">xf_wavepeak1_f</a><br>
<a href="#code-xf_wavepeak2_f">xf_wavepeak2_f</a><br>
<a href="#code-xf_wavewidth3_f">xf_wavewidth3_f</a><br>
<a href="#code-xf_window1_l">xf_window1_l</a><br>
<a href="#code-xf_wint1">xf_wint1</a><br>
<a href="#code-xf_wint1_ls">xf_wint1_ls</a><br>
<a href="#code-xf_wint2_di">xf_wint2_di</a><br>
<a href="#code-xf_wint3_ls">xf_wint3_ls</a><br>
</td></table></tr>
<h3 id="tag-slice"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: slice</font></h3>
<table><tr>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_readwinltp1_f">xf_readwinltp1_f</a><br>
</td></table></tr>
<h3 id="tag-SLICE"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: SLICE</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-ldas5-sliceEPSP">xe-ldas5-sliceEPSP</a><br>
<a href="#code-xe-ldas5-slicePOP">xe-ldas5-slicePOP</a><br>
</td></table></tr>
<h3 id="tag-spectra"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: spectra</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-ldas-coh1">xs-ldas-coh1</a><br>
<a href="#code-xs-ldas-pow1">xs-ldas-pow1</a><br>
<a href="#code-xs-ldas5-XHAR1">xs-ldas5-XHAR1</a><br>
<a href="#code-xs-ldas5-XHAR1b">xs-ldas5-XHAR1b</a><br>
<a href="#code-xs-ldas-XLASER1">xs-ldas-XLASER1</a><br>
<a href="#code-xs-ldas-XLASER1b">xs-ldas-XLASER1b</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-fftcoh3">xe-fftcoh3</a><br>
<a href="#code-xe-fftpow1">xe-fftpow1</a><br>
<a href="#code-xe-fftpow2">xe-fftpow2</a><br>
<a href="#code-xe-ldas5-spectproc1">xe-ldas5-spectproc1</a><br>
<a href="#code-xe-spectdenoise1">xe-spectdenoise1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_spectdenoise1_d">xf_spectdenoise1_d</a><br>
</td></table></tr>
<h3 id="tag-spikes"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: spikes</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-cofiring1">xe-cofiring1</a><br>
<a href="#code-xe-ldas5-clucombine1">xe-ldas5-clucombine1</a><br>
<a href="#code-xe-ldas5-clucombinelist1">xe-ldas5-clucombinelist1</a><br>
<a href="#code-xe-ldas5-cluhist1">xe-ldas5-cluhist1</a><br>
<a href="#code-xe-ldas5-clukiller1">xe-ldas5-clukiller1</a><br>
<a href="#code-xe-ldas5-clukillerlist1">xe-ldas5-clukillerlist1</a><br>
<a href="#code-xe-ldas5-clumatch1">xe-ldas5-clumatch1</a><br>
<a href="#code-xe-ldas5-clurate1">xe-ldas5-clurate1</a><br>
<a href="#code-xe-ldas5-clusort1">xe-ldas5-clusort1</a><br>
<a href="#code-xe-ldas5-cofiring1">xe-ldas5-cofiring1</a><br>
<a href="#code-xe-ldas5-datwavemean1">xe-ldas5-datwavemean1</a><br>
<a href="#code-xe-ldas5-expandclub1">xe-ldas5-expandclub1</a><br>
<a href="#code-xe-ldas5-placefields1">xe-ldas5-placefields1</a><br>
<a href="#code-xe-ldas5-placestats1">xe-ldas5-placestats1</a><br>
<a href="#code-xe-ldas5-readclub1">xe-ldas5-readclub1</a><br>
<a href="#code-xe-ldas5-readwave1">xe-ldas5-readwave1</a><br>
<a href="#code-xe-ldas5-wavestats1">xe-ldas5-wavestats1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_screen_club">xf_screen_club</a><br>
</td></table></tr>
<h3 id="tag-stats"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: stats</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-O2-blockcurve1">xs-O2-blockcurve1</a><br>
<a href="#code-xs-O2-CORSUMMARIZE1">xs-O2-CORSUMMARIZE1</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-autocor1">xe-autocor1</a><br>
<a href="#code-xe-bin1">xe-bin1</a><br>
<a href="#code-xe-bin2">xe-bin2</a><br>
<a href="#code-xe-cor1">xe-cor1</a><br>
<a href="#code-xe-cor3">xe-cor3</a><br>
<a href="#code-xe-correlate">xe-correlate</a><br>
<a href="#code-xe-curvestats1">xe-curvestats1</a><br>
<a href="#code-xe-curvestats2">xe-curvestats2</a><br>
<a href="#code-xe-hist1">xe-hist1</a><br>
<a href="#code-xe-histstats1">xe-histstats1</a><br>
<a href="#code-xe-ldas5-wavestats1">xe-ldas5-wavestats1</a><br>
<a href="#code-xe-ldas-align1">xe-ldas-align1</a><br>
<a href="#code-xe-ldas-align2">xe-ldas-align2</a><br>
<a href="#code-xe-lombscargle1">xe-lombscargle1</a><br>
<a href="#code-xe-norm2">xe-norm2</a><br>
<a href="#code-xe-norm3">xe-norm3</a><br>
<a href="#code-xe-normrow2">xe-normrow2</a><br>
<a href="#code-xe-posstats1">xe-posstats1</a><br>
<a href="#code-xe-rms2">xe-rms2</a><br>
<a href="#code-xe-spearmans1">xe-spearmans1</a><br>
<a href="#code-xe-statscol1">xe-statscol1</a><br>
<a href="#code-xe-statsd1">xe-statsd1</a><br>
<a href="#code-xe-statsgrp0">xe-statsgrp0</a><br>
<a href="#code-xe-statsgrp1">xe-statsgrp1</a><br>
<a href="#code-xe-statsgrp2">xe-statsgrp2</a><br>
<a href="#code-xe-statsgrp3">xe-statsgrp3</a><br>
<a href="#code-xe-statsrow1">xe-statsrow1</a><br>
<a href="#code-xe-transpose4">xe-transpose4</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_auc1_d">xf_auc1_d</a><br>
<a href="#code-xf_auc1_f">xf_auc1_f</a><br>
<a href="#code-xf_auc2_d">xf_auc2_d</a><br>
<a href="#code-xf_auc2_f">xf_auc2_f</a><br>
<a href="#code-xf_correlate">xf_correlate</a><br>
<a href="#code-xf_correlate_d">xf_correlate_d</a><br>
<a href="#code-xf_correlate_f">xf_correlate_f</a><br>
<a href="#code-xf_correlate_i">xf_correlate_i</a><br>
<a href="#code-xf_correlate_l">xf_correlate_l</a><br>
<a href="#code-xf_correlate_simple_d">xf_correlate_simple_d</a><br>
<a href="#code-xf_correlate_simple_f">xf_correlate_simple_f</a><br>
<a href="#code-xf_correlate_simple_i">xf_correlate_simple_i</a><br>
<a href="#code-xf_correlate_simple_l">xf_correlate_simple_l</a><br>
<a href="#code-xf_crit_T1">xf_crit_T1</a><br>
<a href="#code-xf_curvestats1_d">xf_curvestats1_d</a><br>
<a href="#code-xf_curvestats2_d">xf_curvestats2_d</a><br>
<a href="#code-xf_curvestats3_f">xf_curvestats3_f</a><br>
<a href="#code-xf_density1_l">xf_density1_l</a><br>
<a href="#code-xf_density2_l">xf_density2_l</a><br>
<a href="#code-xf_densitymatrix1_l">xf_densitymatrix1_l</a><br>
<a href="#code-xf_densitymatrix2_l">xf_densitymatrix2_l</a><br>
<a href="#code-xf_hist1d">xf_hist1d</a><br>
<a href="#code-xf_hist1_l">xf_hist1_l</a><br>
<a href="#code-xf_histburst1_d">xf_histburst1_d</a><br>
<a href="#code-xf_histratio1_d">xf_histratio1_d</a><br>
<a href="#code-xf_histratio2_d">xf_histratio2_d</a><br>
<a href="#code-xf_histrefract1_d">xf_histrefract1_d</a><br>
<a href="#code-xf_histtheta1d">xf_histtheta1d</a><br>
<a href="#code-xf_mae1_f">xf_mae1_f</a><br>
<a href="#code-xf_morletwavelet1_f">xf_morletwavelet1_f</a><br>
<a href="#code-xf_morletwavelet2_f">xf_morletwavelet2_f</a><br>
<a href="#code-xf_mtm_F">xf_mtm_F</a><br>
<a href="#code-xf_mtm_slepian1">xf_mtm_slepian1</a><br>
<a href="#code-xf_mtm_spectavg1">xf_mtm_spectavg1</a><br>
<a href="#code-xf_mullerize_d10">xf_mullerize_d10</a><br>
<a href="#code-xf_norm1_d">xf_norm1_d</a><br>
<a href="#code-xf_norm2_d">xf_norm2_d</a><br>
<a href="#code-xf_norm2_f">xf_norm2_f</a><br>
<a href="#code-xf_norm3_d">xf_norm3_d</a><br>
<a href="#code-xf_percentile1_d">xf_percentile1_d</a><br>
<a href="#code-xf_percentile1_f">xf_percentile1_f</a><br>
<a href="#code-xf_placeinfo1_l">xf_placeinfo1_l</a><br>
<a href="#code-xf_placestats1_d">xf_placestats1_d</a><br>
<a href="#code-xf_power_goertzel1_d">xf_power_goertzel1_d</a><br>
<a href="#code-xf_power_goertzel1_f">xf_power_goertzel1_f</a><br>
<a href="#code-xf_power_goertzel2_d">xf_power_goertzel2_d</a><br>
<a href="#code-xf_power_goertzel2_f">xf_power_goertzel2_f</a><br>
<a href="#code-xf_prob_F">xf_prob_F</a><br>
<a href="#code-xf_prob_T1">xf_prob_T1</a><br>
<a href="#code-xf_rms1_d">xf_rms1_d</a><br>
<a href="#code-xf_rms1_f">xf_rms1_f</a><br>
<a href="#code-xf_rms2_d">xf_rms2_d</a><br>
<a href="#code-xf_rms2_f">xf_rms2_f</a><br>
<a href="#code-xf_spearmans1_f">xf_spearmans1_f</a><br>
<a href="#code-xf_stats1_d">xf_stats1_d</a><br>
<a href="#code-xf_stats2_d">xf_stats2_d</a><br>
<a href="#code-xf_stats2_f">xf_stats2_f</a><br>
<a href="#code-xf_stats3_d">xf_stats3_d</a><br>
<a href="#code-xf_stats3_f">xf_stats3_f</a><br>
<a href="#code-xf_ttest2_d">xf_ttest2_d</a><br>
<a href="#code-xf_ttest3_d">xf_ttest3_d</a><br>
<a href="#code-xf_unique_d">xf_unique_d</a><br>
<a href="#code-xf_wavecor1_f">xf_wavecor1_f</a><br>
<a href="#code-xf_wavecor2_f">xf_wavecor2_f</a><br>
<a href="#code-xf_wavepeak1_f">xf_wavepeak1_f</a><br>
<a href="#code-xf_wavepeak2_f">xf_wavepeak2_f</a><br>
<a href="#code-xf_wavewidth3_f">xf_wavewidth3_f</a><br>
<a href="#code-xf_wint1">xf_wint1</a><br>
<a href="#code-xf_wint1_ls">xf_wint1_ls</a><br>
<a href="#code-xf_wint2_di">xf_wint2_di</a><br>
<a href="#code-xf_wint3_ls">xf_wint3_ls</a><br>
</td></table></tr>
<h3 id="tag-string"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: string</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-checkkeys">xs-checkkeys</a><br>
<a href="#code-xs-ldas-parsename">xs-ldas-parsename</a><br>
<a href="#code-xs-ldas-updatenotes">xs-ldas-updatenotes</a><br>
<a href="#code-xs-ldas-updatenotes2">xs-ldas-updatenotes2</a><br>
<a href="#code-xs-match">xs-match</a><br>
<a href="#code-xs-rename">xs-rename</a><br>
<a href="#code-xs-renamespace">xs-renamespace</a><br>
<a href="#code-xs-strmatch">xs-strmatch</a><br>
<a href="#code-xs-strsub">xs-strsub</a><br>
<a href="#code-xs-strsubfile">xs-strsubfile</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-checkisnum2">xe-checkisnum2</a><br>
<a href="#code-xe-dateconv1">xe-dateconv1</a><br>
<a href="#code-xe-dbmatch1">xe-dbmatch1</a><br>
<a href="#code-xe-delimit">xe-delimit</a><br>
<a href="#code-xe-delimitkiller">xe-delimitkiller</a><br>
<a href="#code-xe-getsequence1">xe-getsequence1</a><br>
<a href="#code-xe-insert1">xe-insert1</a><br>
<a href="#code-xe-makepairs1">xe-makepairs1</a><br>
<a href="#code-xe-strgroup1">xe-strgroup1</a><br>
<a href="#code-xe-stripcomments">xe-stripcomments</a><br>
<a href="#code-xe-strsub1">xe-strsub1</a><br>
<a href="#code-xe-strsub2">xe-strsub2</a><br>
<a href="#code-xe-strxmlparse1">xe-strxmlparse1</a><br>
<a href="#code-xe-timeconv1">xe-timeconv1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_dateconv1">xf_dateconv1</a><br>
<a href="#code-xf_datemod1">xf_datemod1</a><br>
<a href="#code-xf_dateparse1">xf_dateparse1</a><br>
<a href="#code-xf_linecomment1">xf_linecomment1</a><br>
<a href="#code-xf_lineparse1">xf_lineparse1</a><br>
<a href="#code-xf_lineparse2">xf_lineparse2</a><br>
<a href="#code-xf_lineread1">xf_lineread1</a><br>
<a href="#code-xf_parselist1_l">xf_parselist1_l</a><br>
<a href="#code-xf_strcat1">xf_strcat1</a><br>
<a href="#code-xf_strcut1">xf_strcut1</a><br>
<a href="#code-xf_strescape1">xf_strescape1</a><br>
<a href="#code-xf_strkey1">xf_strkey1</a><br>
<a href="#code-xf_strncat1">xf_strncat1</a><br>
<a href="#code-xf_strstr1">xf_strstr1</a><br>
<a href="#code-xf_strsub1">xf_strsub1</a><br>
<a href="#code-xf_strtod1">xf_strtod1</a><br>
</td></table></tr>
<h3 id="tag-synthetic_data"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: synthetic_data</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-makesignal1">xs-makesignal1</a><br>
<a href="#code-xs-makesignal2">xs-makesignal2</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-makedata1">xe-makedata1</a><br>
<a href="#code-xe-makedata2">xe-makedata2</a><br>
<a href="#code-xe-random1">xe-random1</a><br>
<a href="#code-xe-timestamp2">xe-timestamp2</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_rand1_d">xf_rand1_d</a><br>
</td></table></tr>
<h3 id="tag-taini"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: taini</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-ldas5-XHAR1">xs-ldas5-XHAR1</a><br>
<a href="#code-xs-ldas5-XHAR1b">xs-ldas5-XHAR1b</a><br>
<a href="#code-xs-ldas5-XHAR3">xs-ldas5-XHAR3</a><br>
<a href="#code-xs-ldas-XLASER1">xs-ldas-XLASER1</a><br>
<a href="#code-xs-ldas-XLASER1b">xs-ldas-XLASER1b</a><br>
<a href="#code-xs-TAINI-hargreaves0">xs-TAINI-hargreaves0</a><br>
<a href="#code-xs-TAINI-legacy0">xs-TAINI-legacy0</a><br>
<a href="#code-xs-TAINI-legacy1">xs-TAINI-legacy1</a><br>
<a href="#code-xs-TAINI-legacy2">xs-TAINI-legacy2</a><br>
<a href="#code-xs-TAINI-legacy3">xs-TAINI-legacy3</a><br>
<a href="#code-xs-TAINI-preproc1">xs-TAINI-preproc1</a><br>
<a href="#code-xs-TAINI-tools">xs-TAINI-tools</a><br>
</td></table></tr>
<h3 id="tag-time"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: time</font></h3>
<table><tr>
<td><b><font color="Black">Scripts</font></b><br><br>
<a href="#code-xs-ldas-gettrials1">xs-ldas-gettrials1</a><br>
<a href="#code-xs-ldas-gettrials2">xs-ldas-gettrials2</a><br>
<a href="#code-xs-plotbydate">xs-plotbydate</a><br>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-dateconv1">xe-dateconv1</a><br>
<a href="#code-xe-filesize1">xe-filesize1</a><br>
<a href="#code-xe-getintervals1">xe-getintervals1</a><br>
<a href="#code-xe-ldas5-packetloss2">xe-ldas5-packetloss2</a><br>
<a href="#code-xe-ldas5-packetloss3">xe-ldas5-packetloss3</a><br>
<a href="#code-xe-ldas5-readssp1">xe-ldas5-readssp1</a><br>
<a href="#code-xe-ldas5-samp2time1">xe-ldas5-samp2time1</a><br>
<a href="#code-xe-ldas5-screentxt1">xe-ldas5-screentxt1</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_blockrealign1_ls">xf_blockrealign1_ls</a><br>
<a href="#code-xf_blockrealign2">xf_blockrealign2</a><br>
<a href="#code-xf_dateparse1">xf_dateparse1</a><br>
<a href="#code-xf_density1_l">xf_density1_l</a><br>
<a href="#code-xf_density2_l">xf_density2_l</a><br>
<a href="#code-xf_samplefreq1_d">xf_samplefreq1_d</a><br>
<a href="#code-xf_screen_club">xf_screen_club</a><br>
<a href="#code-xf_screen_lf">xf_screen_lf</a><br>
<a href="#code-xf_screen_ls">xf_screen_ls</a><br>
<a href="#code-xf_screen_ssp1">xf_screen_ssp1</a><br>
<a href="#code-xf_screen_ssp2">xf_screen_ssp2</a><br>
<a href="#code-xf_sspsplit1_l">xf_sspsplit1_l</a><br>
<a href="#code-xf_window1_l">xf_window1_l</a><br>
<a href="#code-xf_wint1">xf_wint1</a><br>
<a href="#code-xf_wint1_ls">xf_wint1_ls</a><br>
<a href="#code-xf_wint2_di">xf_wint2_di</a><br>
<a href="#code-xf_wint3_ls">xf_wint3_ls</a><br>
</td></table></tr>
<h3 id="tag-transform"><a href="#CODE-LINKS">&#8679</a><font color="SteelBlue"> CATEGORY: transform</font></h3>
<table><tr>
</td><td><b><font color="Black">Programs</font></b><br><br>
<a href="#code-xe-densitymatrix2">xe-densitymatrix2</a><br>
<a href="#code-xe-ldas5-spectproc1">xe-ldas5-spectproc1</a><br>
<a href="#code-xe-ldas-align1">xe-ldas-align1</a><br>
<a href="#code-xe-ldas-align2">xe-ldas-align2</a><br>
<a href="#code-xe-transpose3">xe-transpose3</a><br>
</td><td><b><font color="Black">Functions</font></b><br><br>
<a href="#code-xf_bin1a_d">xf_bin1a_d</a><br>
<a href="#code-xf_bin1a_f">xf_bin1a_f</a><br>
<a href="#code-xf_bin1b_d">xf_bin1b_d</a><br>
<a href="#code-xf_bin1b_f">xf_bin1b_f</a><br>
<a href="#code-xf_bin1b_s">xf_bin1b_s</a><br>
<a href="#code-xf_bin2_d">xf_bin2_d</a><br>
<a href="#code-xf_binpeak1_f">xf_binpeak1_f</a><br>
<a href="#code-xf_binpeak4">xf_binpeak4</a><br>
<a href="#code-xf_expand1_f">xf_expand1_f</a><br>
<a href="#code-xf_matrixexpand1_d">xf_matrixexpand1_d</a><br>
</td></table></tr>

<br><br>
<hr id="CODE">
<h2><font color="SteelBlue"><a href="#TOP">&#8679</a> CODE</font></h2>

<br>
This section lists the LDAS code in it's entirety, and the category-tags
associated with the code. The entries are not broken down into sections,
but scripts (xs-) come first, then programs (xe-) then functions (xf_).
<br><br>
Each entry is also accompanied by a description. In the case of scripts
and programs, the description comes from the help-output generated when
the script or program is invoked without any arguments. In LDAS, this is
how users access instructions.
<br><br>
Functions are a little different, as they are not executables. Here the
description comes from the comments at the top of the code, beginning
with a section labelled "DESCRIPTION", and ending with the next "*/"
. If these features are not found in the code for the function, nothing
will be printed by way of a description.
<br><br>


<font color="Black"><h3 id="code-xs-autocor"><a href="#CODE">&#8679</a> xs-autocor</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
-----------------------------------------------------------
Create autocorrellogram or cross-corellogram
Calls xe-wint1, xe-hist1, and xe-plottable1
*** NOTE *** ASSUMES SAMPLE RATE IS 20KHz

USAGE: xs-autocor [input] [g1] [g2]
	[input]: .clubt file or ASCII file (col1=time, col2=id)
	[g1]: id of reference event
	[g2]: id of comparator event
		NOTE: If g2=g1, result is an autocorellogram
ADDITIONAL ARGUMENTS:
	-w: window-size [0.1]
	-b: number of bins in histogram [100]
	-s: sample-frequency (.clubt input only) [20000]
	-p: plot output (0=NO 1=YES) [1]
	-P: extra plot options (in quotes) []
Output: 
	data file temp_xs-autocor.txt
	plot file temp_xs-autocor.ps
-----------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-batch1"><a href="#CODE">&#8679</a> xs-batch1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-batch1: run a command in directories specified in a database file 
- command is run in each directory
USAGE: 
	xs-batch1 [db] [com] [options]
		[db]: database file in format &#60path&#62 &#60group&#62
		[com]: command to run
			- should be placed in double-quotes
			- wildcards should function normally
			- if com itself requires quotes, preceed with \ (eg. \")
VALID OPTIONS (defaults in []):
	--xml: specify database XML section containing path & group columns []
	--out: redirect output to this file in each database directory []
		- affects only output normally sent to stdout
		- if command generates a file by default, this is not affected
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-batch1 db_all.txt "echo \"ok\"" --verb 1
 	xs-batch1 db_new.txt "ls *notes" 2&#62&1|tee logfile.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-checkkeys"><a href="#CODE">&#8679</a> xs-checkkeys</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-checkkeys: check that file contains a list of keywords
USAGE: xs-checkkeys [in] [keys] [options]
	[in]: input file
	[keys]: CSV list of keywords to find
		- if keys contain whitespace, use quotes
VALID OPTIONS (defaults in []):
	
EXAMPLE: 
	xs-checkkeys data.notes freq=,"high cut",nchans=,date=
OUTPUT: 
	- no output if all keys are found
	- outputs error messages if keys are missing
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-collate1"><a href="#CODE">&#8679</a> xs-collate1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-collate1: collate files using a database file 
- applies header to first output only
- pads missing values with "-"
	- adds group designation from the database file
	- adds additional designations from the .notes file in each folder
		- must contain keywords subject= or SUBJECT followed by value
USAGE: 
	xs-collate1 [db] [file] [options]
		[db]: database file in format &#60path&#62 &#60group&#62
		[file]: file to collate
VALID OPTIONS (defaults in []):
	--xml: specify database XML section containing path & group columns []
	--pad:  insert lines padded with "-" for missing data (0=NO 1=YES) [0]
	--head: do input files have headers (0=NO 1=YES) [1]
		- if no, output a comment line indicating subject and group
		- if no, padding is not an option
	--dname: file defining date-names  []
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-collate1 db_all.txt data.txt --pad
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-collect1"><a href="#CODE">&#8679</a> xs-collect1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-collect1: collect & rename files using a database file 
- the copied file-names will be appended with the folder-name
USAGE: 
	xs-collect1 [db] [file] [options]
		[db]: database file in format &#60path&#62 &#60group&#62
		[file]: file to collect
VALID OPTIONS (defaults in []):
	--xml: specify database XML section containing path & group columns []
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-collect1 db_all.txt data.txt --verb 1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-crunch2"><a href="#CODE">&#8679</a> xs-crunch2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-crunch2: invocation script for CRUNCH.exe - pre-Lilly
key variables defined by reading the .notes file in the data directory
	data sampling rate
	video sampling rate
	video resolution
	total number of channels
	eeg (theta) channel
- USAGE: xs-crunch2 [basename] [CRUNCH arguments]
- EXAMPLE: xs-crunch2 jh001-091231_01 -maptype 1/opt/LDAS/xs-crunch2: line 26: /opt/LDAS/bin/CRUNCH: No such file or directory
</blockquote></pre>

<font color="Black"><h3 id="code-xs-dat2bin"><a href="#CODE">&#8679</a> xs-dat2bin</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dat2bin: downsample an interlaced .dat file
	- uses xe-ldas5-readdat2 to interpolate, filter(anti-alias), and decimate
	- outputs multiple 1-channel .bin files (binary 32-bit float)
	- basename is everything before the last dot in the input file name
USAGE: xs-dat2bin [infile] [nchans] [srin]
	[infile]: interlaced multi-channel binary file (16-bit short-integer)
	[nchans]: number of channels in infile
	[srin]: sample-rate of infile
VALID OPTIONS (defaults in []):
	--chans: CSV list of channels (from 0) to process []
	--base: basename for output (if unset, infile minus extension) []
	--mean: window size (seconds) for de-meaning data (0=SKIP) [0]
	--srout: output sample-rate (Hz) [1000]
	--bad: invalid value (0,-1, or 1=SHRT_MAX) [1]
	--verb: verbose output (0=NO 1=YES) [1]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-dat2bin 20180101_123456.dat 64 20000
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-dbcheck1"><a href="#CODE">&#8679</a> xs-dbcheck1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dbcheck1: check a database for integrity 
- path defined in column 1 must exist 
- a group must be defined in column 2
- database-file is converted from DOS to UNIX as an initial precaution
USAGE: 
	xs-dbcheck1 [db] [file] [options]
		[db]: database file in format &#60path&#62 &#60group&#62
VALID OPTIONS (defaults in []):
	--xml: specify name of XML section containing path & group columns []
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-dbcheck1 db_all.txt data.txt --verb 1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-dbcomp1"><a href="#CODE">&#8679</a> xs-dbcomp1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dbcomp1: compare matching database tables
	- to quantify changes in columns matching on an ID-column
USAGE: 
	xs-dbcomp1 [table1] [table2] [col]
		table1: first table (baseline)
		table2: second table to measure change in  (response)
		col: name of column to match rows on
ADDITIONAL ARGUMENTS:
	--list: list of variables to analyze (if unset, analyze all) [unset]
	--type: type of comparison (see xe-math_doublet) [2]
		1: add
		2: subtract
		3: multiply
		4: divide
	--stat: summary statistic to use (single value per column) [unset]
		options: MIN,MAX,SUM,MEAN,RANGE,STDDEV,SEM,PERCENTILE_50
	--round: round numbers to the nearest... [0.001]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-dbcomp1 table1.txt table2.txt cluster
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-dbmake1"><a href="#CODE">&#8679</a> xs-dbmake1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dbmake1: Make database of paths to data directories, format= &#60path&#62 &#60group&#62
	- assumes these directories are named according to date and subject
	- database output can use either comments or XML tags to exclude lines
	- a notes file in the directories can be used to specify an experiment-type
USAGE: 
	xs-dbmake1 [basepath]
		[basepath]: path to sub-directories
		 - wildcards can be used to restrict results
		 - if wildcards are used, enclose path in quotes
ADDITIONAL ARGUMENTS and [defaults]:
	--expt: experiment name to find []
		- requires a .notes file in each path defining "experiment="
	--groups: table defining &#60subject&#62 &#60group&#62, all groups=0 if unset []
		-subject name derived from path, default=[date]_[subject]
	--gcol: head for group-column in the above table [group]
	--names: table defining &#60group&#62 &#60name&#62 []
	--pdelim: delimiter for path-name separating date and subject [_]
	--pdate: path-name field specifying the date [1]
	--psub:  path-name field specifying the subject id [2]
	--xml: specify name of XML section to contain path & group columns []
EXAMPLE: 
	xs-dbmake1 ../Data_Library/ --expt REACT --xml PATHS
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-dbmatch1"><a href="#CODE">&#8679</a> xs-dbmatch1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dbmatch1: Extract a column from a file if another column matches a value
- USAGE: xs-dbmatch1 [in] [col1] [match] [col2]
	[in]: file containing data
	[col1]: column containing key to be matched
	[match]: the value which must match [col1]
	[col2]: column containing the required output
ADDITIONAL ARGUMENTS:
	-p: prefilter database for lines beginning with a keyword
		- allows searching files with multiple record types
	-m: match style [default=exact]
		0=exact
		1=contains (case-sensitive)
		2=case-insensitive (exact)
		3=numeric unpadded
EXAMPLE: xs-dbmatch1 database.txt region pfc channel -m 2 
EXAMPLE: xs-dbmatch1 005-999999.notes region hip_ca1pyr channel -m 0 -p CHANNEL
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-dbmatch2"><a href="#CODE">&#8679</a> xs-dbmatch2</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-dbmatch2: if columns match, append lines in file1 with values from file2
	- assumes both files have columns with headers labelling them
	- blank lines and lines beginning with "#" will be output but not appened
USAGE: 
	xs-dbmatch2 [in1] [in2] [col1]
		[in1]: main file - all lines will be output
		[in2]: file providing appended values if key-column matches [in1]
		[col1]: name of the key-column in [in1]
VALID OPTIONS (defaults in []):
	--col2: column in [in2] to match (unset: default is same as [col1]) []
	--out: column in [in2] to output (unset: default is all) []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-dbmatch2 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-getgroupnames1"><a href="#CODE">&#8679</a> xs-getgroupnames1</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-getgroupnames1: extract group-names from an LDAS database (db) file
 - output is in the format &#60group&#62 &#60name&#62
 - there are three potential sources for the group names: 
		1: db-file comments in the format "# group_[no]= [name]"
			[no]= group-number (integer)
			[name]= group-name, with no spaces or tabs
 			example: # group_5= ketamine_3mg/kg
 		2: --names table to use, if db-file doesn't list group names [] 
		3: the db-file group-ids themselves, with the prefix "group_"
USAGE: 
	xs-getgroupnames1 [infile]
		[infile]: a file with group definitions
VALID OPTIONS (defaults in []):
	--names: headered file defining group and name []
	--xml: specify an infile XML section with path & group columns []
	--head: output header? (0=NO 1=YES) [1]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-getgroupnames1 db_all.txt &#62 table_groupnames.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-getheader"><a href="#CODE">&#8679</a> xs-getheader</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-getheader: extract the header-line from a file
- this is the first non-blank, non-commented line
- output will have delimiters converted to tabs by default
USAGE: xs-getheader [infile] [options]
	[infile]: file to extract header from
VALID OPTIONS (defaults in []):
	--delimit: convert all delimiters (comma,space,tab)  [tab]
		- see xe-delimit for options
		- if "no", preserve header, delimiters and all
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-getmedian1"><a href="#CODE">&#8679</a> xs-getmedian1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-getmedian1: calculate the median of a variable for grouped subjects
	- input file must have columns with names specified on the first line
	- sub, grp and var (see below) should all be numeric
USAGE: 
	xs-getmedian1 [in] [sub] [grp] [var]
		[in]: file with headered columns
		[sub]: name of column defining subject id's (integers)
		[grp]: name of column defining group (integers)
		[var]: name of column holding the variable to be analyzed
VALID OPTIONS (defaults in []):
	--plot: plot the mean and data-points (0=NO 1=YES) [0]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-getmedian1 data.txt name dose weight
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-cellstats1"><a href="#CODE">&#8679</a> xs-ldas5-cellstats1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-cellstats1: create a summary table of cell statistics
- .wfm file is used to calculate waveform width and amplitude
- .club(t) file is used to calculate firing rate, refractoriness, burstiness
	NOTE: assumes .clubt file is expanded (referenced to original .dat file)
USAGE: 
	xs-ldas5-cellstats1 [base]
VALID OPTIONS (defaults in []):
	-t | --trials: CSV list of trials to use (or "all") [all]
		NOTE: will not affect waveform amplitude or width
	--class: add cell-classification column (0=NO 1=YES) [0]
		class0= undefined (or rate&#600.05 or width&#621.0)
		class1= pyramidal:   rate &#60 10.0 and width &#62 -burst+.7
		class2= interneuron: rate &#62 10.0 and width &#60 -burst+.7
		NOTE: should only be used when analyzing all
		    : restricting data can reduce classification accuracy
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-cellstats1 20170731-001_000016
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-checktrials"><a href="#CODE">&#8679</a> xs-ldas5-checktrials</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-checktrials: summarize the CRACK-IT sessions and ethovision trials
	- to help determine which EV trials belong in which sessions
	- use this to generate or confirm the table_trialmapping.txt file
	- uses start-times and duration (minutes)
	- will rename Track* and Hardware files to remove spaces
REQUIRES: 
	- CRACK-IT [yyyymmdd]-[ses]_[sbject].datraw files
	- EthoVision tracking files 

USAGE: 
	xs-ldas5-checktrials [subject_ID] or "*"

EXAMPLES: 
	xs-ldas5-checktrials "*"
	xs-ldas5-checktrials 1234567

SAMPLE OUTPUT: 
	Electrophysiology sessions:
	SESS  START	DUR
	000   16:00:55	41.82

	EthoVision Trials for subject 000001:
	TRIAL TIME	DUR	NAME
	1     16:02:36	10.00	FAM1
	2     16:14:56	10.00	CARD1
	3     16:33:22	10.00	SLEEP1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-chunkdat1"><a href="#CODE">&#8679</a> xs-ldas5-chunkdat1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-chunkdat1: Extract chunks from a .dat file
USAGE: 
	xs-ldas5-chunkdat1 [dat] [ssp]
		[dat]: binary multi-channel data file to chunk
		[ssp]: binary start-stop-pair file defining the chunks to keep
			- pairs of sample-numbers stored as long int
			- first sample is the start of a chunk to be extracted
			- second sample is omitted from that chunk
ADDITIONAL ARGUMENTS:
	-n: number of channels [16]
OUTPUT:
	- binary stream with chunks back-to-back
	- invalid values are preserved 
	- binary stream with chunks back-to-back
EXAMPLE: 
	xs-ldas5-chunkdat1 test.dat trials.ssp &#62 new.dat
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-clucombine1"><a href="#CODE">&#8679</a> xs-ldas5-clucombine1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
POST-KLUSTAKWIK COMBINATION  OF CLUSTERS (NOV. 2016)
--------------------------------------------------------------------------------
- assumes KK was run without using time as a feature
- combine clusters based on common refractoriness and waveform correlation
- iterative process with gradually declining criteria
- at each step output is sent to a temporary file
DEPENDENCIES: 
	xe-ldas5-clucombine1
USAGE: xs-ldas5-clucombine1 [clubt] [club] [wfm]
		[clubt]: binary cluster timestamp file
		[club]:  binary cluster ID file
		[wfm]:   ASCII waveform file
ADDITIONAL ARGUMENTS (defaults in []):
	-v | --verb : verbose output [1]
	--base: base-name for output files [temp_xs-ldas5-clucombine1]
	--kwik : specify a .kwik file to update [""]
	--low : low-cut filter to apply to .wfm file [500]
	--high : high-cut filter to apply to .wfm file [500]
		NOTE: filter settings affect the .wfm output
OUTPUT: 
	- 
	- 
	- 
EXAMPLE:
	xs-ldas5-clucombine1 file.clubt file.club file.wfm  -u
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-clukiller1"><a href="#CODE">&#8679</a> xs-ldas5-clukiller1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
Remove noise clusters from club(t) records
- basically, builds bad-cluster list for xe-ldas5-clukillerlist1 
REQUIRES: 
	- .notes, .club, .clubt, and .wfm files
DEPENDENCIES: 
	- xe-ldas5-wavestats1
	- xe-ldas5-cluhist1
	- xe-ldas5-clukillerlist1
USAGE: xs-ldas5-clukiller1 [clubt] [club] [wfm] [options]
	[clubt]: timestamp records
	[club]:  cluster ids
	[wfm]:   waveform file containing mean waveforms
VALID OPTIONS (defaults in []):
	--minspk : minimum total spikes in cluster [1]
	--minhist : minimum spikes in +-50ms autocorrelogram [0]
	-H : strong criterion (max) for refract score [0.08]
	-W : strong criterion (max) for waveform-correlation [0.95]
	-h -w: weak criteria required in combination [0.06] [0.90]
	--kz: kill cluster zero (0=NO 1=YES) [0]
	--base: base-name for output files [temp_xs-ldas5-clukiller1]
	--clean: remove intermediate files (no|yes) [no]
OUTPUT:
	- temp_xs-ldas5-clukiller1.club
	- temp_xs-ldas5-clukiller1.wfm
	- temp_xs-ldas5-clukiller1.txt
EXAMPLE:
	xs-ldas5-clukiller1 20160721-000_2904407.club -u
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-coh1"><a href="#CODE">&#8679</a> xs-ldas-coh1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-coh1: spectral coherence between time-series data
- reads .bin files (single-channel 32-bit float)
- requires a .notes file specifying sample_rate= and a CHANNELS section
- assumes .bin files are present for the matching channel
REQUIRES: a properly formatted .notes file
USAGE: xs-ldas-coh1 [notes] [c1] [c2] [options]
	[notes]: parameter-file
	[c1]: 1st channel number or region-name
	[c2]: 2nd channel number or region-name
GENERAL OPTIONS (defaults in []):
	--trials: CSV list of .notes file trial-names (or "all" or "no") [all]
	--ssp: alternatively, start-stop pairs file (.ssp) defining trials []
	--win: FFT window size (seconds) [1]
	--step: number of steps spanning FFT-window []
	--norm: band timecourse normalization-type - refer to xe-norm2 [-1]
	--bin: bin-size (seconds) for summary [1]
	--plot: generate plots (0=NO,2=YES) [1]
	--dummy: NAN output (0=NO 1=YES, useful for dead channels) [0]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
DATA REALIGNMENT OPTIONS...
	--align: redefine start & stop as one or the other (start|stop) []
		NOTE: if set, use --pre or --post to make non-zero-length trials
	--pre: seconds to add to start [0]
	--post: seconds to add to stop [0]
NORMALIZATION OPTIONS (FOR BAND-OUTPUT)...
	--norm: band timecourse normalization-type - refer to xe-norm2 [-1]
		--n1: norm-start (seconds after start, -1=start) [-1]
		--n2: norm-stop  (seconds after stop,  -1=stop)  [-1]
NOISE-REMOVAL OPTIONS...
	--clip: clipping value (de-noising only,-1=noclip) [-1]
	--nz: Z-score threshold for noise at each freq (NAN to skip) [1.0]
	--ns: sign of thesholding (-1=NEG,+1=POS,0=BOTH) [1]
	--np: % of freq &#62 nz needed to invalidate timepoint [33.333]
HIGH-CUT FILTER OPTIONS...
	--fhi: high-frequency cut (0=NONE) [0.00])
BAND OVERRIDE OPTIONS - specify comma-separated start-stop pairs...
	--delta: [.5,4]
	--alpha: [4,6]
	--theta: [6,12]
	--beta: [12,30]
	--gamma: [30,100]
	--hfo: [120,150]
PLOT OPTIONS...
	--psx: Gaussian smoother, x-axis, units []
	--psy: Gaussian smoother, y-axis (matrix plot only), units []
EXAMPLE: 
	xs-ldas-coh1 *.notes amyg hipp --pre -60  2&#62&1 | tee log_xs-ldas-coh1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-crunch2"><a href="#CODE">&#8679</a> xs-ldas5-crunch2</h3></font>
<blockquote><pre>
------------------------------------------------------------------------------
xs-ldas5-crunch2: invocation script for CRUNCH
key variables defined by reading the .notes file in the data directory
	data sampling rate
	video sampling rate
	video resolution
	total number of channels
	eeg (theta) channel
EXECUTABLE PATH: 
	/opt/LDAS/bin/CRUNCH
USAGE:
	xs-ldas5-crunch2 [basename] [CRUNCH arguments]
EXAMPLE:
	xs-ldas5-crunch2 jh001-091231_01 -maptype 1
/opt/LDAS/xs-ldas5-crunch2: line 28: /opt/LDAS/bin/CRUNCH: No such file or directory
</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-getbase1"><a href="#CODE">&#8679</a> xs-ldas5-getbase1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-getbase1: find the [date]-[session]_[subject] basename for an experiment
- scans multiple .notes files for the experiment= field
- only one .notes file should match the user-defined experiment type
REQUIRES: at least one properly formatted .notes file
USAGE: 
	xs-ldas5-getbase1 [exp]
		[exp]: name of experiment
VALID OPTIONS (defaults in []):
	-q --quiet: suppress error messages
EXAMPLE: 
	xs-ldas5-getbase1 REACT
OUTPUT: yyyymmdd-ses_subject basename, example:
	20170131-001_123456
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-klusta1"><a href="#CODE">&#8679</a> xs-ldas5-klusta1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-klusta1: invoke klusta for spike-detection and clustering
REQUIRES:
	- miniconda klusta environment and klustaviewa/spikedetect2
	- klustakwik-0.3.0
USAGE: 
	xs-ldas5-klusta1 [datfile] [params] [probes]
		[datfile]: multi-channel binary date-session-subject file to process
			- assumed to be interpolated to remove "missing data" holders
			- assumed to chunked to remove unwanted portions of data
		[params]: master paramter file for klustakwik
		[probes]: master probe-mapping file with three columns:
			column #1: probe channel (e.g. 1-16)
			column #2: channel depth (0= most shallow)
			column #3: corresponding channel in the .dat file (0-offset)
ADDITIONAL ARGUMENTS:
	-s: sign for detection (negative or positive) [negative]
	-K: klusta options (in quotes) [--overwrite]: 
		-h, --help      show this help message and exit
		--debug         run the first few seconds of data for debugging
		--overwrite     overwrite the KWIK files if they already exist
		--detect-only   run only SpikeDetekt
		--cluster-only  run only KlustaKwik (after SpikeDetekt has run)
		--convert-only  convert data to Kwik format, no spike detection
		--version       show program's version number and exit
EXAMPLE: 
	xs-ldas5-klusta1 test.dat ~/param.txt ~/probe.txt -s negative -K "--cluster-only"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-klusta2"><a href="#CODE">&#8679</a> xs-ldas5-klusta2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-klusta2: invoke klusta for spike-detection and clustering
	- this version is for klustkwik2
REQUIRES:
	- miniconda klusta2 environment and klustaviewa/spikedetect2
	- klustakwik2-0
USAGE: 
	xs-ldas5-klusta2 [datfile] [params] [probes]
		[datfile]: multi-channel binary date-session-subject file to process
			- assumed to be interpolated to remove "missing data" holders
			- assumed to chunked to remove unwanted portions of data
		[params]: master paramter file for klustakwik
		[probes]: probe-mapping file
			- contains columns headered "chan" "depth" and "good"
			- may be embeded in a file in an xml CHANNELS section
			- typically this is part of a .notes file
ADDITIONAL ARGUMENTS:
	-s: sign for detection (negative or positive) [negative]
	-K: klusta options (in quotes) [--overwrite]: 
		-h, --help      show this help message and exit
		--debug         run the first few seconds of data for debugging
		--overwrite     overwrite the KWIK files if they already exist
		--detect-only   run only SpikeDetekt
		--cluster-only  run only KlustaKwik (after SpikeDetekt has run)
		--convert-only  convert data to Kwik format, no spike detection
		--version       show program's version number and exit
EXAMPLE: 
	xs-ldas5-klusta2 test.dat ~/templates/param.txt *notes -s negative -K "--cluster-only"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-lombscargle1"><a href="#CODE">&#8679</a> xs-ldas5-lombscargle1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-lombscargle1: plot a row of histograms for mulitple clusters
USAGE: 
	xs-ldas5-lombscargle1 [clubt] [club] [options]
		[clubt]: binary cluster timestamp file
		[club]:  binary cluster ID file
VALID OPTIONS:
	--sf: sample frequency for calculating histograms [19531.25] 
	--win: size of window for histogram (ms) [500] 
	--clu: CSV list of clusters to analyze [all] 
	--min: minimum frequency to analyze (-1=AUTO) [] 
	--max: maximum frequency to analyze (-1=AUTO) [] 
	--bands: frequency bands to analyze []
	--plot1: extra options for histogram plot []
	--plot2: extra options for L-S periodogram plot []
	--norm: normalize LS-periodogram (-1=NO, 0=0-1, 1=Zscore) [-1]
	--base: basename for output files [temp_xs-ldas5-lombscargle1]
	--clean: remove temporarty files (0=NO 1=YES) [1]
	--verb: verbose output, 0=NO 1=YES [0]
EXAMPLE: 
	xs-ldas5-lombscargle1 data.clubt data.club --verb 1 --base LOMBS
OUTPUT: 
	- temp_xs-ldas5-lombscargle1.summary
	- temp_xs-ldas5-lombscargle1_[cluster].ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-makeprobemap1"><a href="#CODE">&#8679</a> xs-ldas5-makeprobemap1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-makeprobemap1: make a KlustaKwik probe map from the CHANNELS section in a file
USAGE: 
	xs-ldas-makeprobemap1 [infile]
		[infile]: file with headered channels content
		- required headers: chan (channel), depth and good (0=exclude,1=include)
			- chan  (channel)
			- depth (0=shallow, depth increases with values)
			- good  (0=exclude,1=include)
		- headers must be on the first line or inside a &#60CHANNELS&#62 section
		- example:
			&#60CHANNELS&#62
			chan	prbchan	depth	good	region
			7	16	0	1	x
			10	2	1	1	x
			6	15	2	1	x
			8	1	3	1	x
			13	8	13	1	x
			0	9	14	0	x
			15	7	15	1	x
			&#60/CHANNELS&#62
EXAMPLE: 
	xs-ldas-makeprobemap1 ~/table_probe_16a.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-packet2b"><a href="#CODE">&#8679</a> xs-ldas5-packet2b</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-packet2b: batch-visualise packet-loss based on -lost.ssp files
REQUIRES: a -lost.ssp file in each folder
USAGE: xs-ldas5-packet2b [db] [options]
	[in]: input file, format= &#60time&#62 &#60data&#62
VALID OPTIONS (defaults in []):
	--opts1: quoted options to pass to xe-ldas5-packetloss3 [-win 60 -min 0 ]
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-packet2b db.txt 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plotdata1"><a href="#CODE">&#8679</a> xs-ldas5-plotdata1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plotdata1: plot the traces from .dat or .bin files
USAGE: 
	xs-ldas5-plotdata1 [in] [options]
	[in]: .dat .bin or .notes file
		.dat = binary (short) interlaced 16-channel file
		.bin = binary (float) single-channel files, one per channel
		.notes = file used to define available .bin files to plot

VALID OPTIONS, defaults in []:
...channel selection...
	-c: channels to plot (or "all" or "good") [all]
		- "good" option requires a channel-table (see -t)
	-t: channel-table or .notes file with an XML CHANNELS section []
		- defines depth,goodness and name of each channel
		- if not set, channels are unamed and in order listed
...data properties...
	-f: sample-frequency (Hz) [.dat=19531.25 .bin=1000]
...data alignment...
	-s: align to time (seconds) [.5]
	-a: align to .dat-sample (overrides -s) []
	-w: window size (seconds) [1]
	-m: set alignment to middle of window instead of start (0=NO 1=YES) [1]
...signal processing...
	-o: 50Hz notch filter width (0=none) [.9]
	-l: low-cut filter (0=none) [10]
	-h: high-cut filter (0=none) [250]
	-r: rectify signal (0=n 1=YES) [0]
	-b: boxcar smoothing window (seconds, 0=none) [0]
	-n: normalization as per xe-norm2 (-1=none, 1=z-score) [-1]
	-d: decimate to this number of samples per trace [1000]
...plotting options...
	-S: spacer between individual traces (units) [100]
	-P: plot options (in quotes)) []
...general...
	-v: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-ldas5-plotdata1 20160609-000_2881801.dat -c all -a 177423 -m 1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plothist1"><a href="#CODE">&#8679</a> xs-ldas5-plothist1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plothist1: plot a row of histograms for mulitple clusters
USAGE: 
	xs-ldas5-plothist1 [clubt] [club] [options]
		[clubt]: binary cluster timestamp file
		[club]:  binary cluster ID file
VALID OPTIONS:
	--type: auto- or cross-correlograms [auto] 
	--list: CSV list of clusters to process (or "all") [all] 
	--width: half-width (ms) of the histogram [15] 
	--maxcols: maximum number of histograms on a row (-1 no limit) [-1] 
	--outbase: basename for output files [temp_xs-ldas5-plothist1]
	--clean: remove temporary files (0=NO 1=YES) [1]
	--verb:  flag: verbose output
	--tics: add axis tics & labels (0=NO 1=YES) [0]
	-P: additional plot options, in quotes []
EXAMPLE: 
	xs-ldas5-plothist1 waves.wfm
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plothistwave1"><a href="#CODE">&#8679</a> xs-ldas5-plothistwave1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plothistwave1: plot the xcor-histograms & waveforms for mulitple clusters
USAGE: 
	xs-ldas5-plothistwave1 [clubt] [club] [wfm] [options]
		[clubt]: binary cluster timestamp file
		[club]:  binary cluster ID file
		[wfm]:   ASCII waveform file
VALID OPTIONS:
	-c: comma-separated list of clusters to plot (or "all") [all] 
	-d: depth profile trace-offset (-t 3 only) [150]
	-p: plot histogram (1) waveforms (2) or both (3) [3]
	--outbase: basename for output files [temp_xs-ldas5-plothistwave1]
	--clean: remove temporarty files (0=NO 1=YES) [1]
	--verb:  flag: verbose output
EXAMPLE: 
	xs-ldas5-plothistwave1 waves.wfm
OUTPUT: 
	- [outbase]_summary1.ps: histograms
	- [outbase]_summary2.ps: waveforms
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plotplace1"><a href="#CODE">&#8679</a> xs-ldas5-plotplace1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plotplace1: plot place fields using a multi-matrix file
USAGE: 
	xs-ldas5-plotplace1 [matrixfile]
ADDITIONAL ARGUMENTS:
	-c: comma-separated list of clusters to plot (or all) [all]
	-f: flip maps (0=sno, 1=x-axis, 2=y-axis) [0]
	-s: smooth map (pixels) [0]
	-b: output base filename [ default=temp_xs-ldas5-plotplace1_[trials] ]
	-P: options for xe-plotmatrix1 (in quotes) []
	-M: options for xe-plotmerge1 (in quotes) []
EXAMPLE: 
	xs-ldas5-plotplace1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plotthetadelta1"><a href="#CODE">&#8679</a> xs-ldas5-plotthetadelta1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plotthetadelta1: plot the theta-delta ratio for a trial
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-ldas5-plotthetadelta1 [base] [channel] [options]
VALID OPTIONS, defaults in []:
	-t: trial [1]
	-b: bin-size (sec) for averaging (0= no binning) [1]
	-d: decimation (sec - will override -b if set) []
	-s: Gaussian smoothng half-window size (0=none) [0]
	-P: plot options (in quotes)) []
EXAMPLE: 
	xs-ldas5-plotthetadelta1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-plotwave1"><a href="#CODE">&#8679</a> xs-ldas5-plotwave1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-plotwave1: plot the compound waveform from a .wfm file
USAGE: 
	xs-ldas5-plotwave1 [wave] [options]
		[wave]: waveform file as produced by xe-ldas5-datwavemean
VALID OPTIONS:
	--clean: remove temporary files (0=NO 1=YES) [1]
	-c: comma-separated list of clusters to plot (or "all") [all] 
	-s: set scale to min/max waveform for all clusters (0=NO 1=YES) [0]
	-t: set plot-type [1]
		0: multi-channel waveform, 1 cluster per line, compressed
		1: multi-channel waveform + max waveform, 1 cluster per line
		2: 5x10 summary of max waveforms
		3: 10x5 depth-profile plots
		4: single-row depth-profile plots
...peak detection options...
	--sign: .wfm detection sign, for peak-detection (-1:neg 1:pos) [-1]
	--low:  .wfm low-cut filter for xs-ldas5-clucombine1 [0]
	--high: .wfm high-cut filter for xs-ldas5-clucombine1 [0]
...plotting options...
	-f: apply filter to plots (0=NO 1=YES) [1]
	-d: depth profile trace-offset (-t 3 only) [150]
	-P: mean waveform plot options (in quotes) []
	-M: xe-plotmerge1 options (in quotes) []
EXAMPLE: 
	xs-ldas5-plotwave1 waves.wfm
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-pow1"><a href="#CODE">&#8679</a> xs-ldas-pow1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-pow1: spectral analysis of time-series data
- reads .bin files (single-channel 32-bit float)
- requires a .notes file specifying sample_rate= and a CHANNELS section
- assumes .bin file is present for the matching channel
REQUIRES: a properly formatted .notes file
USAGE: xs-ldas-pow1 [notes] [c1] [options]
	[notes]: parameter-file
	[c1]: channel number or region-name
GENERAL OPTIONS (defaults in []):
	--trials: CSV list of .notes file trial-names (or "all" or "no") [all]
	--ssp: alternatively, start-stop pairs file (.ssp) defining trials []
	--win: FFT window size (seconds) [1]
	--step: number of steps spanning FFT-window []
	--bin: bin-size (seconds) for summary [1]
	--plot: generate plots (0=NO,2=YES) [1]
	--dummy: NAN output (0=NO 1=YES, useful for dead channels) [0]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
DATA REALIGNMENT OPTIONS...
	--align: redefine start & stop as one or the other (start|stop) []
		NOTE: if set, use --pre or --post to make non-zero-length trials
	--pre: seconds to add to start [0]
	--post: seconds to add to stop [0]
NORMALIZATION OPTIONS (FOR BAND-OUTPUT)...
	--norm: band timecourse normalization-type - refer to xe-norm2 [4]
		--n1: norm-start (seconds after start, -1=start) [-1]
		--n2: norm-stop  (seconds after stop,  -1=stop)  [-1]
NOISE-REMOVAL OPTIONS...
	--clip: clipping value (de-noising only,-1=noclip) [-1]
	--nz: Z-score threshold for noise at each freq (NAN to skip) [1.0]
	--ns: sign of thesholding (-1=NEG,+1=POS,0=BOTH) [1]
	--np: % of freq &#62 nz needed to invalidate timepoint [33.333]
HIGH-CUT FILTER OPTIONS...
	--fhi: high-frequency cut (0=NONE) [0.00])
BAND OVERRIDE OPTIONS - specify comma-separated start-stop pairs...
	--delta: [.5,4]
	--alpha: [4,6]
	--theta: [6,12]
	--beta: [12,30]
	--gamma: [30,100]
	--hfo: [120,150]
PLOT OPTIONS...
	--psx: Gaussian smoother, x-axis, units []
	--psy: Gaussian smoother, y-axis (matrix plot only), units []
EXAMPLE: 
	xs-ldas-pow1 *.notes amyg  --pre -60  2&#62&1|
		tee log_xs-ldas-pow1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-preproc2"><a href="#CODE">&#8679</a> xs-ldas5-preproc2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-preproc2: spike cluster refinement
	- convert kwik file to club(t)
	- extract waveforms
	- (A) remove noisy clusters
	- (B) combine clusters based on cross-refractoriness & waveform similarity
	- (C) remove very low-spike-cuont clusters
	- (D) sort clusters based on depth of maximum-waveform
REQUIRES: 
	- [base].notes file
	- [base].dat file (chunked for clustering using times_alltrials.ssp)
	- times_alltrials.ssp
USAGE: 
	xs-ldas5-preproc2 [base]
		[base]:  base name for date-session_subject
ADDITIONAL ARGUMENTS:
	--low : .wfm low-cut filter for xs-ldas5-clucombine1 [500]
	--high : .wfm high-cut filter for xs-ldas5-clucombine1 [3000]
		NOTE: filter settings are used for combining and sorting clusters
		NOTE: filters are not used for cluster removal steps or final plots
	--kz: kill cluster zero (0=NO 1=YES) [0]
	-s | --skip : skip these steps [-]
		e: extract kwik file to club(t) files
		w: extract waveforms from .dat file (make [base].wfm)
		k: kill-step 1, based on histogram & wavecor
		c: combine steps
		K: kill-step 2, based on sparse histograms
		s: sort the clusters by peak-waveform depth
		d: expand the final .clubt file to account for .dat-chunking
		p: plot the histograms and waveforms
	--clean: remove temporarty files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-preproc2 20160721-000_2904408 --skip ew
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-preproc2b"><a href="#CODE">&#8679</a> xs-ldas5-preproc2b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-preproc2b: spike cluster refinement - batch script
	- convert kwik file to club(t)
	- extract waveforms
	- remove noisy clusters
	- combine clusters based on cross-refractoriness and waveform similarity
	- remove very low-spike-cuont clusters
	- sort clusters based on depth of maximum-waveform
USAGE: 
	xs-ldas5-preproc2b [db] [expt] [options]
		[db]: database file specifying [path] & [group]
		[expt]: experiment to analyze
OPTIONS:
	--opts1: options for xs-ldas5-preproc2, in quotes []
		--low : .wfm low-cut filter for xs-ldas5-clucombine1 []
		--high : .wfm high-cut filter for xs-ldas5-clucombine1 []
			NOTE: filter settings are used for combining and sorting clusters
			NOTE: filters are not used for cluster removal steps or final plots
		--kz: kill cluster zero (0=NO 1=YES) []
		-s | --skip : skip these steps []
			e: extract kwik file to club(t) files
			w: extract waveforms from .dat file (make [base].wfm)
			k: kill-step 1, based on histogram & wavecor
			c: combine steps
			K: kill-step 2, based on sparse histograms
			s: sort the clusters by peak-waveform depth
			p: plot the histograms and waveforms
		--clean: remove temporarty files (0=NO 1=YES) []
EXAMPLE: 
	xs-ldas5-preproc2b 20160721-000_2904408 --opts1 "--skip es --kz 0"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-preproc3b"><a href="#CODE">&#8679</a> xs-ldas5-preproc3b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-preproc3b: final wrap-up of pre-processing
	- perform cell-classification
	- create links to the Data_Library folders in Data_Working folders
USAGE: 
	xs-ldas5-preproc3b [db]
		[db]: database-file linking to the Data_Library folder
VALID OPTIONS (defaults in []):
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-preproc3b db_all.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-rega2"><a href="#CODE">&#8679</a> xs-ldas5-rega2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
Invoke regaamc8 for .dat (16-channel) or .bin (1-channel)
	- CRACK-IT version
	- assumes sampling frequency = 19531.25 Hz (.dat) or 1000Hz (.bin)
EXECUTABLE PATH: 
	/opt/LDAS/bin/regaamc8
USAGE:
	xs-ldas5-rega2 [filename] 
		[filename]: a binary .dat or .bin file
VALID OPTIONS (defaults in []):
	-t | --table: channel-table, format= &#60probe chan&#62 &#60depth&#62 &#60.dat chan&#62 []
		default depth-order = 7,10,6,8,4,11,5,9,3,12,1,14,2,13,0,15
	-o | --offset: plot offset (if data is not zero-ed) [0]
	-n | --nchans: : override number of channels if set []
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-ripdet2"><a href="#CODE">&#8679</a> xs-ldas5-ripdet2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-ripdet2: profile ripples in .dat files to aid in electrode positioning
	- ripple power (140-220 Hz) calculated using xe-ldas5-ripdet1
REQUIRES: 
	- corresponding .syn file
USAGE: 
	xs-ldas5-ripdet2 [dat] [options]
		[dat]:  name of multi-channel binary 16-bit .dat file
VALID OPTIONS:
	-s: set read start-time (seconds) [0]:
	-n: set read duration (seconds, 0=whole-file) [0]:
	-d: decimate to 2000 Hz (for plotting only: 0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-ripdet2 20100208-010_000019.dat
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-slice0"><a href="#CODE">&#8679</a> xs-ldas5-slice0</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-slice0: pre-process slice experiments
 - reads the .log2 file to find file names matching session-keywords
 		- Input/Output (IO) keyword: uA
 		- Paired-Pulse (PP) keyword: PP
 		- Long-term-potentiation (LTP) keyword: LTP
	- the .log2 file is a copy of the original WinLTP log file, except...
		- entries are checked by experimenter
		- additional fields are added to the top of the file:
			experiment= [experiment name]
			subject= [subjectID]
	- generates a machine-readable .notes file: [date]_[subject].notes
		- uses the experiment= and subject= fields added to .log2
		- extracts the date, amplification, and sample-rate from all files
			- NOTE: should be identical across all files in the folder
		- creates an XML section for each session (IO,PP,LTP)

USAGE: xs-ldas5-slice0 [log]
		[log]: log file pattern to match, in quotes

VALID OPTIONS (defaults in []):
	--db: optional database file for batch processing (&#60path&#62 &#60group&#62) []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

EXAMPLE: 
	xs-ldas5-slice0 "*.log2"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-slice1"><a href="#CODE">&#8679</a> xs-ldas5-slice1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-slice1: Analyze slice electrophysiology data (WinLTP files)
 - calls xe-ldas5-slicePOP for POP-spike analysis
 - calls xe-ldas5-sliceEPSP for fEPSP and fibre-voley analysis
 - generates a plot for each input file and a summary (SLICE1_summary.txt)
 	POP-spike
		- red dots: POP-spike area
 	fEPSP
		- red-dots: stimulation artefact
		- blue-dots: scan-area for fEPSP slope
		- green-dots: fibre-volley (if detected)

USAGE: 
	xs-ldas5-slice1 [pattern]
		file-name pattern to match (use double-quotes)

VALID OPTIONS (defaults in []):
	--pop: name of channel defining the POP-spike [AD0]
	--epsp: name of channel defining the fEPSP [AD1]
	--fout: filter output traces? (0=NO_FILTER, or 1,2,3) [2]
		1= POP-spike and fEPSP-artefact
		2= POP-spike and fEPSP-fiber-volley
		3= POP-spike and fEPSP-trough
	--opt1: quoted options for xe-ldas5-slicePOP (POP-spike) [-min1 2.5 -max1 15]
	--opt2: quoted options for xe-ldas5-sliceEPSP (fEPSP/fibre-volley) [-max1 1.25 -max2 2.5 -max3 15.0]
	--plot1: quoted options POP-spike plot [unset]
	--plot2: quoted options fEPSP plot [unset]
	--tlabel: add a label to the plot titles
	--xmax: control maximum time (ms) on x-axis of plots (""= auto) [50]
	--clean: remove temporary files on completion (0=NO 1=YES) [1]
	--conv: convert postscript output to .gif files (0=NO 1=YES) [0]
	--verb: verbose output (0=NO 1=YES) [0]

EXAMPLE: 
	xs-ldas5-slice1 "6329*.AP0"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-SLICE1b"><a href="#CODE">&#8679</a> xs-ldas5-SLICE1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-SLICE1b: batch-analize slice ephys experiments
REQUIRES:

USAGE: xs-ldas5-SLICE1b [db]
	[db]: database file in format &#60path&#62 &#60group&#62

VALID OPTIONS (defaults in []):
	--exp: CSV list of experiments to run [IO,PP,LTP]
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

EXAMPLE: 
	xs-ldas5-SLICE1b db_tg4510.txt --exp LTP,PP 2&#62&1 | tee logfile.txt

OUTPUT: 

--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-sliceconvert1"><a href="#CODE">&#8679</a> xs-ldas5-sliceconvert1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-sliceconvert1: convert a slice-ephys table of results to a machine-readable form
 - first column must contain stimulus amplitudes
 - actual values must begin on the third row
 - columns must be tab-delimited (copy & paste from excel should be ok)
 - input must contain rows labelled BATCH and SWARM
 - recontructs subject ID from BATCH and SWARM entries (remove B, append SWARM)
Example: 
	uA		BATCH	B28755	B28755	B28818	B28818	B28852
			SWARM	02	03	08	05	01
	20			-0.191	-0.25	-0.171	-0.102	-0.392
	40			-0.411	-0.6	-0.305	-0.248	-1.034
	60			-0.739	-0.835	-0.453	-0.376	-1.594
	...etc...

USAGE: xs-ldas5-sliceconvert1 [in] [group] [options]
	[in]: input file containing table
	[group]: group number to apply (0,1,2 etc)
VALID OPTIONS (defaults in []):
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-sliceconvert1 table_io_pop_grp0.txt 0
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-slice_io"><a href="#CODE">&#8679</a> xs-ldas5-slice_io</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-slice_io: Analyze slice electrophysiology input/output (I/O) experiment
 - reads the .notes file to get experiment stats and session file-names
 - calls xs-ldas5-slice1 for each trial
 	- gets the POP-spike and fEPSP stats for each session's .APO files
 - problem trials (***) and baseline (bs) are excluded
 - summarizes and plots the data for each session
USAGE: xs-ldas5-slice_io [notes]
		[notes]:  .notes file
		[expt]: CSV list of experiments to look for (IO,PP,LFP)

VALID OPTIONS (defaults in []):
	--fout: filter output traces? (0=NO_FILTER, or 1,2,3) [2]
		1= POP-spike and fEPSP-artefact
		2= POP-spike and fEPSP-fiber-volley
		3= POP-spike and fEPSP-trough
	--plot1: quoted options for POP-spike plot [unset]
	--plot2: quoted options for fEPSP plot [unset]
	--clean: remove temporary files on completion (0=NO 1=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]

OUTPUT:
	SLICE_IO_traces.ps     : plots of the individual traces (sweeps)
	SLICE_IO_summary.ps    : plots of I/O curves & transmission efficacy
	SLICE_IO_results.txt   : all results from xs-ldas5-slice1
	SLICE_IO_summary.txt   : summary stats for transmission efficacy
		measure r prob slope inter
			measure= "fv versus epsp" or "epsp versus pop-spike"
			r= Pearson's correlation coefficient
			prob= statistical probability
			slope: slope of the line (x versys y)
			inter: y-axis intercept
EXAMPLE: 
	xs-ldas5-slice_io 20160725_00000048.notes
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-slice_ltp"><a href="#CODE">&#8679</a> xs-ldas5-slice_ltp</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-slice_ltp: Analyze slice ephys LTP experiment
 - reads the .notes file to get experiment stats and session file-names
 - calls xs-ldas5-slice1 for each trial
 	- gets the POP-spike and fEPSP stats for each session's .APO files
 - problem trials (***) and tetanising trials (TO) are excluded
 - baseline is taken as the mean of the last 5 trials of the basleline period
 - summarizes and plots the data for each session
USAGE: xs-ldas5-slice_ltp [notes]
		[notes]:  .notes file

VALID OPTIONS (defaults in []):# for most scripts...
	--fout: filter output traces? (0=NO_FILTER, or 1,2,3) [2]
		1= POP-spike and fEPSP-artefact
		2= POP-spike and fEPSP-fiber-volley
		3= POP-spike and fEPSP-trough
	--tmax: maximum time (seconds) after baseline to use []
	--plot1: quoted options for POP-spike plot []
	--plot2: quoted options for fEPSP plot []
	--clean: remove temporary files on completion (0=NO 1=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]

OUTPUT:
	SLICE_LTP_traces.ps     : plots of the individual traces (sweeps)
	SLICE_LTP_summary.ps    : plots of the time-series
	SLICE_LTP_results.txt   : all results from xs-ldas5-slice1
	SLICE_LTP_epspslope.txt : normalized time-series
	SLICE_LTP_popamp.txt    : normalized time-series
	SLICE_LTP_summary.txt   : summary stats
		measure prob base ltp-1 ltp-2 ...etc...
			measure= epspslope or popamp
			prob= linear fit of baseline (if stable, should be &#62.05)
			base= avg of last 5 baseline points
			ltp-1, ltp-2 etc: avg of last 5 points for each block
EXAMPLE: 
	xs-ldas5-slice_ltp 20160725_00000048.notes
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-slice_pp"><a href="#CODE">&#8679</a> xs-ldas5-slice_pp</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-slice_pp: Analyze slice electrophysiology paired-pulse (PP) experiment
 - reads the .notes file to get experiment stats and session file-names
 - calls xs-ldas5-slice1 for the paired-pulse sweep
 	- gets the POP-spike and fEPSP stats for the relevant .APO file(s)
 - summarizes and plots the data for each session
USAGE: xs-ldas5-slice_pp [notes]
		[notes]:  .notes file

VALID OPTIONS (defaults in []):
	--fout: filter output traces? (0=NO_FILTER, or 1,2,3) [2]
		1= POP-spike and fEPSP-artefact
		2= POP-spike and fEPSP-fiber-volley
		3= POP-spike and fEPSP-trough
	--plot1: quoted options for POP-spike plot [unset]
	--plot2: quoted options for EPSP plot [unset]
	--clean: remove temporary files on completion (0=NO 1=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]

OUTPUT:
	SLICE_PP_traces.ps     : plots of the individual traces (sweeps)
	SLICE_PP_summary.txt   : summary stats for paired-pulse-facilitation
		block epsp1 epsp2 pop1 pop2  ratio_e  ratio_p
			block: stimulation-pair (there may be more than 1 pair)
			epsp2: slope of the fEPSP: 2nd stim
			epsp1: slope of the fEPSP: 1st stim
			pop1: amplitude of the POP-spike: 1st stim
			pop2: amplitude of the POP-spike: 2nd stim
			ratio_e: epsp2/epsp1
			ratio_p: pop2/pop1
EXAMPLE: 
	xs-ldas5-slice_pp 2plotmerge0160725_00000048.notes
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-velocity0"><a href="#CODE">&#8679</a> xs-ldas5-velocity0</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-velocity0: analyze Ethovision running speed, integrated over 0.4 s
REQUIRES: an Ethovision Track file 
USAGE: 
	xs-ldas5-velocity0 [pattern] [options]
		[pattern]: portion of Tracking file name(s) to match for analysis
VALID OPTIONS, defaults in []:
	-i: set integration period (s) for velocity calculation [0.4]
	-v: set velocity max (cm/s) for immobility [1]
	-V: set velocity min (cm/s) for running    [5]
	-d: set min duration (s) for immobility [10]
	-D: set min duration (s) for running    [0.1]
plot options:
	-p: plot the velocity timecourse (0=NO 1=YES) [1]
	-b: plot bin-size (sec) for averaging (0= no binning) [1]
	-x: plot decimation (sec - will override -b if set) []
	-P: extra plot options for xe-plottable1 (in quotes)) []
EXAMPLE: 
	xs-ldas5-velocity0 Track-20160415_Methods_FAM_SLEEP -b .4 -P "-ymax 10"
OUTPUT: 
	velocity data  : output_xs-ldas5-velocity0_[subject].txt
	summary        : output_xs-ldas5-velocity0_summary.txt
	plots          : output_xs-ldas5-velocity0.001.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-velocity1"><a href="#CODE">&#8679</a> xs-ldas5-velocity1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-velocity1: analyze .xyd file running speed, integrated over 0.4 s
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-ldas5-velocity1 [base] [part] [options]
	[base]= [yyyymmdd]-[ses]_[subject]
	[part]= "nose" or "body"
VALID OPTIONS, defaults in []:
	-t: trial number, name, or "all" [all]
	-i: set integration period (s) for velocity calculation [0.4]
	-v: set velocity max (cm/s) for immobility [1]
	-V: set velocity min (cm/s) for running    [5]
	-d: set min duration (s) for immobility [10]
	-D: set min duration (s) for running    [0.1]
plot options:
	-p: plot the velocity timecourse (0=NO 1=YES) [1]
	-b: plot bin-size (sec) for averaging (0= no binning) [1]
	-x: plot decimation (sec - will override -b if set) []
	-P: extra plot options for xe-plottable1 (in quotes)) []
EXAMPLE: 
	xs-ldas5-velocity1 20160415-000_2881801 body -t all -b .4 -P "-ymax 10"
OUTPUT: 
	SSP file for immobility : times_immobile.ssp
	SSP file for running    : times_running.ssp
	velocity data           : temp_xs-ldas5-velocity1
	plot of velocity        : temp_xs-ldas5-velocity1.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XBEHAV1"><a href="#CODE">&#8679</a> xs-ldas5-XBEHAV1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XBEHAV1: Behavioural analysis for REACT trials
REQUIRES: a properly formatted .notes file
USAGE: 
	xs-ldas5-XBEHAV1 [base] [part] [options]
	[base]= [yyyymmdd]-[ses]_[subject]
	[part]= "nose" or "body"
VALID OPTIONS, defaults in []:
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
	-i: set integration period (s) for velocity calculation [0.4]
	-v: set velocity max (cm/s) for immobility [.5]
	-V: set velocity min (cm/s) for running [5]
	-d: set min duration (s) for immobility [10]
	-D: set min duration (s) for running [0.1]
plot options:
	-p: generate plots?  (0=NO 1=YES) [1]
	-b: plot bin-size (sec) for averaging (0= no binning) [10]
	-x: plot decimation (sec - will override -b if set) []
	-P: extra plot options for xe-plottable1 (in quotes)) []
EXAMPLE: 
	xs-ldas5-XBEHAV1 20160415-000_2881801 body -t all -b .4 -P "-ymax 10"
OUTPUT: 
	velocity data (from 12AM) : XBEHAV1_velocity.txt
	optional plot of velocity : XBEHAV1_velocity.ps
	plot of path : XBEHAV1_path_[base].ps
	summary : XBEHAV1_summary.txt
		trial: trial name
		dur: total trial duration (seconds)
		%run: percentage of "dur" spent running (-v,-d)
		%immob: percentage of "dur" spent immobile (-V -D)
		bout: median immobility bout length (seconds)
		vmean: mean overall velocity (cm/s)
		vmedian: median overall velocity (cm/s)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XBEHAV1b"><a href="#CODE">&#8679</a> xs-ldas5-XBEHAV1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XBEHAV1b: Batch process for electrophysiology experiments
USAGE: 
	xs-ldas5-XBEHAV1b [db]
		[db]: database file to use
ADDITIONAL ARGUMENTS:
	--opt1: options (in quotes) for xs-ldas5-XBEHAV1 []
	--skip: skip these steps [-]
		x: calculation of values
		c: collate results
		p: plot results
EXAMPLE: 
	xs-ldas5-XBEHAV1b db_REACT_all.txt --opt1 "-p 0" 2&#62&1 | tee log_XBEHAV1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XHAR1"><a href="#CODE">&#8679</a> xs-ldas5-XHAR1</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>][<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XHAR1: analyze Hargreaves task behaviour and ephys data
ANALYSES:
	- behavioural latencies
		- looks for TRIAL "latency" column in the .notes file
		- if present, this is used to re-define "start" for each trial
		- if latency &#62= timeout (30 seconds), trial is excluded
USAGE: xs-ldas5-XHAR1 [base] [options]
	[base]: [yyyymmdd]-[session]_[subject]
GENERAL OPTIONS...
	--timeout: time (seconds) at which trials stop automatically [30]
	--plot: generate plots (0=NO,2=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
OPTIONS FOR xs-ldas-pow1/coh1 FOR ALTERING START-STOP PAIRS:
	--trials: CSV list of trial-names to use (or "all" or "no") [all]
	--adj: adjust trial duration using seconds in a named TRIALS column []
		"-" prefix resets start relative to stop
		"+" prefix resets stop relative to start
		- Hargreaves task stop-signals (paw-withdrawal) are accurate
		- however the trial start-syncs may preceed the lamp-activation
		- e.g. --adj -latency : start=(stop-latency*samplerate)
	--align: redefine start & stop as one or the other (start|stop) [stop]
		NOTE: if set, use --pre or --post to make non-zero-length trials
	--pre: seconds to add to start [-60]
	--post: seconds to add to stop [60]
	--fhi: high-freq. cut (smooth) for power-timecourse (0=NONE) [0.000])
BAND OVERRIDE OPTIONS - specify comma-separated start-stop pairs...
	--delta: [.5,4]
	--alpha: [4,6]
	--theta: [6,12]
	--beta: [12,30]
	--gamma: [30,100]
	--hfo: [120,150]
EXAMPLE: 
	xs-ldas5-XHAR1 20181231-000_12345 2&#62&1 | tee log_xs-ldas5-XHAR1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XHAR1b"><a href="#CODE">&#8679</a> xs-ldas5-XHAR1b</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XHAR1b: batch-run xs-ldas5-XHAR1
REQUIRES: a properly formatted .notes file
USAGE: xs-ldas5-XHAR1b [db] [options]
	[db]: database file specifying path and group on each line
VALID OPTIONS (defaults in []):
	--opt1: quoted options to pass to xs-ldas5-XHAR1 []
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
...options by-date plots
	--norm: normalisation (see xe-normrow2) [-1]
	--n1: start of normalisation zone (week-number)) [0]
	--n2: end of normalisation zone (week-number) [1]
EXAMPLE: 
	xs-ldas5-XHAR1b db_all.txt  2&#62&1 | tee log_xs-ldas5-XHAR1b.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XHAR2"><a href="#CODE">&#8679</a> xs-ldas5-XHAR2</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XHAR2: re-process TAINI Hargreaves data
 - plot mean-spectra for regions (rows) and date (page) 
 - each column summarizes data by:
 		- column1: per-subject, coloured by subject
 		- column2: per-subject, coloured by group
 		- column3: group averages, with error-bars
REQUIRES: 
	- must run xs-ldas5-XHAR1b to generate required input:
		- XHAR1_COH_summary_avg.txt
		- XHAR1_POW_summary_avg.txt
USAGE: xs-ldas5-XHAR2 
	[]: 
VALID OPTIONS (defaults in []):
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XHAR2 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XHAR3"><a href="#CODE">&#8679</a> xs-ldas5-XHAR3</h3></font>
[<a href="#tag-taini">taini</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XHAR3: analyse XHAR1b output: coherence (inflection, pre & post withdrawal)
	- run this in the Analysis folder
	- xs-ldas5-XHAR1b must be run first
USAGE: xs-ldas5-XHAR3 [analysis] [options]
	[analysis]: POW or COH 
VALID OPTIONS (defaults in []):
	--omit: CSV list of subjects to omit []
REQUIRES: xs-ldas5-XHAR1b must be run first
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
...options for by-week plots
	--norm2: by-date normalisation (see xe-normrow2) [2]
...options within-trial plots
	--bin: bin-size (seconds) [5]
	--norm1: within-trial normalisation (see xe-norm3) [3]
	--n1: start of normalisation zone (week-number)) [-60]
	--n2: end of normalisation zone (week-number) [-30]
EXAMPLE: 
	xs-ldas5-XHAR3 COH --norm 2
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPAC1"><a href="#CODE">&#8679</a> xs-ldas5-XPAC1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPAC1: Phase-amplitude coupling (PAC) analysis for LFP/EEG recordings
- does low-freq. wave-phase modulate high-freq. wave-amplitude?
- low-frequency (phase-modulating) range: 2,25 Hz
- high-frequency (amplitude-modulated) range: 30,250 Hz
- REQUIRES:
	- a properly formatted .notes file
	- a .bin file for the appropriate brain-region channel
USAGE:  
	xs-ldas5-XPAC1 [base] [c1] [c2] [options]
		[base]= base-name, typically yyyymmdd-ses_subject
		[c1]: phase(low)-freq.      channel-number or region-name
		[c2]: amplitude(high)-freq. channel-number or region-name
VALID OPTIONS, defaults in []:
	--skip: skip calculaltion of PAC - summarize & plot only (0=NO 1=YES)
		- automatically disables initial removal of old output
	--clean: remove temporary files (0=NO 1=YES) [1]
	--trial: trial number, name, TOD_LIGHT, TOD_DARK "all" or "no" [all]
		- "all" uses data from all trials
		- "no" uses data from the entire recording
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
...spectral analysis options...
	--win: window size (seconds) [2]
	--phase: limits for phase-frequencies, CSV pair [2,25]
	--amp: limits for amplitude-frequencies, CSV pair [30,250]
	--pow: method of power-calculation for PAC [1]
		0: Goertzel algorithm (slowest)
		1: Butterworth filter + RMS (fastest)
		2: 101-tap FIR filter + RMS
...band analysis options...
	--delta: delta band, CSV pair [2,4]
	--theta: theta band, CSV pair [6,12]
	--gamma: gamma/HFO bands, CSV 3xpairs [30,70,70,140,140,250]
...plot options...
	--mmod: (see xe-matrixmod1) smooth, normalize (etc.) matrix []
	--plot1: (see xe-plotmatrix) options for matrix plot (-1 to skip) []
	--plot2: (see xe-plottable1) options for line-plots (-1 to skip) []
EXAMPLE: 
	xs-ldas5-XPAC1 20160415-000_2881801 prefront amyg --trial all
OUTPUT: 
	XPAC1_log.txt
	XPAC1_pacparams.txt
	XPAC1_matrix.txt
	XPAC1_coupling.txt
	XPAC1_summary.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPAC1b"><a href="#CODE">&#8679</a> xs-ldas5-XPAC1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPAC1b: Batch process PAC analysis
- low-frequency (phase-modulating) range: 4-25 Hz
- high-frequency (amplitude-modulated) range: 25-250 Hz

USAGE: xs-ldas5-XPAC1b [db] [c1] [c2] [options]
	[db]: database file specifying path and group on each line
	[c1]: channel, phase(low)-freq.      number or region-name
	[c2]: channel, amplitude(high)-freq. number or region-name
VALID OPTIONS (defaults in []):
	--skip: skip these steps [-]
		x: execution of analysis
		c: collation of results files
	--opts: options (in quotes) for xs-ldas5-XPAC1 []
EXAMPLE: 
	xs-ldas5-XPAC1b db_25HOUR.txt --opts "-r pfc -t FAM,NOV"  2&#62&1 | tee logfile.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPAC2"><a href="#CODE">&#8679</a> xs-ldas5-XPAC2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPAC2: Determine optimal theta and high-freqbands for PAC analysis
- run this program on the multi-subject-matrix output from xs-ldas5-XPAC1b
- low-frequency (phase-modulating) range: - Hz
- high-frequency (amplitude-modulated) range: - Hz
USAGE: 
	xs-ldas5-XPAC2 [ref]
		[ref]: reference group (or "all") for estimating bands []
ADDITIONAL ARGUMENTS (default in []):
	--twidth: fixed width of auto=-detected theta-band (Hz) [3]
	--theta: CSV list specifying theta-range, or auto [auto]
			NOTE: this overrides --twidth
	--stat: statistic to use to summarize high-frequency PAC band [auc]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XPAC2 all
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPACKETLOSS1"><a href="#CODE">&#8679</a> xs-ldas5-XPACKETLOSS1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPACKETLOSS1: estimate packet loss in a trial from the binary .dat file
REQUIRES: a properly formatted .notes file
USAGE: 
	xs-ldas5-XPACKETLOSS1 [base] [options]
	[base]= [yyyymmdd]-[ses]_[subject]
VALID OPTIONS, defaults in []:
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
plot options:
	-b: bin-size (seconds) for averaging (0= no binning) [1]
	-P: extra plot options for xe-plottable1 (in quotes)) []
EXAMPLE: 
	xs-ldas5-XPACKETLOSS1 20160415-000_2881801 -t all -b .4 -P "-ymax 10"
OUTPUT: XPACKETLOSS1 files
	XPACKETLOSS1_summary.txt : summary statistics
	XPACKETLOSS1_trace.txt   : data trace for the binned packet-loss
	XPACKETLOSS1_trace.ps    : plot of the above
	XPACKETLOSS1_hist.ps     : probability histogram for packet loss
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPACKETLOSS1b"><a href="#CODE">&#8679</a> xs-ldas5-XPACKETLOSS1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPACKETLOSS1b: Batch process for electrophysiology experiments - packet loss
USAGE: 
	xs-ldas5-XPACKETLOSS1b [db]
		[db]: database file to use
ADDITIONAL ARGUMENTS:
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
	-b: bin-size (sec) for averaging (0= no binning) [1]
	-s: skip these steps [-]
		x: calculation of values
EXAMPLE: 
	xs-ldas5-XPACKETLOSS1b 20150930-001 ../Data_Library
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPLACE1"><a href="#CODE">&#8679</a> xs-ldas5-XPLACE1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPLACE1: Generate and plot place fields using a multi-matrix file
USAGE: 
	xs-ldas5-XPLACE1 [base]
		base: base-name in format yyyymmdd-ses_subject
ADDITIONAL ARGUMENTS:
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
	-c: comma-separated list of clusters to analyze (or all) [all]
	-f: flip maps (0=sno, 1=x-axis, 2=y-axis) [0]
	-s: smooth map (pixels) [0]
	-O: options for xe-ldas5-placefields1 (in quotes) []
	-P: options for xe-plotmatrix1 (in quotes) []
	-M: options for xe-plotmerge1 (in quotes) []
	--vmin: minimum speed (cm/s) [NAN]
	--vmax: maximum speed (cm/s) [NAN]
		NOTE: set both to "NANa" to include spikes when vel=NAN
	--skip: skip these steps [-]
		p: plot place fields
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XPLACE1 20001231-001_000001.data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPLACE1b"><a href="#CODE">&#8679</a> xs-ldas5-XPLACE1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPLACE1b: Batch process place-field analysis
USAGE: 
	xs-ldas5-XPLACE1b [db]
		[db]: database file specifying path and group on each line
ADDITIONAL ARGUMENTS:
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
		p: plot results
	--opt1: options (in quotes) for xs-ldas5-XPLACE1 []
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-ldas5-XPLACE1b db_25HOUR.txt -O "-t FAM1"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPOW1"><a href="#CODE">&#8679</a> xs-ldas5-XPOW1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPOW1: LFP/EEG spectral power analysis (0-100Hz) - Taini + Ethovision
REQUIRES: .bin LFP files and a properly formatted .notes file
USAGE: 
	xs-ldas5-XPOW1 [base] [options]
	[base]= [yyyymmdd]-[ses]_[subject]
VALID OPTIONS, defaults in []:
	-r: region [hipp.dorsal.ca1.pyr]
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
	--clean: remove temporary files (0=NO 1=YES) [1]
Movement options:
	-i: set integration period (s) for velocity calculation [0.4]
	--immobvel: set low-velocity max (cm/s) for immobility [0.5]
	--immobdur: set min duration (s) for immobility [10]
	--runvel: set high-velocity min (cm/s) for running [5]
	--rundur: set min duration (s) for running [0.1]
FFT options:
	--fmin: FFT minimum frequency [0.5]
	--fmax: FFT maximum frequency [140]
	--funits: FFT output units (0=amp 1=dB 2=RMS 3=power ie. RMS-squared) [0]
Plot options:
	-p: plot the velocity timecourse (0=NO 1=YES) [1]
	-b: bin-size (sec) for averaging (0= no binning) [1]
	-x: decimation (sec - will override -b if set) []
	-P: extra plot options for xe-plottable1 (in quotes)) []
EXAMPLE: 
	xs-ldas5-XPOW1 20160415-000_2881801 -t all -b .4 -P "-ymax 10"
OUTPUT: 
	XPOW1_summary.txt
	XPOW1_specmean.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XPOW1b"><a href="#CODE">&#8679</a> xs-ldas5-XPOW1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XPOW1b: Batch process spectral power analysis
	- includes spectral post-processing to redefine functional bands
USAGE: 
	xs-ldas5-XPOW1b [db]
		[db]: database file specifying path and group on each line
ADDITIONAL ARGUMENTS:
	--cont: control group to use for re-defining bands [1]
	--opts1: options (in quotes) for xs-ldas5-XPOW1 []
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
EXAMPLE: 
	xs-ldas5-XPOW1b db_25HOUR.txt -O "-r pfc -t NOVEL" 2&#62&1 | tee XPOW1.log
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XREMAP1"><a href="#CODE">&#8679</a> xs-ldas5-XREMAP1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XREMAP1: remapping tests and related measures
	- to quatntify changes in response to a minupulation (eg. novelty)
	- makes use of:
		xs-ldas5-cellstats1
		xs-ldas5-XPLACE1
		xs-ldas5-XBEHAV1
USAGE: 
	xs-ldas5-XREMAP1 [base] [trial1] [trial2]
		base: base-name in format yyyymmdd-ses_subject
		trial1: first trial for comparison (baseline)
		trial2: second trial for comparison (response)
ADDITIONAL ARGUMENTS:
	--type: type of comparison (see xe-math_doublet) [2]
		1: add
		2: subtract
		3: multiply
		4: divide
	--stat: summary statistic to use (single value per column) [unset]
		options: MIN,MAX,SUM,MEAN,RANGE,STDDEV,SEM,PERCENTILE_50
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XREMAP1 20001231-001_000001.data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XREMAP1b"><a href="#CODE">&#8679</a> xs-ldas5-XREMAP1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XREMAP1b: Batch process remapping analysis
USAGE: 
	xs-ldas5-XREMAP1b [db] [trial1] [trial2]
		[db]: database file specifying path and group on each line
		trial1: first trial for comparison (baseline)
		trial2: second trial for comparison (response)
ADDITIONAL ARGUMENTS:
	--skip: skip these steps [-]
		x: calculation of values
		c: collate results
		p: plot results
	--opt1: options (in quotes) for xs-ldas5-XREMAP1 []
	--skip: skip these steps [-]
		x: calculation of values
		c: collate results
		p: plot results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XREMAP1b db_25HOUR.txt -O "-t FAM1"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XRIP1"><a href="#CODE">&#8679</a> xs-ldas5-XRIP1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XRIP1: detect ripple oscillations during trial/velocity epochs
REQUIRES: 1000Hz .bin LFP files and a properly formatted .notes file
USAGE: 
	xs-ldas5-XRIP1 [base] [options]
	[base]= [yyyymmdd]-[ses]_[subject]
VALID OPTIONS, defaults in []:
	-r: region [hipp.dorsal.ca1.pyr] - if numeric, force channel-number
	-t: trial number, name, TOD_LIGHT, TOD_DARK or "all" [all]
		- TOD (time-of-day) options select lights on or off
		- this is based on the times_light or times_dark .ssp files
	-i: integration period (s) for velocity calculation [0.4]
	-v: velocity minimum (cm/s) [nan]
	-V: velocity maximum (cm/s) [0.5]
	-d: minimum duration (s) for velocity criteria [300]
	--emin: event-detection minimum (z-score) [2]
	--emax: event-detection maximum (z-score) [20]
	--amp: ripple-amplitude minimum, for inclusion (uV) [0]
	--plot: plot ripples ( 0=NO, 1=MEAN, 2=ALL 3=DEPTH (exemplar) ) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
OUTPUT: 
	 XRIP1_ripples.txt   : statistics on each ripple
	 XRIP1_waveforms.txt : ripple waveforms
	 XRIP1_summary.txt   : subject summary
		NOTE: sample-numbers in output refer to original .dat file
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XRIP1b"><a href="#CODE">&#8679</a> xs-ldas5-XRIP1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XRIP1b: Batch process ripple-detection for electrophysiology experiments
USAGE: 
	xs-ldas5-XRIP1b [db]
		[db]: database file specifying path and group on each line
ADDITIONAL ARGUMENTS:
	-s: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--opts1: quoted options for xs-ldas5-XRIP1 []
EXAMPLE: 
	xs-ldas5-XRIP1b db.txt --opts1 "-t SLEEP -d 60"  2&#62&1|tee log_XRIP1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XRIP2"><a href="#CODE">&#8679</a> xs-ldas5-XRIP2</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XRIP2: detect changes in ripples across blocks of trials 
	- to quatntify changes in response to a minupulation (eg. novelty)
	- makes use of:
		xs-ldas5-XRIP1
USAGE: 
	xs-ldas5-XRIP2 [base] [trial1] [trial2]
		base: base-name in format yyyymmdd-ses_subject
		trial1: first trial for comparison (baseline)
		trial2: second trial for comparison (response)
ADDITIONAL ARGUMENTS:
	-r: region [hipp.dorsal.ca1.pyr]
	-i: integration period (s) for velocity calculation [0.4]
	-v: velocity minimum (cm/s) [nan]
	-V: velocity maximum (cm/s) [0.5]
	-d: minimum duration (s) for velocity criteria [300]
	--type: type of comparison (see xe-math_doublet) [2]
		1: add
		2: subtract
		3: multiply
		4: divide
	--stat: summary statistic to use (single value per column) [unset]
		options: MIN,MAX,SUM,MEAN,RANGE,STDDEV,SEM,PERCENTILE_50
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XRIP2 20001231-001_000001.data.txt
OUTPUT: 
	XRIP2_repeated.txt
	XRIP2_diff.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XRIP2b"><a href="#CODE">&#8679</a> xs-ldas5-XRIP2b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XRIP2b: batch-run xs-ldas5-XRIP2
REQUIRES: a properly formatted .notes file
USAGE: 
	xs-ldas5-XRIP2b [db] [trial1] [trial2]
		[db]: database file specifying path and group on each line
		trial1: first trial for comparison (baseline)
		trial2: second trial for comparison (response)
VALID OPTIONS (defaults in []):
	--opts1: quoted options to pass to xs-ldas5-XRIP2
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XRIP2b db_react.txt SLEEP2 SLEEP3 --opts "-v nan -V 0.5 -d 60"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XSERIES1"><a href="#CODE">&#8679</a> xs-ldas5-XSERIES1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XSERIES1: create table of 1s-window time-series data for:
	- velocity
	- firing rates for pyramidal cells and interneurons
	- spectral power in the delta,theta,beta, and gamma bands
USAGE: 
	xs-ldas5-XSERIES1 [base]
VALID OPTIONS (defaults in []):
	-t | --trials: CSV list of trials to use for rate (or "all") [all]
	-r | --region: brain region to analyze [hipp.dorsal.ca1.pyr]
	-n | --norm: normalization applied to cell firing rates [-1]
			- refer to xe-norm2 for options
			- e.g. -1= no normalization
			- e.g.  1= z-scores
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XSERIES1 20170731-001_000016
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas5-XSERIES1b"><a href="#CODE">&#8679</a> xs-ldas5-XSERIES1b</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XSERIES1b: Batch process time-series analysis
USAGE: 
	xs-ldas5-XSERIES1b [db]
		[db]: database file specifying path and group on each line
ADDITIONAL ARGUMENTS:
	--skip: skip these steps [-]
		x: calculation of values
		c: collate results
		p: plot results
	--opt1: options (in quotes) for xs-ldas5-XSERIES1 []
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-ldas5-XSERIES1b db_25HOUR.txt -O "-t FAM1"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-cmt2series1"><a href="#CODE">&#8679</a> xs-ldas-cmt2series1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-cmt2series1: convert a comment-file to a time series
USAGE: 
	xs-ldas-cmt2series1 [infile] [samplefreq]
		[infile]: input file in format &#60time&#62&#60TAB&#62&#60comment&#62
			- assumes each comment marks the start of a given state
			- assumes this state continues until the next comment
		[samplefreq]: sampling frequency for output
ADDITIONAL ARGUMENTS:
	-f: format (0=simple 1=verbose) [1]
EXAMPLE: 
	xs-ldas-cmt2series1 data.txt
OUTPUT: 
	continuous time-series with comments repeated until next comment occurs: 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-cmt2window"><a href="#CODE">&#8679</a> xs-ldas-cmt2window</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-cmt2window: convert a comment file containing start signals to start/stop pairs
USAGE: 
	xs-ldas-cmt2window [cmtfile] [signal] [pre] [post]
		[cmtfile]: file in format &#60time&#62 &#60signal&#62
			 - time is in seconds and represents the alignment point
		[signal]: text to match in the second column
		[pre]: time (secs) before the signal to include (positive number)
		[post]: time (secs) after the signal to include (positive number)
ADDITIONAL ARGUMENTS, defaults in []:
	-f: sample frequency (Hz) to convert seconds to samples [1]
	-s: minimum start-time: if unset (-s ""), include all []
	-e: maximum stop-time: if unset (-e ""), include all)  []
EXAMPLE: 
	xs-ldas-cmt2window 001-991231.cmt START_000 5 15 -f 400
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-cmtappend1"><a href="#CODE">&#8679</a> xs-ldas-cmtappend1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-cmtappend1: append a comment to a .cmt file
REQUIRES: a properly formatted .notes file
USAGE: 
	xs-ldas-cmtappend1 [in] [comment]
		[in]: input comment file in format &#60time&#62 &#60comment&#62
		[comment]: the comment to append
VALID OPTIONS (defaults in []):
	-t | --type: append type [0]
		1= after first comment
		2= after last comment
		3= after particular comment
			- see -m option below
			- exact-matches not required
	-m | --match: comment to match for types 3&4 above []
	-o | --off: time-offset to apply (seconds) [0]
	-r | --rep: replace original file (0=NO 1=YES) [0]
		NOTE: if "0", output is temp_xs-ldas-cmtappend1
	-v | --verb: verbose output (0=NO 1=YES) [0]
EXAMPLE: 
	xs-ldas-cmtappend1 noreward.cmt TRIALEND -t 3 -m LEVER -o 5.00 -r 1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-cmtstartstop"><a href="#CODE">&#8679</a> xs-ldas-cmtstartstop</h3></font>
<blockquote><pre>
------------------------------------------------------------------------------
xs-ldas-cmtstartstop: pull out the first & last comment in a .cmt file
- first comment will be labelled "SESSION_START"
- last comment will be labelled "SESSION_END"
- only considers lines: 
	- with at least two fields
	- with a numeric value (time) in the first field
	- for which time is larger than the preceeding line
USAGE: xs-ldas-cmtstartstop [comment-file] 
	[comment-file]: file in format &#60time&#62 &#60event&#62

EXAMPLE: 
	xs-ldas-cmtstartstop 002-991231_001.cmt &#62 new_cmt.txt
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-coherence_demo"><a href="#CODE">&#8679</a> xs-ldas-coherence_demo</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-coherence_demo: generate a pseudo-dataset for coherence analysis
USAGE: 
	xs-ldas-coherence_demo [infile1] [infile2]
		input files:
			jjj1: reference data  
			jjj2: high frequency phase-shifted
			jjj3: low frequency phase-shifted
			jjj4: high frequency different 
			jjj5: low frequency different
EXAMPLE: 
	xs-ldas-coherence_demo jjj1 jjj5
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-dbcheck"><a href="#CODE">&#8679</a> xs-ldas-dbcheck</h3></font>
<blockquote><pre>
------------------------------------------------------------------------------
xs-ldas-dbcheck: check the validity of an 02-sensing database
	- is each path valid?
	- are group and hemisphere specified for each path?
	- have the appropriate notes, time, dat and cmt files been produced?
	- does the notes file specify number of channels and sample-rate?
	- is the specified region/hemisphere specified in the notes file?
	- are the .time and .cmt files present for those channels?
USAGE: xs-ldas-dbcheck [database] [region]
	[database]: name of the database (.db) file to use
	[region]: brain region (e.g. DHIPP, MPFC)

EXAMPLE: xs-ldas-dbcheck database_mpfc.db MPFC
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-filtercmtb"><a href="#CODE">&#8679</a> xs-ldas-filtercmtb</h3></font>
<blockquote><pre>
------------------------------------------------------------
Use a database file to batch-filter comment files
- keep only comments matching a pattern
- useful if different probes are from different subjects, but
	CHART software used a ONLY single-column for comment output
- requires a special database file specifying the pattern
Useage: xs-ldas-filtercmtb [database]
	database: 
		contains list of directories to look in
		format: [path] [subject-pattern]
		database example: 
			../Data_Working/031-991231	Aninmal_01
			../Data_Working/032-991231	Aninmal_02
			../Data_Working/033-991231	Aninmal_01
			../Data_Working/034-991231	Aninmal_02
			../Data_Working/035-991231	Aninmal_01
			../Data_Working/036-991231	Aninmal_02
Example:
	xs-ldas-filtercmtb database.txt
Output:
	- modified comment files with only comments matching pattern
	- a backup of the original comment file

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-getchannel"><a href="#CODE">&#8679</a> xs-ldas-getchannel</h3></font>
[<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-getchannel: get the channel-number for a region in an LDAS .notes file
	- this is derived from the CHANNELS table in the .notes file
USAGE: xs-ldas-getchannel [notes] [region] [options]
	[notes]: an LDAS .notes file containing a CHANNELS xml section
	[region]: the brain region to find
VALID OPTIONS (defaults in []):
	--output column [chan]
	--good: accept only good channels (0=NO 1=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
OUTPUT: a CSV list of channels meeting criteria, or an error message
EXAMPLE: 
	chan=$(xs-ldas-getchannel file.notes PFC)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-getseqb"><a href="#CODE">&#8679</a> xs-ldas-getseqb</h3></font>
<blockquote><pre>
------------------------------------------------------------------------------
xs-ldas-getseqb: find sequences of comments in the .cmt files of a database
Calls xe-getsequence1 - check this program for more on sequence detection
USAGE: xs-ldas-getseqb [database] [region] [options] [sequence]
	[database]: name of the database (.db) file to use
	[region]: brain region (e.g. DHIPP, MPFC)
	[options]: optional arguments
	    -i : the input file (overrides the default)
	    -o : the output file (default=temp_xs-ldas-getseqb.cmt)
	    -m : match mode,  "exact" or "contains" (default=contains)
	[sequence]: the sequence of comments to find
EXAMPLE: xs-ldas-getseqb database.db HIPP -i correct.cmt START CORRECT START
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-gettrials1"><a href="#CODE">&#8679</a> xs-ldas-gettrials1</h3></font>
[<a href="#tag-time">time</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-gettrials1: get start-stop-pairs (SSPs) for trials or time of day (TOD)
- requires a properly formatted .notes file
- output is to stdout
USAGE: 
	xs-ldas-gettrials1 [notesfile] [trial]
		[notesfile]: file with XML section defining TRIALS
		[trial]: numbers, name, TOD_LIGHT, TOD_DARK or "all"
			- "all" outputs SSPs for all trials, not the whole recording
			- name matches any trial-names containing the text
			- numbers can be a single number or a CSV list
			- TOD_LIGHT and TOD_DARK use the -t option (below)
				- finds periods spanning the session-start or -stop
				- hence negative start-times are possible
VALID OPTIONS (defaults in []):
	-o: output format (1=CSV list, 2=binary(long) SSPs) [1]
	-t: set time of lights-on (hh:mm:ss) [07:00:00]
	-d: set divisor for SSPs []
EXAMPLES: 
	xs-ldas-gettrials1 20160609-002_2881801.notes  TOD_LIGHT
	xs-ldas-gettrials1 20160609-002_2881801.notes  4,5,6
	xs-ldas-gettrials1 20160609-002_2881801.notes  SLEEP
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-gettrials2"><a href="#CODE">&#8679</a> xs-ldas-gettrials2</h3></font>
[<a href="#tag-time">time</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-gettrials2: extract timestamps or data for trials matching a pattern
 - extract TRIALS from .notes file as start-stop pairs (SSP blocks)
 - option to adjust start or stop relative to the other using a duration column
 - option to redefine start & stop as either (identical values)
 	- allows creation of aligned fixed-length blocks with --pre or --post
 - apply downsampling-correction to SSPs for working with LFP (.bin) files
 - get trial-specific data from .dat .bin .club(t) or .xyd(t) files

USAGE: 
	xs-ldas-gettrials2 [notes] [options]
		[notes]: .notes file

VALID OPTIONS (defaults in []):
	-n | --name : CSV list of trial names, or "all" or "no" [all]
		- NOTE: use of "no" overrides most other options
			- a single "trial" spans the whole recording
	-m | --match : match-style for xe-dbmatch1 [1]
		 1= contains at least one pattern
		 2= exact match with at least one pattern
		-1= contains none of the patterns
		-2= exact match with none of the patterns
	-o | --out : output table,list,ssp, or file) [table]
		table: entire TRIALS table, XML tags and blank lines removed
		list: single-line of SSPs, comma-delimited
		ssp: binary series of long-integer SSPs, sent to stdout
		file: input and output are files
	--pmax: max allowed trial packet-loss [0]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

OPTIONS (IN ORDER PERFORMED) FOR ALTERING THE START-STOP PAIRS:
	--adj: adjust trial duration using seconds in a named TRIALS column []
		"-" prefix resets start relative to stop
		"+" prefix resets stop relative to start
		e.g. --adj +heat adds "heat" to start to adjust stop
	--align: redefine start & stop as one or the other (start|stop) []
		NOTE: if set, use --pre or --post to make non-zero-length trials
	--pre: seconds to add to start [0]
	--post: seconds to add to stop [0]

OPTIONS FOR LIST/SSP OUTPUT:
	-d | --down : downsample SSPs to match .bin files (0=NO 1=YES) [0]

OPTIONS FOR BINARY FILE OUTPUT (--out file):
	--in1 : input filename, if --out is set to "file" []
		.dat      : short multi-channel file
		.bin      : float single-channel file (uses corrected SSPs)
		.clubt    : long/short file pair
		.xydt     : long/triple-float file pair
	--in2 : override for default matching .club or .xyd file name []

EXAMPLE: adjust start to stop-[latency], align start, & take preceeding 60s
	xs-ldas-gettrials2 data.notes --adj -latency --align start --pre -60 

EXAMPLE: extract data from a .clubt file corresponding with SLEEP trials
	xs-ldas-gettrials2 data.notes -n SLEEP -o file --in1 data.clubt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-killbadchans1"><a href="#CODE">&#8679</a> xs-ldas-killbadchans1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-killbadchans1: remove .bin files corresponding to dead channels
 - this is a space-saving measure
 - crawls through the folders in Data_Library and Data_Working
 - requires a .notes file in each directory
USAGE: xs-ldas-killbadchans1 [folders] [options]
	[folders]: CSV list of folders to scan
VALID OPTIONS (defaults in []):
	--xml: XML section containing channel information [CHANNELS]
	--col: column to match "bad" values [good]
	--bad: CSV list of values to match indicating bad values [0]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas-killbadchans1 Data_Library,Data_Working --col good --bad 0 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-maketestcurves1"><a href="#CODE">&#8679</a> xs-ldas-maketestcurves1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-maketestcurves1: #generate a n-segment sin-curve spanning 0 to a fraction of PI
REQUIRES: 
USAGE: 
	xs-ldas-maketestcurves1 [npoints] 
		npoints: number of segments in curve (points=n+1)
VALID OPTIONS (defaults in []):
	-p: maximum fraction of PI to generate [1.5]
	-n: level of Gaussian noise [.25]
	-r: repetitions [100]
	--plot: flag to generate plot of exemplar and mean curve [unset by default]
NOTES: 
		- AUC for each lobe of a sine curve is exaclty 2
		- Example: if pimax=0.75, the total AUC is exactly 1: 
			+2 for the positive portion
			-1 for the negative portion
OUTPUT: 
	CURVES_rows.txt: one curve on each of -r rows
	CURVES_mean.txt: mean curve, single column
	CURVES_examplar.ps: plot of first curve
	CURVES_mean.ps: plot of mean curve
EXAMPLE: 
	xs-ldas-maketestcurves1 10 -n 0.5 -r 100 --plot
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-matrixcut1"><a href="#CODE">&#8679</a> xs-ldas-matrixcut1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-matrixcut1: pull data for one subject from an LDAS multi-matrix file
USAGE: 
	xs-ldas-matrixcut1 [file] [subj]
		[file] file with matrices separated by "# [subj]" comments
		[subj] the subject-number to match on each comment line
ADDITIONAL ARGUMENTS:
EXAMPLE: 
	xs-ldas-matrixcut1 data_matrix.txt 28
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-matrixdiff1"><a href="#CODE">&#8679</a> xs-ldas-matrixdiff1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-matrixdiff1: calculate the matrix-difference for mulitiple subjects
USAGE: 	xs-ldas-matrixdiff1 [in1] [in2]
		[in1] reference multi-matrix file
		[in2] multi-matrix file from which [in1] will be subtracted
EXAMPLE: 
	xs-ldas-matrixdiff1 matrix1.txt matrix2.txt 
OUTPUT: 
	Matrices representing the [in2]-[in1] difference for each subject
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-matrixdiff2b"><a href="#CODE">&#8679</a> xs-ldas-matrixdiff2b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-matrixdiff2b: present matrix group averages based on within-subject differences
- assumes group-id's in database refer to treatments which are repeated
	- hence each subject belongs to multiple groups
- assumes a matrix has already been generated for each subject/treatment
	- subtracts each matrix  for the reference for that subject
	- then averages the difference matrices for each tratment
USAGE: 
	xs-ldas-matrixdiff2b [db] [ref] [matrix] [opts]
		[db] database file in format &#60path&#62 &#60group&#62
		[ref] group-number to  use as reference
		[matrix] the name of the matrix file for each subject/treatment
		[opts] options for plotmatrix1
EXAMPLE: 
	xs-ldas-matrixdiff2b  0 matrix.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-medpavprob1"><a href="#CODE">&#8679</a> xs-ldas-medpavprob1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-medpavprob1:  process multiple MED-PC files for probabilistic Pavolovian training
- input files must be formatted as per requirements of  xe-ldas-readmed2
USAGE: xs-ldas-medpavprob1 [database]
	[databaseb]: file in format &#60filename&#62&#60tab&#62&#60group_code&#62
EXAMPLE: 
	xs-ldas-medpavprob1 db_experiment1.txt
OUTPUT: 
	pavprob1_data.txt : transformed data from  MED-PC file
	pavprob1_average.txt : averages by trial-type
	pavprob1_summary.txt : summary, one line per subject
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-modcmt1b"><a href="#CODE">&#8679</a> xs-ldas-modcmt1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-modcmt1b: substitute up to 5 text-patterns in .cmt files
	- uses group ID to determine what substitution should be
	- uses [basename].001.cmt as input
USAGE: 
	xs-ldas-modcmt1b [database-file] [options]

VALID OPTIONS - defaults in []:
	-g: group to change (all, number, or ""=none) [all]
	-o: name of output file  [temp_xs-ldas-modcmt1b.cmt]
	-a, -b, -c, -d -e: old-patterns to be replaced (default: replace nothing)
	-A, -B, -C, -D -E: new patterns to replace them with

EXAMPLE: recode left/right lever-comments with group-appropriate reward codes
	xs-ldas-modcmt1b db_all.txt -g 0 -a LLEVER -A LOW  -b RLEVER -B HIGH
	xs-ldas-modcmt1b db_all.txt -g 1 -a LLEVER -A HIGH -b RLEVER -B LOW
OUTPUT: new .cmt file temp_xs-ldas-modcmt1b.cmt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-parsename"><a href="#CODE">&#8679</a> xs-ldas-parsename</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-parsename: parse an LDAS file/folder name:
- format assumed to be [date][-session]_[subject][-part]
- must contain a date ans subject section separated by "_"
- example: 20001231-001_12345-064
 		date=31.Dec.2000, session=1, subject=12345, channel=64
	date: typically in yyyymmdd format
	session: (optional): the recording session for that date
	subject: the unique subject ID
	part: (optional): sub-division of subject: channel, region, etc
	base: basename, combination of date, session(optional), and subject
USAGE: xs-ldas-parsename [in] [field]
	[in]: name to parse
	[field]: field to extract - date, session, subject, part or base
VALID OPTIONS (defaults in []):
	-f: flag as filename - if set, strips filetype extension [unset]
	-s: flag, require session to be defined [unset]
	-p: flag, require part to be defined [unset]
OUTPUT: the requested field (empty if not found)
EXAMPLE: 
	xs-ldas-parsename 20181231_12345.dat subject -f
	xs-ldas-parsename 20181231-001_12345-016 subject
	xs-ldas-parsename 20181231_12345-016.dat seession
	d=$(xs-ldas-parsename 20181231_12345 date)
		if [[ $d = *"Error"* ]]; then  echo "$d" ; echo ; exit ; fi
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-readethovision1"><a href="#CODE">&#8679</a> xs-ldas-readethovision1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-readethovision1: extract EthoVision data 
--------------------------------------------------------------------------------
Read and convert Ethovision-export data
	- quotation marks removed
	- semicolon delimiters replaced by tabs
	- empty fields replaced with "nan"
	- spaces and parentheses replaced with underscores
	- multiple consecutive underscores replaced with a single underscore

USAGE: xs-ldas-readethovision1 [source] [options]
	[source]: name of file to read
		- DOS-format files may need to be pre-processed with dos2unix
		- semicolon-delimited
		- fields are enclosed in quotes and may contain spaces
	[options]: values to extract (after reformatting)
		-h header value to extract (1st match) or "ALL" (keys + values)
		-c columns to extract, based on column-labels (or "ALL") 
		-R (flag) extract recording parameters (single line)
			- absolute recording start date (dd/yy/yyyy)
			- absolute recording start time (hh:mm:ss)
				- adjusted for delay at beginning of trial
			- recording duration (hh:mm:ss)
			- example output: 19/08/2015  15:20:43.3  00:00:15.0

EXAMPLE: 
	xs-ldas-readethovision1 ETHO.txt -h vSESSION
	xs-ldas-readethovision1 ETHO.txt -c Recording_time,X_center,Y_center
	xs-ldas-readethovision1 ETHO.txt -R
	dur=$(xs-ldas-readethovision1 ETHO.txt -R |cut -f 3|xe-timeconv1 stdin)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-scorecoh1"><a href="#CODE">&#8679</a> xs-ldas-scorecoh1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-scorecoh1: calculate coherence change between two time-points for two input files
	- this version is for reading 7-day SCORE files
USAGE: 
	xs-ldas-scorecoh1 [inA] [inB] [t1] [t2] [s]
	[inA]: channel-A input (SCORE raw file)
	[inB]: channel-B input (SCORE raw file)
	[start2]: start time (YY:MM:DD:hh:mm:ss) for main block (post-baseline)
ADDITIONAL ARGUMENTS:
	-n: baseline time (hours before start2) [24]
	-a: duration of baseline (hours) [unset: same as -b, below] 
	-b: duration of main block (hours) []
	-f: filter results using behavioural state SCORES []
		R= REM sleep
		N= non-REM sleep
		W= wake
		T= wake, theta
	-C: coherence options (in quotes) [-sf 400 -min 0.5 -max 200 -w 400 -s 1 -t 1 -a 10 -dt 0 ]
		NOTE: if set, added to defaults with override
	-l:  low-frequency boundary for bandwidth analysis [4]
	-h:  high-frequency boundary for bandwidth analysis [4]
	-x:  clean up temporary files (0=NO, 1=YES) [1]
	-p: plot results (0=NO 1=YES) [0]
EXAMPLE: 
	xs-ldas-scorecoh1 30353.hpc4 30353.pfc4 14:11:11:06:00:00  5 -n 24 -d 5 -f WT
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-scorecoh1b"><a href="#CODE">&#8679</a> xs-ldas-scorecoh1b</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-scorecoh1b: calculate coherence change using a database file
	- this version is for reading 7-day SCORE files
USAGE: 
	xs-ldas-scorecoh1b [db] [options]
	[db]: database file in &#60base&#62 &#60time&#62 &#60group&#62 format
VALID OPTIONS :
	-n: baseline time (hours before start2) [24]
	-a: duration of baseline (hours) [unset: same as -b, below] 
	-b: duration of main block (hours) []
	-f: filter results using behavioural state SCORES [RNWT]
		R= REM sleep
		N= non-REM sleep
		W= wake
		T= wake, theta
	-C: coherence options (in quotes) [-sf 400 -min 0.5 -max 100 -w 800 -s 2 -t 1 -a 10]
	-p: plot only (0=NO, 1=YES) [0]
EXAMPLE: 
	xs-ldas-scorecoh1b db_all.txt -n 24 -a 5 -b 5
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-scoresummary1"><a href="#CODE">&#8679</a> xs-ldas-scoresummary1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-scoresummary1: summarize 16 SCORE data files
REQUIRES: a properly formatted database file listing files in cage-order
	- should be 16 files listed in the database
	- files are currently assumed to be SCORE raw format
	- missing files should be designated by a "-"
	- xe-readscore1 used to read the files and assess clipping
	- xe-fftpow2 used to calculate amplitude spectrum
USAGE: 
	xs-ldas-scoresummary1 [dbfile]
ADDITIONAL ARGUMENTS:
	-s: start record (integer) or time (YY:MM:DD:hh:mm:ss) [0]
	-n: number of 10s records to read [360]
EXAMPLE: 
	xs-ldas-scoresummary1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-scoreworksheet2db"><a href="#CODE">&#8679</a> xs-ldas-scoreworksheet2db</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-scoreworksheet2db: read a score worksheet and create a database file
USAGE: 
	xs-ldas-scoreworksheet2db [file]
		[file]: csv file containing experimental info
			ANIMALID	: 5-digit code
			TREATMENTDATE	: Dosing date (dd/mm/yyyy)
			TREATMENTTIME	: Dosing time (mm:hh:ss)
			COMPARISONGROUP	:
				A: combo-treament, becomes group "1"
				B: pre-treament, becomes group "3"
				C: principal treatment, becomes group "2"
				D: vehicle/vehicle, becomes group "8"
			EEG,FFT		: QC pass (Y/N)
ADDITIONAL ARGUMENTS:
	-f: format (0=simple 1=verbose) []
EXAMPLE: 
	xs-ldas-scoreworksheet2db StudyAnimalInfo.csv
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-trials2cmt"><a href="#CODE">&#8679</a> xs-ldas-trials2cmt</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-trials2cmt: convert trials table to a .cmt file
REQUIRES: a properly formatted .notes file with a TRIALS xml section
USAGE: xs-ldas-trials2cmt [in] [options]
	[in]: input file, format= &#60time&#62 &#60data&#62
	--xml: xml section containing trial records []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas-trials2cmt "*.notes"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-updatenotes"><a href="#CODE">&#8679</a> xs-ldas-updatenotes</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-database">database</a>][<a href="#tag-string">string</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-updatenotes: Update a .notes file to add a line at the first blank line
- USAGE: xs-ldas-updatenotes [notesfile] [line-to-add]
- EXAMPLE: xs-ldas-updatenotes 006-991231.notes VIDEO_RESOLUTION 4.3
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-updatenotes2"><a href="#CODE">&#8679</a> xs-ldas-updatenotes2</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-updatenotes2: Update a .notes file to replace an XML section
USAGE: xs-ldas-updatenotes2 [old] [section] [new]
	[old]: input file
	[section]: name of section to be replaced
	[new]: file with replacement text- including the XML tags
- if [section] is not found, [new] will just be appended to the end of the file
EXAMPLE: xs-ldas-updatenotes2 20181231.notes CHANNELS new.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-XLASER1"><a href="#CODE">&#8679</a> xs-ldas-XLASER1</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-XLASER1: analyze laser-stimulated behaviour, ERPs, and evoked oscillations
ANALYSES:
	- behavioural latencies
		- looks for TRIAL "latency" column in the .notes file
		- if present, this is used to re-define "start" for each trial
/opt/LDAS/xs-ldas-XLASER1: line 69: ECHO: command not found
USAGE: xs-ldas-XLASER1 [base] [options]
	[base]: [yyyymmdd]-[session]_[subject]

GENERAL OPTIONS...
	--regions: CSV list of brain-regions to analyse [all]
	--plot: generate plots (0=NO,2=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

OPTIONS FOR xs-ldas-pow1/coh1 FOR ALTERING START-STOP PAIRS:
	--trials: CSV list of trial-names to use (or "all" or "no") [all]
	--align: redefine start & stop as one or the other (start|stop) [start]
		NOTE: if set, use --pre or --post to make non-zero-length trials
	--pre: seconds to add to start [-2]
	--post: seconds to add to stop [5]
	--fhi: high-freq. cut (smooth) for power-timecourse (0=NONE) [10])
BAND OVERRIDE OPTIONS - specify comma-separated start-stop pairs...
	--delta: [.5,4]
	--alpha: [4,6]
	--theta: [6,12]
	--beta: [12,30]
	--gamma: [30,100]
	--hfo: [120,150]
EXAMPLE: 
	xs-ldas-XLASER1 20181231-000_12345 2&#62&1 | tee log_xs-ldas-XLASER1.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-XLASER1b"><a href="#CODE">&#8679</a> xs-ldas-XLASER1b</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-XLASER1b: batch-run xs-ldas-XLASER1
USAGE: xs-ldas-XLASER1b [db] [options]
	[db]: database file specifying path and group on each line
VALID OPTIONS (defaults in []):
	--opt1: quoted options to pass to xs-ldas-XLASER1 []
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
...options for by-date plots
	--norm: normalisation (see xe-normrow2) [-1]
	--n1: start of normalisation zone (week-number)) [0]
	--n2: end of normalisation zone (week-number) [1]
EXAMPLE: 
	xs-ldas-XLASER1b db_all.txt  2&#62&1 | tee log_xs-ldas-XLASER1b.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-ldas-zipexpt"><a href="#CODE">&#8679</a> xs-ldas-zipexpt</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas-zipexpt: compress LDAS experiment folder structure to .zip files
USAGE: 
	xs-ldas-zipexpt [options]
VALID OPTIONS:
	-a: zip Data_Acquired folder (raw data from acquisition systems)
	-l: zip Data_Library folder  (LDAS-formatted Data folders)
	-w: zip Data_Working folder  (links to Data_Library for working-output)
	-y: zip Analysis folder
	-d: delete each folder after zipping
EXAMPLE: 
	xs-ldas-zipexpt -alwyd
OUTPUT: 
	LDAS_Data_Acquired.zip
	LDAS_Data_Library.zip
	LDAS_Data_Working.zip
	LDAS_Analysis.zip
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-makelink1"><a href="#CODE">&#8679</a> xs-makelink1</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-makelink1: build working directories with symbolic links to original files
- this keeps the originals safe but accessible from the working directories
- run this script in directory above both [source] and [dest] (see below)
USAGE: xs-makelink1 [source] [dest] [options]
	[source]: path to sub-directories containing files to be linked
	[dest]:   path to desired destination working-directories
VALID OPTIONS (defaults in []):
	--patterns: quoted list of file-patterns to match, or BASE [BASE]
		- wildcards added to each item in the list
			- eg. .dat becomes *.dat*
		- if blank (""), all files will be matched
		- "BASE" will match the 2-field directory basename
			- typical fields are date and subject
			- permitted delimiters are "-" or "_"
			- examples: 
				123-20171031
				103199_007
			- files in directory must match both fields
			- files can have extra sub-elements delimited
			- sub-elements can be delimited by "-" or "_"
			- eg directory 123_999 will match file 123-0_999.1.dat
	--verb: verbose output (0=NO 1=YES) [0]
EXAMPLES: 
	xs-makelink1 Data_Library Data_Working
	xs-makelink1 Data_Library Data_Working --patterns "BASE"
	xs-makelink1 Data_Library Data_Working --patterns ""
	xs-makelink1 Data_Library Data_Working --patterns ".bin .notes"
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-makesignal1"><a href="#CODE">&#8679</a> xs-makesignal1</h3></font>
[<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-makesignal1: make an LFP-like signal with delta, theta and gamma oscillations

USAGE: 
	xs-makesignal1 [dur] [rate]
		[dur]: duration of signal (seconds)
		[rate]: sample-rate of signal (samples/second)

OPTIONS (in quotes) to be passed to xe-makedata1: 
	-D: delta options [-a 200.0 -f 02 -fsd 0.1]
	-T: theta options [-a 100.0 -f 08 -fsd 1.0]
	-G: gamma options [-a 50.0 -f 75 -fsd 8.0]
	-N: noise options [-a 0 -n 50 -g 1]
		two noise signals will be added:
		1) the noise specified by the user
		2) a 10x version of the noise, HP filtered at 20 Hz
	-E: event options []
	-B: event band (d,t,g) [g]

EXAMPLE: 
	xs-makesignal1 20 2000 -G "-a .05 -fsd 20" -N "-n 0" 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-makesignal2"><a href="#CODE">&#8679</a> xs-makesignal2</h3></font>
[<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-makesignal2: make multi-frequency signal for testing filters etc.
- makes a temp file for each frequency (at base sampling-rate, below)
- then filters at Nyquist freq. for final output
- then decimates the signal to bring it to the desired sampling rate
- then sends the sum of all the individual signals to the output file
USAGE: 
	xs-makesignal2 [dur] [rate] [OPTIONS]
		[dur]: duration of signal (seconds)
		[rate]: sample-rate of signal (samples/second)

OPTIONS (in quotes) to be passed to xe-makedata1: 
	-b: base sampling-rate [500000]
	-h: highest frequency to prodce [ [rate]/2 ]

EXAMPLE: 
	xs-makesignal2 20 2000 -h 100
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-manual"><a href="#CODE">&#8679</a> xs-manual</h3></font>
[<a href="#tag-programming">programming</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-manual: view (default) or make LDAS manuals
USAGE: xs-manual [manual] [options]
	available manuals: 
		ldas
		git
		taini
		mea
		laser
		hargreaves
VALID OPTIONS (defaults in []):
	--view: view manual in terminal,pdf,html [terminal]
		NOTE: only "terminal" will work if logging in remotely
	--make: make different-format manual from .md original []
		Format choices: pdf,html
		NOTE: setting --make cancels viewing
EXAMPLE: 
	xs-manual ldas --view terminal
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-match"><a href="#CODE">&#8679</a> xs-match</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-match: determine if a word is a member of a list
- USAGE: xs-match [word] [list]
	[word]: word to be matched (no spaces)
	[list]: list of words to be checked against
- EXAMPLE: xs-match 3  1 2 3 4 5 6 
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-amp1"><a href="#CODE">&#8679</a> xs-MEA-amp1</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-amp1:(MEA) normalized event-amplitude changes across time, all channels
- requires a .notes file in folder defining recording parameters
USAGE: 
	xs-MEA-amp1 [base] [map]
		[base]: input file basename - assumes directory contains:
			[base].clubt: binary (64-bit int) sample-numbers
			[base].club:  binary (16-bit int) channel-numbers
		[map]: text file describing electrode layout. Example:

			11 21 31 41 51 61 71 81
			12 22 32 42 52 62 72 82
			13 23 33 43 53 63 73 83
			14 24 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88

ADDITIONAL ARGUMENTS:
	-b: size of the block (seconds) to integrate amplitude [60]
	-d: trial duration (if unset, default = time of last event) []
	-o: output file prefix [amp1]
	-g: Gaussian smoothing (plot only, bins apply to time [0]
	-n: normalization [1]
		-1: no normalization
		0: 0-1 range
		1: Z-score (mean & std.dev of normalization trial)
		2: change from sample-0 of normalization trial
		3: change from mean of normalization trial
		4: %change from mean of normalization trial
	-N: normalization trial (name contains) []
	-P: plot options, in quotes []

EXAMPLE: 
	xs-MEA-amp1 20180101_000001 map_chans.txt -g 10 -b 40 -N aCSF -n 4

--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-detect1"><a href="#CODE">&#8679</a> xs-MEA-detect1</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-detect1: detect events in a multi-channel multi-electroode-array file
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-MEA-detect1 [in1] [in2] [map]
		[in1]: baseline data (2-byte binary signed short (16bit) interlaced)
		[in2]: data in which to detect events
		[map]: matrix specifying the layout of the channels. Example:
			11 21 31 41 51 61 71 81
			12 22 32 42 52 62 72 82
			13 23 33 43 53 63 73 83
			14 24 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88	
ADDITIONAL ARGUMENTS:
	-a: analysis to perform (detect|summary|all) [all]
	-l: filter low-cut [5]
	-h: filter high-cut [25]
	-t: peak-detect threshold [3]
	-e: edge-detect threshold [2]
	-s: sign of detection (-1,0,+1, or auto) [auto]
	-r: enforced refractory period [0]
	-c: select a channels to analyze (comma-delimited-list or "all") []
	-S: start-time (seconds) to begin analysis [0]
	-D: duration (seconds) for analysis [unset - whole trial]
EXAMPLE: 
	xs-MEA-detect1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-detect2"><a href="#CODE">&#8679</a> xs-MEA-detect2</h3></font>
[<a href="#tag-MEA">MEA</a>][<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-detect2: detect events in a multi-channel multi-electrode-array file
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-MEA-detect2 [base] [map]
		[base]: input file basename - assumes directory contains:
			[base].dat: binary 16-bit input, merged trials
			[base].ssp: binary start-stop samples delineating trials
			[base].notes: text file specifying sample-rate, trials, etc.
		[map]: matrix specifying the layout of the channels. Example:
			11 21 31 41 51 61 71 81
			12 22 32 42 52 62 72 82
			13 23 33 43 53 63 73 83
			14 24 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88	
ADDITIONAL ARGUMENTS:
	-a: analysis to perform (detect|summary|all) [all]
	-l: filter low-cut [5]
	-h: filter high-cut [25]
	-t: peak-detect threshold (std.dev - positive values only) [3]
	-e: edge-detect threshold (std.dev)[2]
	-s: sign of detection (-1,0,+1, or auto) [auto]
	-r: enforced refractory period [0]
	-c: select channels to analyze (comma-delimited-list or "all") []
	-S: start-time (seconds) to begin analysis [0]
	-D: duration (seconds) for analysis [unset - whole trial]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-MEA-detect2 20180101_000005 table_map.txt
--------------------------------------F----------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-detect2b"><a href="#CODE">&#8679</a> xs-MEA-detect2b</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-detect2b: batch-run xs-MEA-detect2
USAGE: 
	xs-MEA-detect2b [db] [map] [options]
		[db]: database file defining paths and group designations
		[map]: local electrode layout file, to be copied to directories
VALID OPTIONS (defaults in []):
	--opt1: quoted options to pass to xs-MEA-detect2 []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	nohup xs-MEA-detect2b db.txt map.txt --opt1 "-s +1" &#62 log.txt &
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-detect3"><a href="#CODE">&#8679</a> xs-MEA-detect3</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-detect3: detect events in a multi-channel multi-electrode-array file
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-MEA-detect3 [base] [map]
		[base]: input file basename - assumes directory contains:
			[base].dat: binary 16-bit input, merged trials
			[base].ssp: binary start-stop samples defining trials
			[base].notes: specifies sample-rate, trials, etc.
		[map]: matrix specifying the layout of the channels. Example:
			11 21 31 41 51 61 71 81
			12 22 32 42 52 62 72 82
			13 23 33 43 53 63 73 83
			14 24 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88	
ADDITIONAL ARGUMENTS:
	-a: analysis to perform (detect|summary|all) [all]
	-l: filter low-cut [5]
	-h: filter high-cut [25]
	-t: peak-detect threshold (std.dev - positive values only) [3]
	-e: edge-detect threshold (std.dev)[2]
	-s: sign of detection (-1,0,+1, or auto) [auto]
		-1: detect negative-going events
		+1: detect positive-going events
		0: detect +ive or -ive events, using absolute-value of data
		auto: detect +ive, -ive, then choose detection with most events
	-r: enforced refractory period [0]
	-c: select channels to analyze (comma-delimited-list or "all") []
	-S: start-time (seconds) to begin analysis [0]
	-D: duration (seconds) for analysis [unset - whole trial]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-MEA-detect3 20180101_000005 table_map.txt
--------------------------------------F----------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-hdf5"><a href="#CODE">&#8679</a> xs-MEA-hdf5</h3></font>
[<a href="#tag-MEA">MEA</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-hdf5: 
	- merge multiple Multi Channel Systems binary MEA files (.h5)
	- this script is for HDF5-format files containing spike-times and waveforms
	- requires xp-hdf5_parse1
	*** NOTE: for now assumes trials are each 600 seconds long
	*** NOTE: we need Aidan to extract the correct HDF5 file attributes 
USAGE: xs-MEA-hdf5 [pattern] [options]
	[pattern]: text to match anywhere in the filename (not wildcards)
		- at run-time, this becomes *[pattern]*
VALID OPTIONS (defaults in []):
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-MEA-hdf5  190520_2_aCSF_spikes.h5
OUTPUT: 
	output.clubt (timestamps, as samples, 64-bit integer)
	output.club (channel-number, 16-bit integer)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-merge1"><a href="#CODE">&#8679</a> xs-MEA-merge1</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-merge1: 
	- merge multiple Multi Channel Systems binary MEA files (.raw)
	- create per-channel 1000Hz .bin files
	- record the start/stop sample for each file in an SSP file
	- each input file needs a unique order-suffix
		- the suffix should come betweeen an underscore and the dot
		- examples:
			experiment1-base_001.raw
			experiment1-drugA_002.raw
			experiment1-drugB_003.raw

USAGE: xs-MEA-merge1 [pattern]
	[pattern]: text to match anywhere in the filename (not wildcards)
		- at run-time, this becomes *[pattern]*

ADDITIONAL ARGUMENTS:

EXAMPLE: 
	xs-MEA-merge1 .raw

OUTPUT: (note base-name is derived from folder name)
	source.dat
	source.ssp
	source-[channel].bin
	source.notes
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-plotflip"><a href="#CODE">&#8679</a> xs-MEA-plotflip</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-plotflip: make a multi-page "flip-book" of MEA event plots
 - default is to select 100 events for plotting
 - requires .notes, .dat, and .club/t files
USAGE: xs-MEA-plotflip [base] [options]
	[base]= base-name for files in this folder - typically [yyymmdd]]_[subject]

VALID OPTIONS, defaults in []:
	--max: max events to plot (-1=all) [100]
	--chan: channel to use [21]
	--trial CSV list of trial-numbers to read (or "all") [all]
	--win: window-size (seconds) [0.2]
	--notch: 50Hz notch filter width, in Hz (0=off, 1-2 recommended) [5]
	--low: filter low-cut [5]
	--high: filter high-cut [25]
	--out: name of output file [PLOTFLIP.ps]
	--plotopts: extra plot options (see xe-plottable1) []
	--verb: verbose output (0=NO 1=YES) [1]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-MEA-plotflip 20180101_000005
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-pow1"><a href="#CODE">&#8679</a> xs-MEA-pow1</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-pow1:(MEA) spectral power analysis
USAGE: 
	xs-MEA-pow1 [base] [map]
		[base]: input file basename - assumes directory contains:
			[base].dat: multi-channel binary (16-bit int) voltage values
			[base].clubt: binary (64-bit int) sample-numbers
			[base].club:  binary (16-bit int) channel-numbers
		[map]: text file describing electrode layout. Example:

			11 21 31 41 51 61 71 81
			12 22 32 42 52 62 72 82
			13 23 33 43 53 63 73 83
			14 24 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88	

ADDITIONAL ARGUMENTS:
	-b: size of the block (seconds) to integrate amplitude [60]
	-d: trial duration (if unset, default = time of last event) []
	-o: output file prefix [pow1]
	-g: Gaussian smoothing (plot only, bins apply to time [0]
	-n: normalization [1]
		-1: no normalization
		0: 0-1 range
		1: Z-score (mean & std.dev of normalization trial)
		2: change from sample-0 of normalization trial
		3: change from mean of normalization trial
		4: %change from mean of normalization trial
	-N: normalization trial (name contains) []
	-P: plot options, in quotes []

EXAMPLE: 
	xs-MEA-pow1 20180101_000001 map_chans.txt -g 10 -b 40 -N aCSF -n 4

--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-rate1"><a href="#CODE">&#8679</a> xs-MEA-rate1</h3></font>
[<a href="#tag-MEA">MEA</a>][<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-rate1:(MEA) normalized event-rate changes across time, all channels
- requires a .notes file in folder defining recording parameters
USAGE: 
	xs-MEA-rate1 [base] [map]
		[base]: input file basename - assumes directory contains:
			[base].clubt: binary (64-bit int) sample-numbers
			[base].club:  binary (16-bit int) channel-numbers
		[map]: electrode layout file. "--" = skipped channel. Example:

			11 21 31 41 51 61 71 81
			12 22 32 42 52 -- 72 82
			13 23 33 43 53 63 73 83
			14 -- 34 44 54 64 74 84
			15 25 35 45 55 65 75 85
			16 26 36 46 56 66 76 86
			17 27 37 47 57 67 77 87
			18 28 38 48 58 68 78 88	

ADDITIONAL ARGUMENTS:
	-b: size of the block (seconds) to integrate rate [60]
	-d: trial duration (if unset, default = time of last event) []
	-o: output file prefix [RATE1]
	-g: Gaussian smoothing (plot only, bins apply to time [0]
	-n: normalization [1]
		-1: no normalization
		0: 0-1 range
		1: Z-score (mean & std.dev of normalization trial)
		2: change from sample-0 of normalization trial
		3: change from mean of normalization trial
		4: %change from mean of normalization trial
	-N: normalization trial (name contains) []
	--end: minutes to use for final AUC calculation [5]
	--P1: set line-graph plot options, in quotes []
	--P2: set matrix plot options, in quotes []

EXAMPLE: 
	xs-MEA-rate1 20180130_0000123 map_chans.txt -g 10 -b 40 -N aCSF -n 4

--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-rate1b"><a href="#CODE">&#8679</a> xs-MEA-rate1b</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-rate1b: batch-run xs-MEA-rate1
USAGE: 
	xs-MEA-rate1b [db] [map] [options]
		[db]: database file defining paths and group designations
		[map]: name of layout file in directories (bad channels ="-")
VALID OPTIONS (defaults in []):
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--opt1: quoted options to pass to xs-MEA-rate1 []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	nohup xs-MEA-rate1b db.txt map.txt --opt1 "-s +1" &#62 log.txt &
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-MEA-xcor1"><a href="#CODE">&#8679</a> xs-MEA-xcor1</h3></font>
[<a href="#tag-MEA">MEA</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-MEA-xcor1:(MEA) compare event-rate in first and last data-block

USAGE: 
	xs-MEA-xcor1 [.clubt] [.club] [map]

	[.clubt]: binary file (64-bit int) holding time (sample-numbers)
	[.club]: binary file (16-bit int) holding matching channel IDs
	[map]: text file describing electrode layout. Example:

		11 21 31 41 51 61 71 81
		12 22 32 42 52 62 72 82
		13 23 33 43 53 63 73 83
		14 24 34 44 54 64 74 84
		15 25 35 45 55 65 75 85
		16 26 36 46 56 66 76 86
		17 27 37 47 57 67 77 87
		18 28 38 48 58 68 78 88	

ADDITIONAL ARGUMENTS:
	-s: sample-rate (Hz) [1000]
	-b: size of the block (seconds) to integrate rate [600]
	-d: trial duration (if unset, default = time of last event) []
	-o: output file prefix [temp_xs-MEA-xcor1]

EXAMPLE: 
	xs-MEA-xcor1 output.clubt output.club map.txt -b 600

OUTPUT: 
	[prefix]_matrix1.txt	# rates in first block
	[prefix]_matrix2.txt	# rates in last block
	[prefix]_matrix3.txt	# difference (last-first)
	[prefix]_summary.001.ps	# summary plot
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-noise1"><a href="#CODE">&#8679</a> xs-noise1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-noise1: Calculate the noise-ratio in a time-series 
USAGE: 
	xs-noise1 [infile]
ADDITIONAL ARGUMENTS:
	-t: data type [R]
		T: ASCII text file
		R: SCORE raw file
	-d: duration of data to use (seconds) [3600]
	-f: sampling frequency (Hz) [400]
	-w: FFT window size (seconds) [10]
	-s: FFT step (window overlap) [1]
	-n: normalize? (-1=NO 1=YES) [1]
EXAMPLE: 
	xs-noise1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-blockcurve1"><a href="#CODE">&#8679</a> xs-O2-blockcurve1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-blockcurve1: calculate stats and plots for individual curves
	- that is, each subject, group and block
	- also produces mean curves for each group/block
	- reads output of _xs-O2-X1b (X1_aligned.txt)

USAGE: 
	xs-O2-blockcurve1 [infile] [mult]
		[infile]: output of _xs-O2-X1b (X1_aligned.txt)
			format: [subject] [group] [block] [time] [value]
		[mult]: multiplier for time values to determine decimal precision

EXAMPLE: 
	xs-O2-blockcurve1 X1_aligned.txt

OUTPUT:
	blockcurve_[block].txt: all the curves for a given block
		format: [subject] [group] [block] [time] [value]
	blockcurve_stats.txt: statistics on each curve
	blockcurve_[block]_gmeans.txt: group means for the above
		format: [group] [time] [mean-value] [SEM]
	blockcurves_summaryA.001.ps: plot of avg. curves for each block
	blockcurves_summaryB.001.ps: plot of mean stats across blocks
	blockcurves_summaryC.001.ps: as above but within-subject delta scores
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-checkchansb"><a href="#CODE">&#8679</a> xs-O2-checkchansb</h3></font>
[<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-checkchansb: check channels for a brain region in database
Only analyzes the hemisphere specified in the database file
Will flag channels for which:
	- more than 80% of the data are at the limits or invalid
	- RMS power is &#601.5 s.d.. below the mean (dead channel?)
	- RMS power is &#623.0 s.d. above the mean (noisey channel?)
		- mean RMS power is corrected for outliers first
		- excludes data &#6299th percentile
		- also flags any channel if RMS power &#60 1.0
REQUIRES: a .notes file in each data directory
		- CHANNEL record format: CHANNEL no. label hemis region	bottom top %good power
USAGE: xs-O2-checkchansb  [database] [region] [options]
	[database]: database file to read
	[region]: brain region of interest
VALID OPTIONS (defaults in brackets):
		-m sets minimum RMS accepted [1.0]
		-l sets lower threshold std.dev in RMS [1.5]
		-u sets upper threshold std.dev in RMS [3.0]
EXAMPLE: xs-O2-checkchansb database_DHIPP.db  DHIPP -m 2
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-checktxt"><a href="#CODE">&#8679</a> xs-O2-checktxt</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-checktxt: check validity of CHART export files
---------------------------------------------------------
USAGE: xs-O2-checktxt [source] [hem] [region]
	[source]: full path to folder with CHART export files
	    NOTE: files must match pattern [num]-[yymmdd].txt
	    where [num] is 3-digits, eg. 019-991231
	[hem]: comma-separated hemispheres (L,R) to be used
	[reg]: comma-separated regions to be used
	    NOTE: [hem] and [reg] are used to make sure all
	    regions and hemispheres are in the channel labels
EXAMPLE: 
	xs-O2-checktxt /media/UDISK/data/  L,R  HIPP,ACC
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-copycomments"><a href="#CODE">&#8679</a> xs-O2-copycomments</h3></font>
[<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-copycomments: Copy comments from channel 001 to all other.cmt files
Usefull if there are only comments in the first channel
USAGE: xs-O2-copycomments [database]
EXAMPLE: xs-O2-copycomments all.db
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-COR1"><a href="#CODE">&#8679</a> xs-O2-COR1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-COR1: calculate correlation between two channels at a range of frequencies
- data is first padded, filtered for each frequency, and trimmed
- a sliding window (2x wavelength) is used to correlate filtered data
- finally the correlation values are averaged for chunks of the record (max 6)

 USAGE: xs-O2-COR1 [dat1] [dat2] [options]
	[dat1]: 2-column file containing time & data for the first channel
	[dat2]: 2-column file containing time & data for the second channel
OPTIONS:
	-l: lowest frequency in the series [0.01]
	-u: highest frequency in the series [0.1]
	-i: frequency incriment between -l and -u (above) [0.005]
	-a: time interval for plots [1]
EXAMPLE: xs-O2-COR1 X1-NAc_average.txt X1-PFC_average.txt -l .01 -u .1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-COR1b"><a href="#CODE">&#8679</a> xs-O2-COR1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-O2-COR1b: calculate and collate correlation between probes for whole database
- calls xs-O2-COR1
- adds subject and group columns
USAGE: xs-O2-COR1b [database] [in1] [in2] [opts]
	[database]: name of the database (.db) file to use
	[in1]: name of input file for region1, containing &#60time&#62 and &#60data&#62
	[in2]: name of input file for region2, containing &#60time&#62 and &#60data&#62
OPTIONS:as for xs-O2-COR1:
	-l: lowest frequency in the series [0.01]
	-u: highest frequency in the series [0.1]
	-i: frequency incriment between -l and -u (above) [0.005]
	-a: time interval for plots and binned broadband data [1]
	-d: diagnostic mode (0=re-analyze each subject, 1=re-collate) [0]

	OPTIONS APPLIED DURING COLLATION OF MATRIX DATA FROM INDIVIDUAL SUBJECTS
	-s: smoothing factor (turn on smoothing)
		: value = seconds on x-axis
		: smoothing on y-axis = 1/10 frequency range
	-f: apply Fisher's transform to correlation matrix

	OPTIONS APPLIED TO ALL MATRIX PLOTS
	-v: vertical lines (comma-separated, no spaces)
	-h: horizontal lines (comma-separated, no spaces)
	-y: colour scaling: value reprented by black [-1.0]
	-z: colour scaling: value reprented by red [1.0]

	OPTIONS APPLIED TO MATRIX DIFFERENCE PLOTS
	-t: difference plot type (1=diff,2=ratio,3=t-statistic) [1]
	-r: repeated-measures design? (0=NO, 1=YES) [1]
		0. assumes each subject has a unique group ID
		1. assumes subjects are members of multiple groups
		- cohereograms for each subject subtracted from a reference
		- the reference group is defined with the -g option
	-g: reference group (subtracted from others) [0]
	-p: probability threshold for plotting [0.05]

EXAMPLE: xs-O2-COR1b db_NAc.txt X1-NAc_aligned.txt X1-PFC_aligned.txt -a 300
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-COR2b"><a href="#CODE">&#8679</a> xs-O2-COR2b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-COR2b: Run xs-O2-X1b and xs-O2-COR1b on a dataset for correlation analysis
- designed to analyse two brain regions
USAGE: 
	xs-O2-COR2b [db1] [db2] [reg1] [reg2] "[X1opts]" "[COR1opts]" [options]
		[db1]: datbase for region 1
		[db2]: datbase for region 2
		[reg1]: name of region 1
		[reg2]: name of region 2
		[options]: additional options:
			-X [opts1]: options (in quotes) for xs-O2-X1b
			-C [opts2]: options (in quotes) for xs-O2-COR1
			-S [opts3]: options (in quotes) for xs-O2-CORSUMMARIZE1
			-M [opts4]: options (in quotes) for summary matrix plots
			-T: tag for output filenames (renames output to save results) []
			-A: analysis (X1, COR1 or ALL) [ALL]
EXAMPLE: 
	xs-O2-COR2b  dbNAC.txt dbHIP.txt  dbPFC.txt dbRSC.txt  HPC PFC -X "-s Inj1 -d 900"  -C "-a 300" -S _tr1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-COR4b"><a href="#CODE">&#8679</a> xs-O2-COR4b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-COR4b: Run xs-O2-X1b and xs-O2-COR1b on a dataset for correlation analysis
- designed to analyse all possible combinations of four brain regions
USAGE: 
	xs-O2-COR4b [db1] [db2] [db3] [db4] [reg1] [reg2] [reg3] [reg4] "[X1opts]" "[COR1opts]" [options]
		[db1]: datbase for region 1
		[db2]: datbase for region 2
		[db3]: datbase for region 3
		[db4]: datbase for region 4
		[reg1]: name of region 1
		[reg2]: name of region 2
		[reg3]: name of region 3
		[reg4]: name of region 4
		[options]: additional options:
			-X [opts1]: options (in quotes) for xs-O2-X1b
			-C [opts2]: options (in quotes) for xs-O2-COR1
			-S [opts3]: options (in quotes) for xs-O2-CORSUMMARIZE1
			-M [opts4]: options (in quotes) for summary matrix plots
			-T: tag for output filenames (renames output to save results) []
			-A: analysis (X1, COR1 or ALL) [ALL]
EXAMPLE: 
	xs-O2-COR4b  dbNAC.txt dbHIP.txt  dbPFC.txt dbRSC.txt  NAC HPC PFC RSC  -X "-s Inj1 -d 900"  -C "-a 300" -S _tr1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-CORSUMMARIZE1"><a href="#CODE">&#8679</a> xs-O2-CORSUMMARIZE1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-CORSUMMARIZE1: Summarize a transposed data file from xs-O2-COR1b
USAGE: 
	xs-O2-CORSUMMARIZE1 [infile] [block1] [block2] [block3] etc.
		[infile]: transposed summary output from xs-O2-COR1b
		[block1]: comma-separated list of columns to average
			format: label,col1,col2,col3,etc
				label: block category (eg. task, or rest) 
				col#: header for the column, eg. r_300
			note: data is averaged within, and across, blocks with the same label
ADDITIONAL ARGUMENTS:
EXAMPLE: 
	xs-O2-CORSUMMARIZE1 COR1.txt  task,r_300,r_600  rest,r_900,r_1200  task,r_1500,r_1800
OUTPUT:
	- the original input data
	- the average for each block, headered [block]_[label]
	- the average for each label, headered m_[label]
	- the average for label within each group
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-DIF1b"><a href="#CODE">&#8679</a> xs-O2-DIF1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-DIF1b: Run xs-O2-X1b for two start-signals and get response-difference
USAGE: 
	xs-O2-DIF1b [db] [reg] [start1] [start2] "[X1opts]"
		[db]: datbase file
		[reg]: name of region
		[start1]: start signal for blocks to be used as reference
		[start2]: start signal for blocks of responses of interest
			NOTE: result = start2_curve - start1_curve
		[reg]: name of region
		[X1opts]: options (in quotes) for xs-O2-X1b
EXAMPLE: 
	xs-O2-DIF1b  db_NAc_L.txt NAc CSy CSn "-d 30" 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-EVENT1"><a href="#CODE">&#8679</a> xs-O2-EVENT1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>][<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-EVENT1: detect & characterize transient events in a time series
	Specifically designed for very slow (minutes) events, this program uses
	Data is interpolated first to remove non-finite or non-numeric entries
	Box-car smoothing and de-meaning may be used instead of a Butterworth filter
		(sometimes more stable for analyzing very low-frequencies)
USAGE: xs-O2-EVENT1 [base] [hem] [region] [options]
	[base]: base-name [subject]-[yymmdd]
	[hem]: hemisphere (L or R)
	[region]: brain region (e.g. DHIPP, MPFC)
		Note: [hem] & [region] are matched against .notes file
		CHANNEL records to identify the correct .dat file for that channel
	[options] (defaults in []) :
		-i: shortest event (seconds) to detect [60]
		-j: longest event (seconds) to detect [600]

		-t: detection threshold (standard deviations) [1.5]
		-u: upper limit for event peak (standard deviations) [1000]
		-e: detection for edges of events (fraction of -t) [0.5]
		-g: sign of threshold (-1=neg, 1=pos, 0=either) [1]
		-z: convert data to Z-scores for detection (0=NO 1=YES) [1]

		-s: unique start-signal dividing pre- and post-analysis blocks [Start]
		-p: (lower-case) pre-start time to analyze (seconds) [10]
		-d: post-start time to analyze (seconds) [10]

		-f: low-cut filter method (0=Butterworth, 1=boxcar de-mean) [1]
		-F: high-cut filter method (0=Butterworth, 1=boxcar smooth) [0]
		-h: high-cut frequency (0=auto, determined by -i) [0]

		-P: (upper-case) plot the data (0=NO 1=YES) [1]
EXAMPLE: 
	xs-O2-EVENT1 rat002-101116 R MPFC -s Inj1 -p 7200 -d 7200 -t 1 
OUTPUT: average response curve in format [time] [value]
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-EVENT1b"><a href="#CODE">&#8679</a> xs-O2-EVENT1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-O2-EVENT1b: calculate and collate event-detection across subjects
- calls xs-O2-EVENT1
- adds subject and group columns
USAGE: xs-O2-EVENT1b [database] [region] [analysis] [opts]
	[database]: name of the database (.db) file to use
	[region]: brain region (e.g. DHIPP, MPFC)
	[analysis]: analysis to perform (all, collate, or test)

	[options] (run xs-O2-EVENT1 to see defaults) :

		-i: shortest event (seconds) to detect
		-j: longest event (seconds) to detect
		-h: high freq. filter cutoff (0=auto, determined by -i)
		-t: detection threshold (standard deviations)
		-u: upper limit for event peak (standard deviations)
		-e: detection for edges of events (fraction of -t)
		-g: sign of threshold (-1=neg, 1=pos, 0=either)
		-z: convert data to Z-scores for detection (0=NO 1=YES)

		-s: unique start-signal dividing pre- and post-analysis blocks
		-p: pre-start time analyze (seconds)
		-d: post-start time to analyze (seconds)

		-P: (upper-case) plot the data in each subfolder(0=NO 1=YES)

	run xs-O2-EVENT1 for more information on options)

EXAMPLE: xs-O2-EVENT1b db_good1.txt all MPFC -s Inj1 -p 7200 -d 7200 -g 1 -t 1
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-makelink"><a href="#CODE">&#8679</a> xs-O2-makelink</h3></font>
[<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-O2-makelink: build working directories for O2-amperometry experiments
This keeps the pre-processed data safe by providing access via links
Links created to files in Data_Library folder: 
	.notes file (data relating to the entire recording session)
	.time file (timestamps)
	.dat file (one for each channel - the raw data, ASCII txt)
	.cmt files (one for each channel - comments associated with the channel)
USAGE: xs-O2-makelink [source] [dest] [pattern]
	[source]: folder containing sub-folders with files to be linked
	[dest]: folder in which to build links to source folders and files
	[pattern]: pattern to match for names of subfolders in source
EXAMPLE: xs-O2-makelink Data_Library/ Data_Working/ rat-
EXAMPLE: xs-O2-makelink Data_Library/ Data_Working/ "*"
EXAMPLE: xs-O2-makelink Data_Library/ Data_Working/ "???-??????"
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-makex5b"><a href="#CODE">&#8679</a> xs-O2-makex5b</h3></font>
[<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-makex5b: set up experiment directories & transfer data
---------------------------------------------------------
- creates Analysis, Data_Library, & Data_Working folders
- copies data from remote location to Data_Library
- only newer versions of files will be copied
- extracts the [base].txt file to .time .dat .cmt and .notes files
- creates a plot of the traces for each channel
- most problems with the data or folder locations reported immediately
- other reports will go to the log file: /opt/LDAS/source/log_xs-O2-makex5b_200212.txt
- for each subject-date...
		xs-ldas-preproc1
			xe-ldas-readchart1
- then...
		xs-O2-makelink
		xs-dbmake1
		xs-O2-copycomments
		xs-plotcollate
		xs-O2-checkchansb

USAGE: xs-O2-makex5b [source] [options]
	[source]: full path to folder with CHART export files
		NOTE: files must match pattern [num]-[yymmdd].txt
		where [num] is 3-digits, eg. 019-991231
	[options]: general
		-c: copy comments from channel-1 to other channels (unset by default)
	[options]: to control diagnostics
		-w: window-size (s) to calc. RMS power on channels (default 4)
		-b: bottom of y-axis for diagnostic plots (default -500)
		-t: top of y-axis for diagnostic plots (default 0)
		-a: autoscale y-axis (overrides -b and -t) (unset by default)
		-u: time-units (hour,min,sec,ms) for diagnostic plots (default min)
		...diagnostic plotmarkers...
		-s:	start signal from comment file
		-d:	time after start signal
		-p: time before start signal
EXAMPLE: 
	xs-O2-makex5b /media/UDISK/data/ -c 
	xs-O2-makex5b /media/UDISK/data/ -w 4 
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-makex6b"><a href="#CODE">&#8679</a> xs-O2-makex6b</h3></font>
[<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>--------------------------------------------------------------------------------
xs-O2-makex6b: extract data from CHART export files (tab delimited text)
Converts multiple CHART export files (.txt) to an LDAS database
	- files must be exported from CHART as tab-delimited text
Generates folder structure to hold database at output location
Default output path is just above the directory holding .txt files
For each CHART file:
	- date is derived from a 6-digit yymmdd field in the filename
	- file name should have fields separated by hyphens
	- sample-frequency is determined from the intervals in the Time column
	- header defines Channel Titles and number of channels
	- header defines Channel Ranges
Channel Titles (tab-separated, each title has no spaces) 
	- must have 3 underscore-separated fields, eg. 001_R_MPFC
	- field#1 defines 3-digit subject id, zero-padded (eg. 001)
	- field#2 defines single-character hemisphere (L or R)
	- field#3 defines brain region (free form, but no spaces or tabs)
For each Channel:
	- generate a basename using the date from the .txt filename (sub-yymmdd)
	- extracts time data and comments to files with the appropriate basename
	- numbers channels according to order of appearance for a given subject
	- calculates % of good points (where NAN indicates signal clipping)
	- automatically interpolates data across NANs
	- calculates the window-integrated RMS power - finds outliers

USAGE: xs-O2-makex6b [pattern] [options]
	[pattern]: pattern to match for CHART files in current directory
		- can be a single file name, a file list, or may use wildcards
		- if a list or wildcards are used, should be quoted
		- eg. files ending in a hyphen, 6 digits and .txt: "*-??????.txt"
	[options]:
		-f: hyphen-separated filename field containing date [3]
		-c: flag: copy comments from chan.1 to other channels [unset]
		-w: window (sec) used to calc. RMS power [4]
	[extra plot options]:
		-b: bottom of y-axis for diagnostic plots [-500]
		-t: top of y-axis for diagnostic plots [0]
		-a: flag: autoscale y-axis (overrides -b and -t) [unset]
		-u: time-units (hour,min,sec,ms) for diagnostic plots [min]
		...plotmarkers...
		-s: start signal from comment file [unset]
		-d: time after start signal [unset]
		-p: time before start signal [unset]

EXAMPLE: xs-O2-makex6b "*-??????.txt" -ca -w 4

OUTPUT: 
	Log file (eg)... 
		log_xs-O2-makex6b_2020_02_12
	LDAS database containing...
		[base].notes file summarizing recording prameters
		[base].time file holding the timestamps
		[base].[chan].dat files holding the data for each channel
		[base].[chan].cmt files holding the comments for each channel
		[base]-rawplot.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-plot1"><a href="#CODE">&#8679</a> xs-O2-plot1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-plot">plot</a>][<a href="#tag-O2">O2</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-plot1: plot the O2-sensing .dat files
USAGE: xs-O2-plot1 [base] [max] [u] [options]
	[base]: base name (subject-date)
	[max]: maximum number of points to plot
		- if exceeded, every nth point will be output
		- if set to 0, all points will be output
	[u]: units for time (assuming default is seconds)
		- options: hour min sec ms
	[options]: optional arguments for _xe-plottable1
EXAMPLE: xs-O2-plot1 001-091231.txt 0 sec  -ymax 100
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-plot1b"><a href="#CODE">&#8679</a> xs-O2-plot1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-plot1b: batch-plot & collate raw data files
USAGE: xs-O2-plot1b [database] [max] [u] [options]
	[database]: database file
	[max]: maximum number of points to plot
		- if exceeded, every nth point will be output
		- if set to 0, all points will be output
	[u]: units for time (assuming default is seconds)
		- options: hour min sec ms
	[options]: optional arguments for _xe-plottable1
EXAMPLE: xs-O2-plot1b 001-091231.txt 0 sec  -ymax 100
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-plotaligned2"><a href="#CODE">&#8679</a> xs-O2-plotaligned2</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-plotaligned2: plot a pair of aligned O2-amperometry data files (X1_aligned.txt)
REQUIRES:
USAGE: 
	xs-O2-plotaligned2 [in1] [in2] [freq] [low] [high] [plotopts]
		[in1]: aligned file 1
		[in2]: aligned file 2
		[freq]: sampling frequency (samples/s)
		[low]: filter low-cut (0 = none)
		[high]: filter high-cut (0 = none)
		[plotpots]: options for xe-plottable1
ADDITIONAL ARGUMENTS:
EXAMPLE: 
	xs-O2-plotaligned2 X1-HIP_aligned.txt X1-ACC_aligned.txt .01 .1 -xscale 1 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-POW1"><a href="#CODE">&#8679</a> xs-O2-POW1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-POW1: calculate spectral amplitude for O2 recordings
REQUIRES: a .notes file defining sample rate amd probe locations
USAGE: 
	xs-O2-POW1 [base] [region] [options]
		[base]: sub-yymmdd (e.g. 005-991231)
		[region]: brain region to analyze - must be unique
VALID OPTIONS:
	-c specify a comment file containing window start-times []
		- default (unset) is to analyze the entire file
		- set to "auto" to use the .cmt file for the session
	-s (-start) start signal in comment file to align windows to []
	-p (-pre) time (s) to capture before the start-signal [0]
	-d (-post) time (s) to capture after the start-signal []
		NOTE: pre + post should be &#62 FFT window (-w, below)
	-n notch filter - comma-separated list of frequencies to remove []
	-w: FFT window size (seconds) [1]
	-F: additional FFT options for xe-fftpow2, in quotes []

EXAMPLE: 
	xs-O2-POW1 001-991231 R_PRL -x .3 -c auto -s _CORRECT -p 10 -d 0 
OUTPUT: 
	.fft
		the FFT output: [freq] [amplitude]
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-POW1b"><a href="#CODE">&#8679</a> xs-O2-POW1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-POW1b: batch-calculate spectral amplitude for O2 recordings
REQUIRES: a properly formatted .notes file
USAGE: 
	xs-O2-POW1b [db] [region] [options]
		[db]: database file in format [path] [group]
		[region]: brain region to analyze - must be unique
VALID OPTIONS:
	-c specify a comment file containing window start-times []
		- default (unset) is to analyze the entire file
		- set to "auto" to use the .cmt file for the session
	-s (-start) start signal in comment file to align windows to []
	-p (-pre) time (s) to capture before the start-signal [0]
	-d (-post) time (s) to capture after the start-signal []
		NOTE: pre + post should be &#62 FFT window (-w, below)
	-w: FFT window size (seconds) [1]
	-F: additional FFT options for xe-fftpow2, in quotes []

EXAMPLE: 
	xs-O2-POW1b 001-991231 R_PRL -x .3 -c auto -s _CORRECT -p 10 -d 0 
OUTPUT: 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-preproc1"><a href="#CODE">&#8679</a> xs-O2-preproc1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-preproc1: extract data from a CHART output file (tab delimited text)
Converts the CHART output to Unix/Linux format (strips CR from end of each line)
Splits the CHART file into it's composite parts
Creates a .notes file with recording parameters for future reference
Calculates true mean sample-rate (Hz) for the extracted data files
	- this is to allow for possible downsampling during extraction
Extracts subject name from filename
From the CHART file header:
	- extracts the recording date (DATE)
	- extracts number of channels (N_CH)
For each channel:
	- extracts the channel label (replacing spaces with underscores)
	- only keeps last two elements of labels (hemisphere & region)
	- extracts the theoretical range
	- calculates percentage of good points (real numbers not at range limits)
	- calculates the RMS power in the signal integrated in user-defined windows

USAGE: xs-O2-preproc1 [infile] [options]
	[infile]: ascii CHART output (tab delimited) for a single subject
	[options]:
		-w: window-size (s) to calc. RMS power on channels (default 4)
		-b: bottom of y-axis for diagnostic plots (default -500)
		-t: top of y-axis for diagnostic plots (default 0)
		-a: autoscale y-axis (overrides -b and -t) (unset by default)
		-u: time-units (hour,min,sec,ms) for diagnostic plots (default min)
		...plotmarkers...
		-s:	start signal from comment file
		-d:	time after start signal
		-p: time before start signal
EXAMPLE: xs-O2-preproc1 /media/USBDRIVE/002-10111.txt -w 4
OUTPUT:
	[base].notes file summarizing recording prameters
	[base].time file holding the timestamps
	[base].dat files holding the data for each channel
	[base].cmt files holding the comments for each channel
	[base]-rawplot.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-trimtime1"><a href="#CODE">&#8679</a> xs-O2-trimtime1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-O2-trimtime1: recalculate X1 output for shorter time window
	- filter times falling outside range
	- recalculate curve statistics
	- make new plots

USAGE: 
	xs-O2-trimtime1 [prefix] [min] [max]
		[prefix]: prefix of data files to re-analyze (typically X1_)
		[min] [max]: time window to analyze

EXAMPLE: 
	xs-O2-trimtime1 X1_ -60 1800

OUTPUT: files prefixed [prefix]_trimmed_
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-X1"><a href="#CODE">&#8679</a> xs-O2-X1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-O2-X1: generate average O2-sensing response curve for a given subject
USAGE: xs-O2-X1 [base] [hem] [region] [options]
	[base]: base-name [subject]-[yymmdd]
	[hem]: hemisphere (L or R)
	[region]: brain region (e.g. DHIPP, MPFC)
		Note: [hem] & [region] are matched against .notes file
		CHANNEL records to identify the correct .dat file for that channel

	[options] (defaults in []) :

	-c specify the exact name of the comment-file to use for alignment []
		(by default, unset, and original [base].[probe].cmt file is used) 
	-i integration period for high-cutoff filtering, in seconds [10]
		- events occuring faster than this will be attenuated
		- set to zero to skip
	-j integration period for low-freqeuncy filtering, in seconds [0]
		- events occurring longer than this will be attenuated
		- set to zero to skip
	-x skip certain processing steps [-]
		p: no plots (numerical output only - good for highly dense data)

 	[options] passed to xe-ldas-align1 (converted to arguments in ():

	-s (-start) start signal (partial match, case-sensitive) [Start]
	-e (-stop) end, or stop signal (partial match, case-sensitive) []
	-a (-first) first block to use []
	-z (-last) last block to use []
	-d (-dur) block duration []
	-n (-norm) normalization [2]
	-p (-pre) presample time [10]
	-N (-pn) normalization presample time if diff. from -p [unset be default]
	-r (-pz) re-zero to start of presample [0]
	-b (-bin) averaging bin-size - aids block-averaging (0=none) [0]
	-f (-flip) invert the data on the y-axis [1]
	--rmsthresh (-rmsthresh) RMS power rejection threshold [0]
	--sdthresh (-sdthresh) std.deviation rejection threshold [0]

EXAMPLE: 
	xs-O2-X1 rat002-101116-KET01 R DHIPP -s Pump_on
OUTPUT: average response curve in format [time] [value]
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-X1b"><a href="#CODE">&#8679</a> xs-O2-X1b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-O2-X1b: calculate and collate response curves across subjects
- calls xs-O2-X1
- adds subject and group columns
USAGE: xs-O2-X1b [database] [region] [analysis] [opts]
	[database]: name of the database (.db) file. Sets path, group, & hemisphere
	[region]: brain region (e.g. DHIPP, MPFC)
	[analysis]: analysis to perform (all, collate, or test)

	[options] (defaults in []) :

	-c specify the exact name of the comment-file to use for alignment
	-i integration period for high-cutoff filtering, in seconds []
		- use this to eliminate high-frequency artefacts
	-j integration period for low-freqeuncy filtering, in seconds []
		- use this to eliminate slow drift in your signals
	-x skip certain processing steps [-]
		p: no plots (numerical output only - good for highly dense data)

 	options passed to xe-ldas-align1 (converted to arguments in ():

	-s (-start) start signal (partial match, case-sensitive)
	-e (-stop) end, or stop signal (partial match, case-sensitive)
	-a (-first) first block to use
	-z (-last) last block to use
	-d (-dur) block duration
	-n (-norm) normalization
	-p (-pre) presample time
	-N (-pn) normalization presample time if different from -p 
	-r (-sz) re-zero to start of presample
	-b (-bin) bin-size to aid block-averaging, sets new sample-interval
	-f (-flip) invert the data on the y-axis []
	--rmsthresh (-rmsthresh) RMS power rejection threshold []
	--sdthresh (-sdthresh) rejection threshold (multiple of total std.dev) [-1]

	run xs-O2-X1 for more information on options)

EXAMPLE: xs-O2-X1b db_all.txt DHIPP all -p 10 -s Inj1 -d 1800
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-O2-X2b"><a href="#CODE">&#8679</a> xs-O2-X2b</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
------------------------------------------------------------------------------
xs-O2-X2b: calculate and collate response curves across subjects
- calls xs-O2-X1
- adds subject and group columns
USAGE: xs-O2-X2b [database] [region] [analysis] [opts]
	[database]: name of the database (.db) file to use
	[region]: brain region (e.g. DHIPP, MPFC)
	[analysis]: analysis to perform (all, collate, or test)
	[options]: as for xs-O2-X1:
		-c specify the exact name of the comment-file to use for alignment
		-f filter type: none,box,bworth,despike,dejump
		-i integration period for filtering, in seconds
		-s (-start) start signal
		-e (-stop) end, or stop signal
		-a (-first) first block to use
		-z (-last) last block to use
		-d (-dur) block duration
		-n (-norm) normalization
		-p (-pre) presample time
		-N (-pn) normalization presample time if different from -p 
		-r (-sz) re-zero to start of presample
		-b (-bin) bin-size to aid block-averaging, sets new sample-interval
		-m temporary multiplier for aligned block-times
	run xs-O2-X1 for more information on options)

EXAMPLE: xs-O2-X2b KETAMINE DHIPP all -p 10 -s Inj1 -d 1800
------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-paste1"><a href="#CODE">&#8679</a> xs-paste1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-paste1: paste single-column files together to make a multi-column file
 - similar to the BASH paste command, but with extra checks and options
 - each file must have exactly one column (tab-delimited)
	- a file with no lines (-h 0) or a header-oonly (-h 1) can be tab-filled
	- missing files can also be tab-filled, and headered if -H is set

ERRORS will be generated if:
	- none of the files are found
	- none of the files have non-header lines
	- any files with non-header lines do not have different line-counts
	- any files with non-header lines have more than one column

USAGE: xs-paste1 [files] [options]
	[files]: quoted list of input files, each a single column

VALID OPTIONS (defaults in []):
	-p: value to use as padding for missing data []
	-h: do files have a header as the first line? (0=NO 1=YES) [0]
	-H: quoted list of headers for files, if file or header is missing []
		- only applied if -h 1
		- must be the same number of elements as there are input files
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

EXAMPLE: 
	xs-paste1 "a.txt b.txt c.txt -h 1 -H "dogs cats mice" &#62 output.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotbydate"><a href="#CODE">&#8679</a> xs-plotbydate</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotbydate: plot data by date (lines)
USAGE: xs-plotbydate [in] [cx] [cy] [options]
	[in]: input file
	[cx]: name of column holding x-values (date, format yyyy/mm/dd
	[cy]: name of column holding y-values
VALID OPTIONS (defaults in []):
	--opt: quoted options for xe-plottable1 []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotbydate data.txt  2&#62&1 | tee logxs-plotbydate.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotcollate"><a href="#CODE">&#8679</a> xs-plotcollate</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
---------------------------------------------------------
xs-plotcollate: Collate plots of a given name from a database
Usefull if there are only comments in the first channel
USAGE: xs-plotcollate [database] [name] [opts]
	[database]: database file listing paths to plots
	[name]: name of the plot file in each directory
	[opts]: options for xe-plotmerge1
EXAMPLE: xs-plotcollate all.db plotchart.001.ps
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotcolours"><a href="#CODE">&#8679</a> xs-plotcolours</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotcolours: make a test-plot of colours from xe-plottable1
USAGE: 
	xs-plotcolours test
VALID OPTIONS (defaults in []):
OUTPUT:
	temp_plotcolours1.ps
	temp_plotcolours2.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotconvert1"><a href="#CODE">&#8679</a> xs-plotconvert1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotconvert1: convert LDAS postscript plots to other formats
USAGE: xs-plotconvert1 [ps] [options]
	[ps]: postscript plot file
		- wildcards accepted, if quoted
VALID OPTIONS (defaults in []):
	--format: set output format (jpg,png,tiff or pdf) [jpg]
		- for multi-page plots, use --format pdf --crop 0
		- other formats will only include the first page
	--res: set resolution (DPI) [300]
	--crop: crop output to actual drawing (0=NO 1=YES) [1]
	--opts: ghostscript options []
	--verb: verbose output (0=NO 1=YES) [1]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotconvert1 "output_*.ps" --format png
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotcor2"><a href="#CODE">&#8679</a> xs-plotcor2</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotcor2: Correlate variables in two separate files, allowing grouping
 - requires a column with matching keys in both files
 - uses xs-dbmatch2 to combine data
 - NOTE: columns are referred to by name (first-line)
USAGE: 
	xs-plotcor2 [in1] [in2]
		in1: input file with [match1], [group], and [var1]
		in2: input file with [match2] and [var2]
VALID OPTIONS (defaults in []):
	--m1: column-name holding key-to-match in "in1" [subject]
	--m2: as above in "in2" - if empty, default= m1 []
	--grp: column in "in1" defining group-membership [group]
	--v1: variable from "in1" to correlate [var1]
	--v2: variable from "in2" to correlate [var2]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
...plot options...
	--px: scatterplot x-label []
	--py: scatterplot y-label []
	--pt: scatterplot title []
	--p1: general options for the scatterplot []
	--p1: general options for the box-plot []
	--swap: swap x- and y-axes (0=NO 1=YES) [0]
EXAMPLE: 
	xs-plotcor2 data.txt  2&#62&1 | tee logfile.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotextract1"><a href="#CODE">&#8679</a> xs-plotextract1</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotextract1: extract data from plots (.ps) generated by xe-plottable1
- one of points or lines must be defined
- if error-bars are defined, these too will be printed
- if no groups are defined, group is "0" by default

USAGE: 
	xs-plotextract1 [postscript-file]

EXAMPLE: 
	xs-plotextract1 temp_xe-plottable1.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmatrixsplit1"><a href="#CODE">&#8679</a> xs-plotmatrixsplit1</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmatrixsplit1: do a split-plot of a matrix
 - this is very useful for spectral heat-maps
USAGE: xs-plotmatrixsplit1 [in] [options]
	[in]: input matrix
VALID OPTIONS (defaults in []):
	--mod: quoted options for pre-processing with xe-matrixmod1 []
	--yrange: CSV min,max [1,150]
	--xrange: CSV min,max [-60,59]
	--splity: y-value at which to split plot [30]
	--clean: remove temporary files (0=NO 1=YES) [1]
	--verb: verbose output (0=NO 1=YES) [0]
...options for plots
	--shift: vertical-shift for bottom plot [60]
	--title: quoted title, top plot only []
	--xl: quoted x-axis label, bottom-plot only []
	--yl: quoted y-axis label []
	--opts1: everything else, for both plots (see xe-plotmatrix1) []
	--out: name of output file [plot_xs-plotmatrixsplit1.ps]
OUTPUT: 
	postscript plot: plot_xs-plotmatrixsplit1.ps
EXAMPLE: 
	xs-plotmatrixsplit1 matrix.txt --xrange -60,60 --opts "-font 6"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmeans1"><a href="#CODE">&#8679</a> xs-plotmeans1</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------
xs-plotmeans1: plot group means, SEM, + raw-data
USAGE: xs-plotmeans1 [infile] [cg] [cy] [options]
	[infile]: 2-column data file with header-line defining columns
	[cg]: column-name for group-ids
	[cy]: column-name for data
VALID OPTIONS (defaults in []):
	-x: x-axis label, in quotes [Group]
	-y: y-axis label in quotes, if unset: "Mean [cy]" []
	-t: title, in quotes []
	-e: error to use (sem or sd) [sem]
	-o: name of output file [plot_xs-plotmeans1.ps]
Plot options applied to xe-plottable1 :
	-A: box plot options (in quotes)
	-B: point plot options (in quotes)
	--name1: file defining group g1 names (group name) []
- EXAMPLE: xs-plotmeans1 data.txt  1 2 -x "Group" -y "Mean (uV)"
----------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmeans2"><a href="#CODE">&#8679</a> xs-plotmeans2</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------
xs-plotmeans2: plot group means for a an x/y line-plot
- USAGE: xs-plotmeans2 [infile] [grp] [x] [y] [mult] [options]
- 	[infile]: data file
- 	[grp]: column holding group-ids
- 	[x]: column holding a predictor (-1 to omit)
- 	[y]: column holding raw data
- 	[mult]: multiply x by this to convert to integers
- 		- sets decimal precision of x-data
- 		- eg. if mult=100, precision=2 decimal places
- 	[options]: xe-plottable1 options
- EXAMPLE: xs-plotmeans2 data.txt  1 2 3 1000 -colour 3
----------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmeans3"><a href="#CODE">&#8679</a> xs-plotmeans3</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-math">math</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmeans3: stacked box-plot of group means for 2 nested group levels
	- group designations must be numeric
	- uses xe-statsgrp2 and xe-plottable1
USAGE: 
	xs-plotmeans3 [in] [g1] [g2] [cy]
		[in] input file with headers labelling columns
		[g1] column defining primary group (position on x-axis)
		[g2] column defining secondary group (colour)
		[cy] column defining the data to be averaged
VALID OPTIONS (defaults in []):
	-x: x-axis label in quotes [Group]
	-y: y-axis label in quotes, if unset: "Mean [cy]" []
	-t: title, in quotes []
	--name1: file defining group g1 names (group name) []
	--name2: file defining group g2 names (group name) []
	--out: output plot file name [plot_xs-plotmeans3.ps]
	--plot: additional plot options (refer to xe-plottable1) []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotmeans3 data.txt genotype dose response
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmod1"><a href="#CODE">&#8679</a> xs-plotmod1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmod1: replace basic LDAS postscript plot parameters
 - will make changes for all plots in a multi-plot file
 - output sent to stdout - input file is unchanged
USAGE: 
	xs-plotmod1 [psfile] [options]
		[psfile]:  postscript output from program xe-plottable1
VALID OPTIONS (defaults in []):
	--ps: change point size []
	--font: change base font size []
	--cswap: swap colours (old,new) []
	--legend: name of group-labels file to rebuild legend []
	--xtics: CSV list of value,label pairs []
	--ytics: CSV list of value,label pairs []
ADDITIONAL ARGUMENTS:
	--out: output to stdout (0) or overwrite original file (1) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotmod1 plotfile.ps --cswap 1,9 --ps 12 &#62 newplot.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmodlegend"><a href="#CODE">&#8679</a> xs-plotmodlegend</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmodlegend: replace numbers in plot legend with alternative text
USAGE: 
	xs-plotmodlegend [psfile] [keyfile]
		[psfile]:  postscript output from program xe-plottable1
		[keyfile]: file containing replacement code-legend entries
			example:
				0 control
				1 dose1
				2 dose2
ADDITIONAL ARGUMENTS:
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotmodlegend plotfile.ps legend.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmodtics"><a href="#CODE">&#8679</a> xs-plotmodtics</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmodtics: replace tics with alternative values
USAGE: 
	xs-plotmodtics [psfile] [keyfile] [type]
		[psfile]:  postscript output from program xe-plottable1
		[keyfile]: file containing replacement tic position-label
			example:
				1 first
				2 second
				3 last
		[type]: tic-type to replace (xtic or ytic)
ADDITIONAL ARGUMENTS:
	-f: format (0=simple 1=verbose) [1]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-plotmodtics plotfile.ps tics.txt xtics
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotmulti"><a href="#CODE">&#8679</a> xs-plotmulti</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotmulti: make multiple plots from a file defining plot-groups

USAGE: 
	xs-plotmulti [infile] [col] [options]
		[infile]: input file with a column defining the plot-id
		[col]: the column number (or label) defining the plot-ids
OPTIONS (defaults in []):
	-t: flag - remove title
	-v: flag - verbose output
	-P: individual plot options (in quotes) for xe-plottable1
	-M: plot merge options (in quotes) for xe-plotmerge1
OUTPUT: postscript code to stdout (must redirect to file) 
EXAMPLE: 
	xs-plotmulti table.txt trial -P "-cx 5 -cy 6 -line 1 -ps 0" &#62 plot.ps
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotsignal"><a href="#CODE">&#8679</a> xs-plotsignal</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-plotsignal: make a summary plot characterizing a time-series 

USAGE: 
	xs-plotsignal [infile] [options]
		[infile]: time series in format &#60time&#62&#60tab&#62&#60value&#62

OPTIONS (defaults in []):
	-u: units of FFT output [0]
		0: amplitude
		1: RMS
		2: RMS power
		3: dB amplitude
		4: dB RMS
		5: db RMS power

	-l: FFT low frequency [determined by duration]
	-h: FFT high frequency [determined by sample rate]
	-b: FFT buffer (window-size) [detemined by low frequency]
	-s: FFT step (overlap= 1-1/step: 1=0%, 2=50%, 4=75% etc) [1]
	-t: FFT tapers [1]
	-g: FFT output Gaussian smoothing factor (average FFt only)  [0]
	-u: FFT units: 0=amplitude,1=RMS,2=RMSpower,3=dBamplitude [0]
	-A: start time (s) for signal plot []0
	-D: duration (s) for signal plot [1]
	-S: options (in quotes) for the signal plot
	-M: options (in quotes) for the mean amplitude spectrum plot
	-T: options (in quotes) for the time x frequency x amplitude plot
EXAMPLE: 
	xs-plotsignal signal.txt -u 3 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-plotsubgrptime"><a href="#CODE">&#8679</a> xs-plotsubgrptime</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
----------------------------------------------------------------
xs-plotsubgrptime: plot time-series by subject/grp/mean
- use to fully explore data by subject and by group
- for each measure, shows three times-course plots
	- subject (colour-coded by subject)
	- subject (colour-coded by group)
	- group means (colour-coded by group, with error-bars)
- USAGE: xs-plotsubgrptime [infile] [time] [measures]
- 	[infile]: data file
- 	[time]: column holding the time-variable
- 	[measures]: CSV list of measures to plot against time
VALID OPTIONS (defaults in []):
	--subject: column defining subject [subject]
	--group: column defining group [setgroup]
	--norm: by-time normalisation (see xe-normrow2) [-1]
	--xlabel: plot x-label [default= same as --time]
	--title: top-of-page plot title []
	--plotopts: options to apply to all plots []
		- NOTE: general plot appearance options only
	--out: output file name [plot_xs-plotsubgrptime]
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
OUTPUT:
	- postscript plot: plot_xs-plotsubgrptime
----------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progbackup2"><a href="#CODE">&#8679</a> xs-progbackup2</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progbackup2: back-up all programs in [path] to a zip file in the current folder
- assumes script are in the current directory and begin with "r_" "xs-" or "xp-"
- assumes all source code is in subdirectory "source"
- assumes documents are in subdirectory "documents"
- also collects from the "0_jozsef" directory
USAGE: 
	xs-progbackup2 [path]
ADDITIONAL ARGUMENTS:
EXAMPLE: 
	xs-progbackup2 /opt/ldas/
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progclean1"><a href="#CODE">&#8679</a> xs-progclean1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progclean1: deletes or archives outdated program source-code
- should be run in the top-level program directory
USAGE: xs-progclean1 [version] [archive | noarchive]
	[version]: version of xs-progfindcopies to use
	[noarchive]: old source code is deleted
	[archive]: move to ./backups/source_archive/
		NOTE: archive is the default
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progcompile"><a href="#CODE">&#8679</a> xs-progcompile</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>/opt/LDAS/xs-progcompile: line 21: lsb_release: command not found

------------------------------------------------------------
Compiler script for programs using external functions
Avoids having to create a Makefile for the program
Function prototypes should be defined in "main"
Prototypes must be formatted as in the following example...

	/* external functions start */
	void errorhandler(char error_txt[]);
	int substring(char *source, char *target, int case);
	/* external functions end */

USAGE: xs-progcompile [source] [options]
	[source]: name of source file, or pattern in quotes
OPTIONS, defaults in []:
	--comp compiler to use, gcc or g++ [gcc]
	--func path to function source files [./]
	--dest path for executable output [../bin/]
	--prefix to add to executable output []
	--opt optimization-level [0-3] [3]
	--warn warning level (0=low,1=high,2=all) [2]
	--pack package output into folder name []

EXAMPLES:
- make executable "xe-anova" in current dir: 
	xs-progcompile anova.c --prefix "xe-" --dest ./
- compile files matching "xe-*.c", show all warnings:
	xs-progcompile "xe-*.c" --warn 2
------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progdep"><a href="#CODE">&#8679</a> xs-progdep</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progdep: get dependencies for LDAS scripts/progs/functions
- assumes source code will be in a sub-directory called "source"
- USAGE: xs-progdep [file] [setindent]
- ADDITIONAL ARGUMENTS:
- EXAMPLE: xs-progdep xs-myscript 2 
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progfindcopies"><a href="#CODE">&#8679</a> xs-progfindcopies</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progfindcopies: find multiple versions of files matching a pattern
Specifically, finds multiple files matching [pattern].[version].[extention]

USAGE: 
	xs-progfindcopies [version] [pattern]
		[version] = version of algorithm
			1: use sort --version-sort
			2: use sort -V
			3: use custom algorithm 
				- suitableif versions 1&2 are unsupported by operating system
				- may fail for multi-part versions (e.g. file.3.10.c)
EXAMPLE: 
	xs-progfindcopies 1 *.c
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-proggit1"><a href="#CODE">&#8679</a> xs-proggit1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-proggit1: Git helper script
REQUIRES: a properly formatted ,notes file
USAGE: 
	xs-proggit1 [mode]
	[mode]: status, diff, push, or pull
		status: show local changes (committed=green, uncommitted=red)
		diff: compare local commited changes to remote master
		pull: pull remote master repository
		push: add changes, commit (with -m message), and push to remote master
ADDITIONAL ARGUMENTS (defaults in []):
	-m: message for push [update]
EXAMPLE: 
	xs-proggit1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progheader1"><a href="#CODE">&#8679</a> xs-progheader1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progheader1: create a header file (.h) for a repository
- should capture all files beginning with "xf_" and ending in ".c"
- USAGE: xs-progheader1 [name]
	[name]: name of the header, for definition purposes
- VALID OPTIONS (defaults in [])...
	- pro
- EXAMPLE: xs-progheader1 LDAS_H &#62 LDAS.h
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-proglicence"><a href="#CODE">&#8679</a> xs-proglicence</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-proglicence
--------------------------------------------------------------------------------
Apply licence text to the top of a source code file (or remove it)
Reads a licence file to obtain the text of the licence
Licence text will appear as a comment appropriate for c,cpp or script files
USAGE: xs-proglicence [sourcefile] [licence] [options]

	[source]: source-code file to add licence to
		- existing licence text is removed
			- starting the text "LICENCE INFORMATION:"
			- ending at the first blank line after this text
		- any additional leading blank lines are removed
		- files which do not end in .c or .cpp are assumed to be scripts
		- for these files the shell path "#![PATH]" is kept on line 1

	[licence]: licence file to use - contains basic text
		- "NONE" will simply remove existing licence text (see above)
		- first line should read "Copyright (c) &#60YEAR&#62, &#60OWNER&#62."
		- blank lines at the top & bottom of the licence text are removed
		- text "LICENCE INFORMATION:" is added to the top
		- each line of the licence text will be commented:
			.c files: bracketed by "/*" and "*/"
			.cpp files: "\\ "
			other files: "# "
		- a single blank line is added to the bottom

OPTIONS, defaults in []:
	-y : year  to replace &#60YEAR&#62 label in licence file [2020]
		- do not use commas, do place multiple years in quotes
		- set to L to preserve current licence setting
		- set to D to use current file date
	-o : owner to replace &#60OWNER&#62 label in licence file [John R. Huxter &#60j.r.huxter@gmail.com&#62]
		- can include contacts, etc.
	 	- place in quotes, avoid commas
		- set to L to preserve current licence setting
	-w : [flag] wrap licence texte to 80 columns [unset by default]
	-t : [flag] preserve original timestamp of file [unset by default]
EXAMPLE: 
	xs-proglicence xe-cor1.c ~/docs/licence_MIT.txt -w -y "1999 2013"
	xs-proglicence xe-cor1.c NONE -y D -o "John Smith"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-proglist"><a href="#CODE">&#8679</a> xs-proglist</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-proglist: build list of programs from the output of xs-progdep 
Only outputs one line per script/program/function
Assumes: 
	xs- = script, path= current directory
	xe- = program, path= source/
	xf- = function, path= source/functions
- USAGE: xs-proglist [list]
- EXAMPLE: xs-proglist dependencies.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progpath1"><a href="#CODE">&#8679</a> xs-progpath1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progpath1: modify the $PATH environment variable (defines program locations)
	- modifications are temporary and only apply to current window


USAGE: 
	xs-progpath1 [newpath]
		[newpath]: directory to prepend to the PATH variable

ADDITIONAL ARGUMENTS:
	-o: path-pattern to omit [unset]

EXAMPLE: 
	source xs-progpath1 /run/media/huxprog/DataLocker1/LDAS -o /home/huxprog
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progpermission"><a href="#CODE">&#8679</a> xs-progpermission</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progpermission: check if user has write-permission for a file or directory
USAGE: xs-progpermission [user] [path]
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progps"><a href="#CODE">&#8679</a> xs-progps</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
------------------------------------------------------------------
- find a pattern in current processes running
- equivalent of ps aux | grep, but with filtering
- useage: xs-progps [pattern] [fields]
[pattern]: an element of the command line to match
	echo  - NOTE: place quotes around multi-word patterns
        echo 	[fields] (optional): the number of command-line options to print
- example: xs-progps "KlustaKwik jh001-091231" 4
------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progsync1"><a href="#CODE">&#8679</a> xs-progsync1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progsync1: sync (copy) current program directory with a remote program directory
	- copies the following files :
		.\xs-* (scripts)
		.\documents\*  (documentation)
		.\source\* (source code for executables, functions & headers)
	- removes temporary files first
	- archives outdated program source-code in local and remote directories

USAGE: xs-progsync1 [remote] [mode] [version] [options]
	[remote]: remote top-level program directory
	[mode]: push or pull
		push: push ALL newer local files to remote dest.
		pull: pull ONLY newer copies of local files from remote dest.
	[version] = algorithm used for cleaning up old versions
		1: use sort --version-sort
		2: use sort -V
		3: use custom algorithm 
			- suitableif versions 1&2 are unsupported by operating system
			- may fail for multi-part versions (e.g. file.3.10.c)

VALID OPTIONS:
	-f: force copy (if unset, only newer files are copied))

EXAMPLE: to copy local programming files to usb stick:
	cd /home/huxprog/
	xs-progsync1 /media/INTEGRAL/Sync/huxprog/

EXAMPLE: to copy programs from USB stick to local programming folder:
	cd /media/INTEGRAL/Sync/huxprog/
	xs-progsync1 /home/huxprog/
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-progtag"><a href="#CODE">&#8679</a> xs-progtag</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-progtag: find tags associated with LDAS scripts, programs and functions
 - assumes tags fall between a &#60TAGS&#62 &#60/TAGS&#62 XML block in the code
 - tags in the source code must be comma or white-space separated
USAGE: xs-progtag [mode] [options]
	view: view the overview - requires graphical interface + firefox
	list: list all the tags mentioned in code
	find [tags]: find code matching a CSV list of tags
	replace [old] [new]: find and replace particular tags (exact match)
	html [file]: build web-page summarising all tagged code
		default output file = /opt/LDAS/docs/PROGTAG.html

VALID OPTIONS (defaults in []):
	--verb: verbose output (0=NO 1=YES) [1]
EXAMPLES: 
	xs-progtag view
	xs-progtag list
	xs-progtag find math,FFT
	xs-progtag replace statistics stats
	xs-progtag html output.html
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_ancova"><a href="#CODE">&#8679</a> xs-R_ancova</h3></font>
<blockquote><pre>
Perform ANCOVA using R
Determine effect of factor A on Y, controlling for correlation between X and Y
Format: xr_ancova [filename] [y column] [x column] [A column]

Assumptions: X and Y are continuous variables, while A is integers

</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_anova"><a href="#CODE">&#8679</a> xs-R_anova</h3></font>
<blockquote><pre>
--------------------------------------------------------------------------------
- Perform ANOVA using R
- Will perform Tukey's HSD post-hoc tests
USAGE: 
	xr_anova [filename] [data] [predictors]
		filename:  input file with headered columns
		data: name of the column containing the dependent variable
		predictors: CSV list of column-names for independent variables
			- NOTE: predictors should be integer values
EXAMPLE: 
	xs-R_anova data.txt height age,sex,income
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_anova_circ"><a href="#CODE">&#8679</a> xs-R_anova_circ</h3></font>
<blockquote><pre>	---------------------------------------------------------
	Perform one-way circular ANOVA using R
	Format: xr_anova_circ [filename] [data (dv)] [factor (iv)]
	---------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_anova_rc"><a href="#CODE">&#8679</a> xs-R_anova_rc</h3></font>
<blockquote><pre>-----------------------------------------------------------
Perform repeated-measures ANOVA using R
Specify filename and list of columns
Format: xr_anova_rc [file] [data] [sub] [rep] [options]
	[file] = input file
	[data] = column containing dependent variable
	[sub] = subject-number column
	[rep] = repeated-measures column
	[options]: optional arguments...
		-b [between-subjects factors]
			Specify factor-columns(in quotes)
		-c [planned comparisons]
			Specify comparisons (in quotes) to be performed
			Run without -c to see available contrasts
			Example: -c "0 0 0 -1 0 0 1"
		-l : list possible planned comparisons
		-d : Dunnetts posthoc comparisons
		-t : Tukeys posthoc comparisons
Examples:
	xr_anova_rc file.txt 5 1 3
	xr_anova_rc file.txt 5 1 3 -d
	xr_anova_rc file.txt 5 1 4 -b "3 2 " -c 0,0,-1,1,0,0,0

NOTE: proper planned comparisons require specifying orthogonal 
	contrast-coefficient sets - do manually using temp file?
-----------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-rega"><a href="#CODE">&#8679</a> xs-rega</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-plot">plot</a>][<a href="#tag-file">file</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
---------------------------------------------------------
Script for invoking regaamc8 for 64-channel recordings
- USAGE: xs-rega [filename] [min] [max] [step]
	[filename]: a binary .dat .eeg .eegh or .fex file
	[min]: lowest channel number to display [0-63]
	[max]: highest channel number to display [0-63]
	[step]: interval between channels [1,2,4,8,16]
---------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-rega2"><a href="#CODE">&#8679</a> xs-rega2</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
Invoke regaamc8 to view multi-channel binary files (16-bit short-integers)
	- 
EXECUTABLE PATH: /opt/LDAS/bin/regaamc8
USAGE: xs-rega2 [in] [nch] [sf]
	[in]: a binary .dat file (16-bit short integer)
	[nch]: number of interlaced channels
	[sf]: the sample-frequency (Hz)
VALID OPTIONS (defaults in []):
	--chans: CSV list of channels to display []
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-rega2 results.dat 64 20000 --chans 3,20,34,60
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-rename"><a href="#CODE">&#8679</a> xs-rename</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-file">file</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>--------------------------------------------------------------------------------
xs-rename: replace characters or patterns in filenames, using sed
- approximates behaviour of the non-regex "rename" tool from RedHat Linux
USAGE: 
	xs-rename [old] [new] [in] [options]
		old: (in quotes) character or pattern to be replaced
		new: (in quotes) the replacement character or pattern
		in: input file(s) - quote multiple filenames or wildcards

VALID OPTIONS:
	-c: compress consecutive "old"s  to a single "new" (0=NO 1=YES) [0]
		NOTE: this is the only behaviour when "old"=white-space
	-w: wildcard usage (0=user, 1=auto) [0]
		NOTE: "0" may fail for script-invocation of xs-rename
			 : wildcards should be enclosed in quotes
		NOTE: "1" is safe for script-invocation of xs-rename
			 : [in] should not include your own wildcards
			 : [in] is interpreted as *[in]*

EXAMPLE: 
	xs-rename  " " "_" "Track" -w 0
	xs-rename  " " "_" "Track.*txt" -w 1
	xs-rename  "k" "p" "Track.*txt" -w 1 -c 1
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-renamespace"><a href="#CODE">&#8679</a> xs-renamespace</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-renamespace: replace spaces in filenames
	- consecutive spaces will undergo a single replacement
USAGE: 
	xs-renamespace [in] [new]
		in: input file(s) - quote multiple filenames or wildcards
		new: the replacement - can be a single character or a string
EXAMPLE: 
	xs-renamespace "Track.*txt"  "_"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_multregression_example"><a href="#CODE">&#8679</a> xs-R_multregression_example</h3></font>
<blockquote><pre>/opt/LDAS/xs-progtag: line 393: xs-R_multregression_example: command not found
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_regress"><a href="#CODE">&#8679</a> xs-R_regress</h3></font>
<blockquote><pre>
Perform multiple regression using R
Specify filename and list of columns containing data and predictors
Format: 
	xr_regress [filename] [y column] [x1 column] [x2 column]... etc

</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_sample_contrasts"><a href="#CODE">&#8679</a> xs-R_sample_contrasts</h3></font>
<blockquote><pre>/opt/LDAS/xs-progtag: line 393: xs-R_sample_contrasts: command not found
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_sample_data"><a href="#CODE">&#8679</a> xs-R_sample_data</h3></font>
<blockquote><pre>/opt/LDAS/xs-progtag: line 393: xs-R_sample_data: command not found
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_ttest"><a href="#CODE">&#8679</a> xs-R_ttest</h3></font>
<blockquote><pre>-----------------------------------------------------------
Perform a t-test using R
Uses Welch's correction if variances are unequal
Assumes files DO NOT have headers identifying variables
Strips non-numeric or missing values from dataset
Format: xr_ttest [file][dv][iv] [options]
	[file] = input file
	[dv] = column-number holding dependent variable
	[iv] = column-number holding independent variable (2-levels)
Valid options:
	-v set verbose output
Non-verbose output:
	mean1  mean2  t  df  p  (w) if Welch's correction
Examples:
	xr_ttest file.txt  5 1 
-----------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_ttest1"><a href="#CODE">&#8679</a> xs-R_ttest1</h3></font>
<blockquote><pre>-----------------------------------------------------------
Perform a 1-sample t-test using R
Assumes files DO NOT have headers identifying variables
Strips non-numeric or missing values from dataset
Format: xr_ttest1 [file][dv] [options]
	[file] = input file
	[dv] = column-number holding dependent variable
Valid options:
	-r set reference value for comparison (default=zero)
	-v set verbose output
Non-verbose output:
	mean1 t  df  p 
Examples:
	xr_ttest1 file.txt  5 -r 0.5 -v 
-----------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_ttest2"><a href="#CODE">&#8679</a> xs-R_ttest2</h3></font>
<blockquote><pre>-----------------------------------------------------------
Perform a 2-sample Student's t-test using R
Uses Welch's correction if variances are unequal
Assumes files DO NOT have headers identifying variables
Strips non-numeric or missing values from dataset
Format: xr_ttest2 [file][dv][iv] [options]
	[file] = input file
	[dv] = column-number holding dependent variable
	[iv] = column-number holding independent variable (2-levels)
Valid options:
	-v set verbose output
Non-verbose output:
	mean1  mean2  t  df  p  (w) if Welch's correction
Examples:
	xr_ttest2 file.txt  5 1 
-----------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_ttest_header"><a href="#CODE">&#8679</a> xs-R_ttest_header</h3></font>
<blockquote><pre>-----------------------------------------------------------
Perform a t-test using R
Uses Welch's correction if variances are unequal
Assumes files have headers identifying variables
Strips non-numeric or missing values from dataset
Format: xr_ttest_header [file][dv][iv] [options]
	[file] = input file
	[dv] = name of the dependent variable
	[iv] = name of the independent variable (2-levels)
Valid options:
	-v set verbose output
Non-verbose output:
	mean1  mean2  t  df  p  (w) if Welch's correction
Examples:
	xr_ttest_header file.txt  weight group 
-----------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-R_watsons"><a href="#CODE">&#8679</a> xs-R_watsons</h3></font>
<blockquote><pre>	--------------------------------------------------------
	Perform Watsons 2-sample test sing R
	Format: xr_watsons [filename] [column1] [column2] [alpha]
	--------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xs-strmatch"><a href="#CODE">&#8679</a> xs-strmatch</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-strmatch: is one character string (needle) is found in another (haystack) ?

USAGE: xs-strmatch  [haystack] [mode] [needle]

	[haystack]: string in which to search for [needle]
	[mode]: type or match, must be "exact" or "contains"
	[needle]: text to find

NOTE: will not detect white-space (space, tab, newline)
OUTPUT: "yes" or "no"
EXAMPLE: 
	xs-strmatch "10 15 20" contains "5"
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-strsub"><a href="#CODE">&#8679</a> xs-strsub</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-file">file</a>][<a href="#tag-file">file</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-strsub: substitute text in an input string and print
USAGE: xs-strsub [string] [old] [new]
	[string]: string of text to be altered
	[old]: the old characters to be replaced
	[new]: what the old characters should be replaced with
EXAMPLE: xs-strsub "I like cats" "cats" "dogs and cats"
OUTPUT: the modified string
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-strsubfile"><a href="#CODE">&#8679</a> xs-strsubfile</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>0
--------------------------------------------------------------------------------
xs-strsubfile: substitute text in an input file (replaces original)
USAGE: xs-strsubfile [infile] [old] [new]
	[infile]: file name, in quotes if using wildcards
	[old]: the old characters to be replaced
	[new]: what the old characters should be replaced with
EXAMPLE: xs-strsubfile "*.txt" "cats" "dogs and cats"
OUTPUT: changes saved to original file
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-hargreaves0"><a href="#CODE">&#8679</a> xs-TAINI-hargreaves0</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-hargreaves0: extract HARGREAVES trial-records from acquisition PLAN file
 - trial start-stop pairs are inserted into the .notes file for each subject
USAGE: xs-TAINI-hargreaves0 [plan] [options]
	[plan]: a file defining how the eperiment was run
		- defines date= and experiment= 
		- &#60MAPPING&#62 section summarizes session, subject and trial
		- &#60TRIALS&#62 section describes individual trials
VALID OPTIONS (defaults in []):
	--batch: batch-run on this CSV list of directories []
		NOTE: use "*.plan" as the plan name - the quotes matter!
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-TAINI-hargreaves0 PLAN.txt  2&#62&1 | tee log_xs-TAINI-hargreaves0.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-laser1"><a href="#CODE">&#8679</a> xs-TAINI-laser1</h3></font>
[<a href="#tag-laser">laser</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-laser1: 
- creates .notes &#60TRIALS&#62 sections for a laser-ERP expt.
- uses the config (.yaml) file for extracting parameters

USAGE: xs-TAINI-laser1 [worksheet] [options]
	[worksheet]: laser-ERP experimental worksheet (.xlsx or .csv)
	- see /opt/LDAS/docs/templates/template_taini_worksheet_laser.xlsx
	- this can be multiple files, or wildcards - if in quotes

VALID OPTIONS...
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]

EXAMPLES: 
	xs-TAINI-laser1 20181231_000.xlsx
	xs-TAINI-laser1 "*.xlsx"
	xs-TAINI-laser1 "A.xlsx  B.xslx"

OUTPUT...
	- update to individual .notes files in ../../Data_Acquired/[base]/
	- missed-stimuli (x's) summary: LASER1.missing
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-legacy0"><a href="#CODE">&#8679</a> xs-TAINI-legacy0</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-legacy0: invoke "crackit process" for multiple .datraw files 
	- this legacy code uses Taini's legacy "CRACKIT" program output
	- detects and replaces missing samples
	- flips data to correct signal polarity
	- zeros the data by removing the mean
	- names the new output .dat
USAGE: 
	xs-TAINI-legacy0 [pattern]
		[pattern]= file pattern to match, assumes filename ends in ".datraw"
	NOTE: for &#624 files, processing is serial
	    : for &#60=4 files, processesing is parallel and control returned to terminal
ADDITIONAL ARGUMENTS:
	-s: force serial processing rather than parallel (0=NO 1=YES) [0]
		NOTE: serial processing is used anyway for &#624 files
EXAMPLE: 
	xs-TAINI-legacy0 20160415-000
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-legacy1"><a href="#CODE">&#8679</a> xs-TAINI-legacy1</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-legacy1: process .datraw files for ripple-detection
	- this legacy code uses Taini's legacy "CRACKIT" program output
	- runs xs-TAINI-legacy0 to replace missing samples and de-mean the data
	- assumes there are 4 files to process
	- runs xs-ldas5-ripdet1
REQUIRES: 
	- corresponding .synraw files
USAGE: 
	xs-TAINI-legacy1 [base] [options]
		[base]: date-session basename to define input files (.datraw)
VALID OPTIONS (defaults in []):
	-d: expected number of .datraw files [4]
	-n: read duration (seconds, 0=whole-file) [0]
EXAMPLE: 
	xs-TAINI-legacy1 20100208-010 -n 4
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-legacy2"><a href="#CODE">&#8679</a> xs-TAINI-legacy2</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-legacy2: Process Taini Ephys and EthoVision data from a single Ephys session
	- this legacy code uses Taini's legacy "CRACKIT" program output
	- renames files with spaces and converts from DOS format
	- checks date and time from CRACK-IT log & extracts sync-samples
	- extracts xyd info from all EthoVision records in current folder
		- assumes input is semicolon-delimited text
		- generates new timestamps (sample#)
		- corrects EthoVision positions according to Arena
		- assumes 4 arenas each with a  cm x  cm range
	- creates a .notes and .cmt file
	- creates times_alltrials.ssp file describing trial start-stop samples
	- create date_subject folders:
		- copy above output to local files
		- save link to original .dat in notes file
		- create downsampled .bin files
		- create a local interpolated .dat file with non-trial data removed
REQUIRES: 
	- [yyyymmdd]-[ses]_[subject].dat file
	- corresponding .syn file listing trial start-stop samples
	- Ethovision Track files for the corresponding subject and trials
	- Ethovision Hardware Control files containing SyncStartStop times
USAGE: 
	xs-TAINI-legacy2 [pattern] [readme]
		[pattern]: pattern to match in .dat file (or "*")
		[readme]:
			- defines experiment= 
			- &#60TRIALMAP&#62 section lists EV trials for each session
			- if &#621 session listed, .dat files merged &#60NOT IMPLEMENTED AT PRESENT!&#62
ADDITIONAL ARGUMENTS:
	-a: EthoVision start-sync label [sync_0]
	-z: EthoVision stop-sync label [sync_1]
	-s: skip these steps [-]
		d: dat file interpolation and chunking for cluster-cutting
		r: make downsampled (1KHz) .bin files
		v: process EthoVision video failes & make xyd(t) files
		m: move files to their destination folders
	-o: output path [./]
	-t: template to use if table_channels_[subject].txt is missing []
EXAMPLE: 
	xs-TAINI-legacy2 20150930-001 README1.txt -a sync_0 -z sync_1 -s rvm
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-legacy3"><a href="#CODE">&#8679</a> xs-TAINI-legacy3</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-legacy3: run CRACKIT acquitision
	- assumes four subjects are recorded at once
	- automaticaly generates .xml control file
	- uses current directory as output path
	- the xml &#60ACQUISITION&#62 field in README.txt defines subject for each device
	- the same field also defines the device transmission frequency (GHz)

USAGE: 
	xs-TAINI-legacy3 [readme]
		[readme]: a properly formatted README.txt file

EXAMPLE: 
	xs-TAINI-legacy3 README.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-preproc1"><a href="#CODE">&#8679</a> xs-TAINI-preproc1</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-electrophysiology">electrophysiology</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-preproc1: Process a Taini-Live ephys recording session
- run in [experiment]/Data_Aquired/[date] - folder for one experiment-type
- renames TAINI_*.dat and *.sync files to the LDAS standard
- creates [yyyymmdd]-[session]_[subject] folders
	- copies or links .dat files
	- copies .sync files
	- downsamples each .dat channel to a separate 1KHz .bin file
	- creates lost-packet lost.ssp files
	- builds (overwrites) the .notes file
		- adds CHANNELS section based on one of:
			- local table_channel_[subject].txt
			- local table_channel_template.txt
			- ../../table_channels_[subject].txt
			- ../../table_channels_template.txt
			- /opt/LDAS/docs/templates/table_channels_taini_2.txt

USAGE: xs-TAINI-preproc1 [dat] [options]
		[dat]: quoted list of .dat files (wildcards allowed)
VALID OPTIONS:
	--batch: batch-run on this CSV list of directories []
	--expt: name of experiment, for .notes file  [0]
		- overrides "experiment= " in TAINI .yaml config file notes
	--good: analyse good channels only (0=NO 1=YES) [0]
		- as defined in a table_channels file
		- if this file is missing, all channels are treated as good
	--conv: convert .dat files from unsigned to signed (0=NO 1=YES) [0]
	--chans: template to use if table_channels_[subject].txt is missing
	 	[/opt/LDAS/docs/templates/table_channels_taini_2.txt]
	--skip: skip these steps [-]
		p: lost-packet-finding (-lost.ssp)
		d: dat file copying (make link instead)
		b: make downsampled (1KHz) .bin files
EXAMPLE: 
	xs-TAINI-preproc1 "*.dat" -s d 2&#62&1| tee log_xs-TAINI-preproc1.txt
	xs-TAINI-preproc1 "*.dat" --skip pd --batch dir1,dir2,dir3
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-TAINI-tools"><a href="#CODE">&#8679</a> xs-TAINI-tools</h3></font>
[<a href="#tag-taini">taini</a>][<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-TAINI-tools: run TAINI scripts for data setup, acquisition and testing
	- some modes require a .plan file with MAPPING and TRIALS sections
	- TAINI sync-records typically begin with a "blank" sync-0

USAGE: xs-TAINI-tools [mode] [options]

VALID MODES (followed by options starting with --):
	setup
		Set up an acquisition directory (requires --expt)
		Creates a [date]_[expt] directory
		Adds a [date].plan file
		Copies channel-table template /opt/LDAS/docs/templates/table_channels_taini_2.txt
		--expt: name of experiment []
	fft
		Run spectrum viewer
		--input: receiver input to show (ab or cd) [ab]
	live
		Run TainiLive
	sync
		Check a sync-file and extract start-stop pairs
		--file: sync file to check & extract []
		--pre: the sync-record prefix [SYNC_]
		--seq: CSV list of valid sync-number sequence []
		--blank: required sync-record which is not output [0]
		--count: use timestamps to count trials in blocks (0=NO 1=YES) [0]
			- uses mean interval + 5 s.d. as threshold
	trials
		List .plan TRIALS matched to MAPPING subject & session
		--batch: .plan MAPPING batch to check (#, or "all") [all]
		--append: CSV list MAPPING columns to append to trials []
		--file: add sync-file records to trials - see "sync" above
	check
		Compare batch trial-counts with subject sync-records
		--seq: [see above]
		--batch: [see above]
	config
		Output configuration settings (from .yaml)
		--file: you MUST specify a .dat or .yaml file
		--expt: override-name of experiment from .yaml []
	parse
		Parse a TAINI filename to extract a keyword
		--file: the file whose name you want to parse
		--key: the value of interest: id alias year month day date1 date2 inc
	rename
		Rename files from TaiNi default to LDAS format
		TaiNi default: TAINI_[dev]_[alias]-[date]-[session].dat
		LDAS standard: [yyyymmdd]-[session]_[alias].dat
	unrename
		As above, but restore original TAINI filenames
		.yaml files required
	plot
		Generate a 1-second trace-plot for all .dat files
		Looks for table_channels_[subject].txt

EXTRA OPTIONS (defaults in []):
	--plan: specify a plan file (if there is more than one in the folder) []
	--verb: verbose output (0=NO 1=YES) [0]

EXAMPLES: 
	xs-TAINI-tools fft --input 2
	xs-TAINI-tools setup --expt hargreaves_wk3
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-template"><a href="#CODE">&#8679</a> xs-template</h3></font>
[<a href="#tag-programming">programming</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-ldas5-XSERIES1b: template BASH script
xs-ldas5-XSERIES1b: batch-run xs-templat
REQUIRES: a properly formatted .notes file
USAGE: xs-ldas5-XSERIES1b [in] [options]
	[in]: input file, format= &#60time&#62 &#60data&#62
VALID OPTIONS (defaults in []):
	-a: set a-flag to 1 []
	-b: set b-flag to 1 []
	-f: format []
	--batch: batch-run on this CSV list of directories []
		NOTE: in batch mode, quote arguments with wildcards as well
	--skip: skip these steps [-]
		x: execute analysis in each database directory
		c: collate analyis results
	--opt1: quoted options to pass to xs-templat []
	--verb: verbose output (0=NO 1=YES) [0]
	--clean: remove temporary files (0=NO 1=YES) [1]
EXAMPLE: 
	xs-ldas5-XSERIES1b data.txt  2&#62&1 | tee logxs-ldas5-XSERIES1b.txt
	xs-ldas5-XSERIES1b "*.plan" --batch dir1,dir2,dir3
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xs-thetadelta1"><a href="#CODE">&#8679</a> xs-thetadelta1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xs-thetadelta1: Calculate the theta-delta ratio in a time-series 
USEAGE: 
	xs-thetadelta1 [infile]
ADDITIONAL ARGUMENTS:
	-t: data type [R]
		T: ASCII text file
		R: SCORE raw file
	-d: duration of data to use (seconds, or "all") [3600]
	-f: sampling frequency (Hz) [400]
	-w: FFT window size (seconds) [10]
	-s: FFT step (window overlap) [1]
	-n: normalize? (-1=NO 1=YES) [1]
EXAMPLE: 
	xs-thetadelta1 data.txt
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-autocor1"><a href="#CODE">&#8679</a> xe-autocor1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-template1 v 1: 14.August.2012 [JRH]
----------------------------------------------------------------------
Calculate autocorrelation function on a time-series
Non-numeric values will be ignored
USAGE:
	xe-template1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-sf: sample frequency (Hz) [1]
	-max: max lag to calculate (seconds, -1 = auto) [-1]
EXAMPLES:
	xe-template1 data.txt -sf 1500
	cat temp.txt | xe-template1 stdin -sf 24000
OUTPUT:
	1st column: time-lag (seconds)
	2nd column: autocorrelation
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-axona2dat"><a href="#CODE">&#8679</a> xe-axona2dat</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
******************************************************************************
xe-axona2dat v 11: 21.October.2014 [JRH]
******************************************************************************
1. Create a .dat (Csicsvari raw data file) from an Axona .bin file
2. Create a .whd & .xyd file from a .bin and a .trk (video tracking) file

The .trk file is binary file with multiple integers per record
Making the .whd/.xyd files requires a sync signal in the .bin file
This should be on one of the Axona digital I/O pins
If there are more camera frames than sync signals, do frame-alignment
This requires a gap at the start or end of the sync records
If there is no gap, alignment cannot be performed
Valid arguments - defaults in []
	-g: minimum gap (s) in sync signals to allow video data alignment [0.5]
	-outdat: output dat file? 0=no, 1=yes [1]
	-outpos: output whd file? 0=no, 1=yes [1]
	-outsync: output values on sync pin? 0=no, 1=yes [1]
	-camrate: frame capture rate of video camera [25]
	-samprate: sampling rate of binary Axona input [24000]
	-whdrate: output sampling rate for whd file [50.000]
	-whdres: stepdown for x,y resolution (x*whdres,y*whdres) [0.500]
	-syncpin: Axona digital I/O pin (bit) carrying sync signal [1]
	-align: realign video frames if there are fewer sync crecords [1]
		0: disallow - number of sync records and video frames must match
		1: allow - align frames to start or end sync records
	-maxinv: max invalid points across which to interpolate whd data [0]
	-led: using only one LED (no head direction) 1=red, 2=green, 3=blue [0]
	-pause on completion: 0=no, 1=yes [0]

USAGE: xe-axona2dat [.bin file] [.trk file] [arguments]

</blockquote></pre>

<font color="Black"><h3 id="code-xe-bin1"><a href="#CODE">&#8679</a> xe-bin1</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-bin1 v 7: 14.March.2015 [JRH]
----------------------------------------------------------------------
Bin (down-sample) data using non-overlapping windows
Binning is performed on the fly, so there is no memory overhead
Two options: averaging or peak-detect
	- averaging method acts as a low-pass filter
	- for this method any partial bin at the end of the input is
	  combined with the previous bin to avoid under-averaging

USAGE: xe-bin1 [input] [binsize] [options]
	[infile]: single-column data file or "stdin"
		- non-numbers do not contribute to means
		- bins without finite numbers will output NAN
	[binsize]: number of values to average at a time
			- can be a fraction
			- must be greater than or equal to 1
			- if exactly 1, every input value is output

VALID OPTIONS:
	-t(ype):[1]
		1= within-bin average
		2= largest deviation from within-bin average
OUTPUT: 
	the binned version of the input

EXAMPLE: 
	to reduce the sample-rate of an input from 496Hz to 400Hz
	binsize= 496/400 = 1.24

	xe-bin1  data.txt 1.24
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-bin2"><a href="#CODE">&#8679</a> xe-bin2</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-bin2.c v 7: 27.November.2017 [JRH]
--------------------------------------------------------------------------------
Bin data by averaging consecutive samples in non-overlapping windows
USAGE: xe-bin2.c [input] [options]
	[input]: 2-column data file or stdin in format &#60time&#62 &#60value&#62
OPTIONS: defaults in []...
	-t width of the time-window [1]
	-m output time at start of each window (0) middle(1) or end(2) [0])
	-p detect peaks (1) instead of the mean (0) in each window [0])
		: output 2 points (min, max) per window
	-s output sums (1) instead of means (0) [0])
		: only one of -p or -s can be set to 1
NOTES: 
	: missing or invalid time values will result in inconsistent bin start-times
	: all non-numeric data (except INF) are converted to NAN
	: non-numeric data do not contribute to bin sums/averages
	: if all data in a bin are non-numeric, the output for the bin is NAN
	: if any data in a bin are INF, the output for the bin is INF (but see below)
	: the minimum output value for peak-detect binning is unaffected by INF
EXAMPLE:
	cut -f 1,2 data.txt | xe-bin2.c stdin -t 0.5 -m 0 -p 0
OUTPUT: [time] [average or peak]
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-checkisnum2"><a href="#CODE">&#8679</a> xe-checkisnum2</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-checkisnum2 v 7: 6.March.2017 [JRH]
----------------------------------------------------------------------
Output lines from a file only if specified fields are numbers
USAGE:
	xe-checkisnum2 [input] [options]
	[input]: filename or "stdin"):

VALID OPTIONS, defaults in []: 
	-t: valid number-types [2]
		0= integer (no decimals accepted - eg. 1.0 fails)
		1= float or integer
		2= any, including INF or NAN)
	-f: fields to check, comma-separated [all]
...exceptions... 
	-b: output blank lines? 0=no, 1=yes, [0]
	-h: allow header line? (0=NO 1=YES) [0]
	-c: allow "#"comments) (0=NO 1=YES) [0]
	-m: non-numeric missing-value placeholder to accept [-]
		-NOTE: this will be output as if it were numeric

EXAMPLE: output lines if columns 1 3 and 5 contain integers:
	xe-checkisnum2 datafile.txt -t 0 -f 1,3,5 
	cat datafile.txt | xe-checkisnum2 datafile.txt -t 0 -f 1,3,5 
EXAMPLE: output lines if all columns contain any number:
	xe-checkisnum2 datafile.txt -t 2 

CAUTION: strings like 25abc will be interpreted as a number (25) 
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-cofiring1"><a href="#CODE">&#8679</a> xe-cofiring1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-cofiring v 1.2: 18.April.2016 [JRH]
----------------------------------------------------------------------
Calculate co-firing in a cell-pair using a cell-pair list-file
- usage:
	xe-cofiring [data] [listfile] [arguments]
	[data]: filename or "stdin" of format [time] [cell-id]
	[listfile]: file listing cell-id pairs (two numbers per line)
- valid arguments (defaults in []) ...
	-w size of window, seconds [0.1]
	-ms minimum spikes (any cell) in a window to allow inclusion [0]
- examples:
	xe-cofiring data.txt list.txt
	cat data.txt | xe-cofiring stdin list.txt
- output:
	1st column: lower limit of each bin
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-convolve1"><a href="#CODE">&#8679</a> xe-convolve1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-conv1 v 3: 6.October.2014 [JRH]
----------------------------------------------------------------------
Convolve input1 with input2
NOTE: no correction for non-numeric or non-finite numbers (NAN,INF)
USAGE:
	xe-conv1 [input1] [input2]
	[input1]: file name of first input, or "stdin"
	[input2]: file name of second input, or "stdin"
	NOTE: if one input is "stdin", the other cannot be!
VALID OPTIONS:
	none
EXAMPLES:
	xe-conv1 data1.txt wavelet.txt
result: single column of convolved results
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-cor1"><a href="#CODE">&#8679</a> xe-cor1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-cor1 v 6, 17.April.2016 [JRH]
----------------------------------------------------------------------
Simple Pearson's correlation between a pair of columns (fast)
	- filters-out non-numeric data, NaN and Inf
	- will report r=0 if n&#602, and r=1 if n=2
	- reads data into memory: for low-memory, use xe-correlate
	- Not siutable for large matrices - cut columns out first

USAGE:
	xe-cor1 [filename] [options]
		[filename]: file name or "stdin"
VALID OPTIONS [DEFAULT IN BRACKETS]...
	-cx column containing independent variable [1]
	-cy column containing dependent variable [2]
	-xmin minimum value of independent value to include [nan]
	-xmax maximum value of independent value to include [nan]
	-v sets verbosity of output (0=single line, 1=full report) [0]

EXAMPLE:
	xe-cor1 temp.dat -cx 5 -cy 7
OUTPUT: n, r, intercept and slope

----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-cor3"><a href="#CODE">&#8679</a> xe-cor3</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-cor3 v 10, 20.May.April.2016 [JRH]
----------------------------------------------------------------------
Calculate correlation over time between signals at multiple frequencies
- interpolates non-numeric data, NaN and Inf
- pads either end of the two data series (padding = 4.0/min, see below)
- bandpass filters at each frequency of interest
- correlates signals in a sliding (50% overlap) window 2 wavelengths wide
USAGE:	xe-cor3 [input] [options]
	[input]: file name or "stdin" with time, x, and y columns
VALID OPTIONS [DEFAULT IN BRACKETS]...
	-ct column containing time values [1]
	-cx column containing independent variable [2]
	-cy column containing dependent variable [3]
	-min lower frequency at which to calc. correlation [1]
	-max upper frequency at which to calc. corelation [100]
	-fstep by which to incriment frequency from min to max [1]
		NOTE: set to -1 to analyze entire range in one steb
			- in this case time-window size is scaled to low freq.
			- in this case time-step is scaled to high freq.
	-label: window-labels identify start(1) middle(2) or end(3) time [1]
	-filt: filter type (1=Butterworth, 2=FIR) [1]
	-res: filter resonance (0.1 to sqrt(2)=1.4142) [1.4142]
		NOTE: low values can produce ringing in the output
		NOTE: high values can dampen the signal
	-w: use fixed window size (0=AUTO, 2/frequency) [0]

EXAMPLE:
	xe-cor3 temp.dat -cx 5 -cy 7
OUTPUT:
	freq	window	time	nsamps	r_data	r_phase
NOTE: output times correspond with the start of each window
NOTE: last window for each line may be NAN if there are &#603 data
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-correlate"><a href="#CODE">&#8679</a> xe-correlate</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-correlate v 2: 18.April.2016 [JRH]
----------------------------------------------------------------------
Perform Pearson's correlation analysis on an input
	- on-the-fly analysis (no memory overhead)
	- non-numeric values ignored
	- requires at least 4 valid data-points
	- "r" will be "0" for data describing vertical/horizonatal lines
	- "F" will be "99" for nearly-perfect correlations
USAGE:
	xe-correlate [filename] [arguments]
		[filename]: file name or "stdin"
VALID OPTIONS: defaults in []
	-cx column containing independent variable [1]
	-cy column containing dependent variable [2]
	-xmin minimum value of independent value to include [nan]
	-xmax maximum value of independent value to include [nan]
	-invalid numerical data entries to omit [nan]
	-verb sets verbosity (0=one-line, 1=headered, 2=full report[0]
EXAMPLES:
	xe-correlate data.txt -cx 2 -cy 3 -invalid -1
	cut -f 2,3 temp.txt | xe-correlate stdin
OUTPUT:
	-verb 0-1: r,r2,dfa,dfb,F,prob,slope,intercept
	-verb 2  : verbose summary
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-csd1"><a href="#CODE">&#8679</a> xe-csd1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-csd1 v 1: 6.October.2014 [JRH]
----------------------------------------------------------------------
Convert a voltage matrix of current source density
Formula: Ix = -s[ (Ex-h -2*Ex + Ex+h) / (4*h*h) ]
	Ix = current density at site x
	Ex is extracellular voltage at location x
	h is the sampling distance between recording sites
	s is an unknown constant - ignored
USAGE:
	xe-csd1 [input] [options]
	[input]: file or "stdin" in matrix (time x depth) format
VALID OPTIONS (defaults in []):
	-s : spacing between recording sites(mm) [0.100000]
EXAMPLES:
	xe-csd1 matrix.txt -s 0.01
	cat matrix.txt | xe-csd1 stdin -s 0.01
OUTPUT:
	An time x depth CSD matrix
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-curveinflect1"><a href="#CODE">&#8679</a> xe-curveinflect1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-curveinflect1 v 1: 29.April.2019 [JRH]
----------------------------------------------------------------------
Detect inflections in a curve
- assumes one valid numeric value per input line
- interpolates, oversamples and filters the data to aid detection
USAGE: xe-curveinflect1 [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-sr: sample-rate (Hz) of input [1000]
	-off: start-sample offset (seconds) [0]
	-mul: multiplier for sample-rate [4]
	-low: low-cut filter (Hz, 0=NONE) [0]
	-high: high-cut filter (Hz, -1=AUTO, 0=NONE) [-1]
		AUTO= sr/2
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-curveinflect1 data.txt -sr 1000 -mul 4 -low 10 1
	cat temp.txt | xe-curveinflect1 stdin -sr 1000 -mul 2
OUTPUT:
	higher-resolution, filtered values
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-curvestats1"><a href="#CODE">&#8679</a> xe-curvestats1</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-curvestats1 v 5: 21.September.2017 [JRH]
----------------------------------------------------------------------
Calculate area under the curve & other stats for single-column input
Non-numeric values will be ignored
This version only uses the x-values to set inclusion limits

USAGE:
	xe-curvestats1 [input] [options]
	[input]: file name or "stdin"

VALID OPTIONS:
	-sf: sample frequency (sample/s) [1.000000]
	-pre: presample period [0]
	-index: comma-separated start/stop pairs [(null)]
		- if -sf is set to "1", -pre and index are in samples
		- otherwise, -pre and index are in seconds
	-d: delta value to use for integration [default=1/sf]
	-f: output format (0=line, 1=line+header,2=keywords) [1]

EXAMPLES:
	xe-curvestats1 data.txxt -sf 200 -pre .5 -d 1 -index 0,.05,.05,.17
	cat temp.txt | xe-curvestats1 stdin -sf 1000 -pre 0

OUTPUT: format 1
	zone start stop n AUC AUCn Xn Yn AUCp Xp Yp median COM

OUTPUT: format 2
	[zone_keyword] [value]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-curvestats2"><a href="#CODE">&#8679</a> xe-curvestats2</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-curvestats2 v 7: 19.September.2017 [JRH]
----------------------------------------------------------------------
Calculate area under the curve (AUC) for multiple rows of input
Large-input-friendly: only one row of data stored in memory at a time
Interprets the x-values from min,max and number of values on each line
Assumes rows are tab or space-delimited
Missing and non-numeric values will be interpolated
NOTE: extra delimiters are interpreted as missing values (NAN)
NOTE: all input lines processed (including comments, etc)
USAGE:
	xe-curvestats2 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-min: presumed minimum x-value of first item on each line [0]
	-max: presumed maximum x-value of last item on each line [1]
		- delta inferred as (max - min)/(items_on_line - 1)
	-d: fixed AUC delta for interation on each line [unset by default]
		- if set, overrides -max
		- new max = min + delta x items_on_line
	-index: comma-separated start/stop index pairs [unset by default]
		- stop for each pair is excluded
		- indices must be &#62=min and &#60=(max+1)
		- if unset, uses min and max+delta 
		- note that AUC calculation requires at least two points
	-avg: divide AUC values by number of values (0=NO 1=YES)  [0]
		- use this for normalized values like coherence
	-f: output format: 1=line per zone, 2=all zones on one line [1]
EXAMPLES:
	xe-curvestats2 data.txt -int .001 -off -5 -d 1 -index 0,.05,.05,.17
	cat temp.txt | xe-curvestats2 stdin -sf 1000 -pre 0
OUTPUT:
	format1: &#60line&#62&#60zone&#62&#60start&#62&#60stop&#62&#60n&#62&#60AUC&#62
	format2: &#60line&#62&#60AUC0&#62&#60AUC1&#62&#60AUC2&#62... etc.
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-cut1"><a href="#CODE">&#8679</a> xe-cut1</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-cut1 v 4: 11.November.2018 [JRH]
----------------------------------------------------------------------
Extract columns from input based on labels in the first line
	- the order of columns can be rearranged
	- multiple copies of a column can be output
	- for duplicated labels, only the last column matching is output
	- the line-count will be preserved (blank lines are output)
	- missing columns will be replaced by a delimiter

USAGE: xe-cut1 [input] [labels] [options]
	[input]: file name or "stdin"
	[labels]: comma-separated list of column labels

VALID OPTIONS (defaults in []):
	[-n]: labels are numeric (1) instead of defined by header (0) [0]
	[-s]: skip #-comments and blank lines (0=NO 1=YES) [0]
		NOTE: "#" must be first character on the line
		NOTE: blank lines cannot contain spaces or tabs
	[-o]: omit outputting header-line (0=NO, 1=YES) [0]
	[-d]: characters to use as column-delimiters (unset by default)
		if unset:
		- white-space (blanks,tabs) are used
		- multiple consecutive delimiters are treated as one delimiter
		- suitable for reading files without "empty" columns
		if set:
		- behaviour is similar to the linux "cut" command
		- any matching delimiter in the input marks a new column
		- multiple consecutive delimiters signify "empty" colmns
		- suitable for reading CSV files, for example
	[-c]: just count the words on each line (0=NO 1=YES) [0]

EXAMPLES:
	xe-cut1 data.txt name,phone,address
	cat temp.txt | xe-cut1 stdin phone,name,name -d "\t "

OUTPUT:
	the labelled columns, in the order and number specified
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-cut2"><a href="#CODE">&#8679</a> xe-cut2</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-file">file</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-cut2 15.February.2019 [JRH]
----------------------------------------------------------------------
Extract blocks of lines from a text file
- must define a character-string marking the beginning of each block
- default behaviour is to extract this line and all subsequent lines
- override this by using any combination of stop-options (s1,s2,s3,s4)
USAGE:
	xe-cut2 [input] [start]
	[input]: file name or "stdin"
	[start]: quoted text marking start of block to be extracted
VALID OPTIONS: defaults in []
- stop on line (and do not extract) if...
	-s1 line is blank (0=NO 1=YES) [0]
	-s2 1st character matches that of start (eg. #,%,/) (0=NO 1=YES) [0]
	-s3 line matches this quoted string of characters [unset]
	-s4 line indentation is &#60= that of [start] (0=NO 1=YES) [0]
	-verb sets verbosity (0=simple, 1=verbose) [0]
EXAMPLES:
	xe-cut2 data.txt "# block1" -s1 1 -s3 "# block2"
	cat temp.txt | xe-cut2 stdin "% START" -s1 1
OUTPUT:
	the desired block of text, sent to stdout
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-dateconv1"><a href="#CODE">&#8679</a> xe-dateconv1</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-dateconv1 v 6: 27.Jan.2018 [JRH]
----------------------------------------------------------------------
Convert date to 6- or 8-digit format (yymmdd or yyyymmdd)
Assumes one date per input line
Accepts three possible field delimiters: / . -
USAGE:
	xe-dateconv1 [input] [options]
		[input]: file name or "stdin"
VALID OPTIONS:
	-h: input has header-line (0=NO 1=YES) [0]
	-c: column holding date [1]
	-i: input format [1]
		1: UK   (dd/mm/yyyy)
		2: USA  (mm/dd/yyyy)
		3: JP   (yyyy/mm/dd)
		4: LDAS (yyyymmdd)
	-o: output format [4]
		1: UK   (dd/mm/yyyy)
		2: USA  (mm/dd/yyyy)
		3: JP   (yyyy/mm/dd)
		4: LDAS (yyyymmdd)
		...2-digit-year formats...
		5: (yymmdd)
		6: (yy:mm:d)
		...other formats...
		7: week 0-52, Monday=1st day of week
		8: day 1-365
	-z: date-zero (for -o 7 or 8) - must match -i format [(null)]
	-v: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-dateconv1 dates.txt -i 1
	echo 12-31-1999 | xe-dateconv1 stdin -i 2
OUTPUT:
	one modified date per valid input line
	example:  19991231
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-dbmatch1"><a href="#CODE">&#8679</a> xe-dbmatch1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-database">database</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-dbmatch1 v 5: 15.January.2019 [JRH]
----------------------------------------------------------------------
Extract database lines if a column matches/non-matches a pattern
- assumes database file in which first line contains column labels
- can also be used for files with no column labels (see -cn option)
- blank lines and lines beginning with "#" will be ignored
- an XML tag can be specified defining a section contiaining the data
USAGE:
	xe-dbmatch1 [input] [column] [pattern]
	[input]: file name or "stdin"
	[column]: column label (or number) containing value to match
	[patterns]: comma-separated patterns to detect in column (see -m)
			- at least one pattern must match 
VALID OPTIONS:
	[-xml]: XML section containing header-line and data [(null)]
	[-m]: pattern match mode [2]
		 1= contains at least one pattern
		 2= exact match with at least one pattern
		-1= contains none of the patterns
		-2= exact match with none of the patterns
	[-cn]: treat [column] as column-number (0=NO, 1=YES) [0]
		- if set, assumes no header line
	[-o]: omit outputting header-line (0=NO, 1=YES) [0]
	[-oc]: output column (see also -cn) [default=all, "\n" if missing]
	[-d]: characters to use as column-delimiters [unset]
		if unset:
		- white-space (blanks,tabs) are used
		- multiple consecutive delims are treated as one
		- suitable for reading files without "empty" columns
		if set:
		- behaviour is similar to the linux "cut" command
		- any matching delim in the input marks a new column
		- multiple consecutive delims signify "empty" columns
		- suitable for reading CSV files, for example
EXAMPLES:
	xe-dbmatch1 table_cells.txt subject 02 -oc DOB -cn 0
	xe-dbmatch1 table_cells.txt 1 dog,cat -oc 4 -cn 1
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-dbmatch2"><a href="#CODE">&#8679</a> xe-dbmatch2</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-dbmatch2 4.May.2019 [JRH]
----------------------------------------------------------------------
Read an input and append the matching value from a keyfile
- match is performed on a column from the input and the keyfile
- the appended value is in a specified column in the keyfile
- if there is no matching key, a "-" will be appended instead
- matches are case-sensitive and must be exact (eg. 3 does not equal 03)
USAGE:
	xe-dbmatch2 [input] [col] [keyfile] [val]  [options]
	[input]: file name or "stdin" with key-column to be matched
	[col]: input column to match with key
	[keyfile]: file with key- and value-columns
	[val]: column in keyfile containing values to append
VALID OPTIONS:
	[-k]: key-column to match in keyfile [ default=[col] ]
	[-d]: characters to use as column-delimiters ["\t"]
		- max 16 characters permitted
		- any delimiter in the input marks a new column
		- the first delimiter is used for the output
EXAMPLES: add group-names to a file with only group-no. specified
	xe-dbmatch2 data.txt group names.txt name -d ","
OUTPUT:
	input + matching values from keyfile appended on each line
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-decimate1"><a href="#CODE">&#8679</a> xe-decimate1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-decimate1 v 1: 23.June.2014 [JRH]
----------------------------------------------------------------------
Decimate data by outputting every Nth line (N can be a fraction)
Decimation is performed on the fly, so there is no memory overhead

USAGE: xe-decimate1 [input][N]
	[infile]: data file or "stdin" - can be multi-column
	[N]: samples between each output [1]
		- can be a fraction
		- must be greater than or equal to 1
		- if exactly 1, every input value is output
		- first input value is always outptut

OUTPUT: 
	the decimated (down-sampled) version of the input

EXAMPLE: 
	to reduce the sample-rate of an input from 496Hz to 400Hz
	N= 496/400 = 1.24

	xe-decimate1  data.txt 1.24
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-delimit"><a href="#CODE">&#8679</a> xe-delimit</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-delimit v 1: 23.October.2018 [JRH]
----------------------------------------------------------------------
Delimits columns of data in a text file with a delimiter of your choice
- Replaces multiple spaces tabs and commas
- Eliminates leading white-spaces
- maximum line length= 10000 characters
USAGE: xe-delimit [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-d: delimiter- tab,space,comma,colon,semicolon, or newline [tab]
	-c: delimit comment lines (#) as well? 0=NO, 1=YES [1]
	-out: name of output file [stdout = output to screen] [stdout]
EXAMPLES:
	xe-delimit a.txt -d tab -out temp.txt 
	cat a.txt | xe-delimit stdin -d comma

</blockquote></pre>

<font color="Black"><h3 id="code-xe-delimitkiller"><a href="#CODE">&#8679</a> xe-delimitkiller</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-delimitkiller v 1: 23.October.2018 [JRH]
----------------------------------------------------------------------
Remove extra delimiters from an input
USAGE: xe-delimitkiller [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-d delimiter: tab,space,comma,colon,semicolon,underscore or newline [tab]

EXAMPLES:
	xe-delimitkiller a.txt -d tab 
	cat a.txt | xe-delimitkiller stdin -d comma

</blockquote></pre>

<font color="Black"><h3 id="code-xe-demean1"><a href="#CODE">&#8679</a> xe-demean1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-demean1  v 2: 29.February.2016 [JRH]
----------------------------------------------------------------------
De-mean a data series using a sliding ring-buffer window
Averaging is performed on the fly, so there is little memory overhead
This is effectively a high-pass filter, with the advantage of
	permitting in-line processing (only the buffer is stored in memory)
Non-numerical values, NAN and INF will be converted to zero

USAGE: 
	xe-demean1 [input][nwin]
		[infile]: single-column data file or "stdin"
		[nwin]: number of values to average at a time
			- must be an integer greater than or equal to 3

OUTPUT: 
	- the de-meaned data, one output for every input 
EXAMPLE: apply a 5Hz high-pass filter to data stream sampled at 1KHz
	xe-demean1data.txt 200
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-density1"><a href="#CODE">&#8679</a> xe-density1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-density1 v2: 30.September.2018 [JRH]
----------------------------------------------------------------------
Calculate the density (binned sums) in a 1-dimensional data series
USAGE: xe-density1 [input] [options] 
	[input]: input file or "stdin")
VALID OPTIONS (defaulst in []):
	-f : input format: 1=&#60time&#62  2=&#60time&#62&#60value&#62 [1]
		1: density= total lines for each &#60time&#62
		    missing values result in zero
		2: density= sum|mean of &#60values&#62 for each &#60time&#62
		    missing values result in NAN
	-b : total number of bins [100]
	-w : binwidth (overrides -b) in units of &#60time&#62 (-1=auto) [-1]
	-n : normalize data: -1=no, 0=0-1 range, 1=z-scores[-1]
	-s : Gaussian smoothing factor (samples) to apply to bins [0]
	-min : minimum time-value to include [unset]
	-max : maximum time-value to include [unset]
	-trim : trim-threshold (0-1) for last bin (0=NONE) [0]
	    - i.e. proportion of last bin at which the highest time
	      must be, to avoid rejecting this bin. The need can arise
	      because acquired data often includes a time-stamp at a
	      cutoff duration (eg. 60sec). If the binsize is 1sec,
	      the bin starting at 60sec will be undersampled and
	      should probably not be included
	-out : output (1=count, 2=count/unit-time)1 [1]
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLE: xe-density1 temp.txt -min 0 -w 1 -trim 0.75
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-densitymatrix1"><a href="#CODE">&#8679</a> xe-densitymatrix1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-densitymatrix1 v 10: 23.October.2018 [JRH]
----------------------------------------------------------------------
Create a density matrix from 2-column (x,y) or 3-column (x,y,z) input
USAGE: xe-densitymatrix1 [input] [options] 
	[input]: input file or "stdin")
VALID OPTIONS (defaulst in []):
	-f : format of input: 1=&#60x&#62&#60y&#62  2=&#60x&#62&#60y&#62&#60z&#62 [1]
		1:	density= total lines of a given &#60x&#62&#60y&#62
			missing x/y values result in zero
		2:	density= sum of &#60z&#62 for a given &#60x&#62&#60y&#62
			missing x/y values result in NAN
		3:	density= mean of &#60z&#62 for a given &#60x&#62&#60y&#62
			missing x/y values result in NAN
	-x : matrix width (bins, 0=AUTO) [-1]
	-y : matrix height (bins, 0=AUTO) [-1]
		NOTE: setting -x or -y to 0 sets width or height to
		the number of unique elements in the &#60x&#62 or &#60y&#62 columns
	-n : normalize data: -1=no, 0=0-1 range, 1=z-scores[-1]
	-sx : 2D gaussian smoothing factor to apply to matrix [0]
	-sy : 2D gaussian smoothing factor to apply to matrix [0]
	-xmin : force matrix to use this as the x-minimum [unset]
	-ymin : force matrix to use this as the y-minimum [unset]
	-xmax : force matrix to use this as the x-maximum [unset]
	-ymax : force matrix to use this as the y-maximum [unset]
	-yflip : flip matrix 0,0=top-left (0=NO, 1=YES) [0]
 - EXAMPLE: xe-densitymatrix1 temp.txt -x 100 -y 25 -p 1 -s 0
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-densitymatrix2"><a href="#CODE">&#8679</a> xe-densitymatrix2</h3></font>
[<a href="#tag-transform">transform</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-densitymatrix2 v.6: 23.November.2015 [JRH]
----------------------------------------------------------------------
Generate a freq. x time density matrix from 3-columned input
Designed for files with unequal time categories per frequency band
Resamples so each row (frequency) has the same number of columns
Will average multiple entries for the same time/freq
USAGE:
	xe-densitymatrix2 [input] [freq] [time] [density]
	[input]: file or "stdin" with freq,time & coherence columns
	[freq] column defining frequency [2]
	[time] column defining time [3]
	[density] column containing density values [4]
VALID OPTIONS:
EXAMPLES:
	xe-densitymatrix2 CO2_coherence.txt 1 2   4
	cat temp.txt | xe-densitymatrix2 stdin 2 2 4   7
OUTPUT:
	average-density matrix - row = frequency, column=time
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-detectcycles2"><a href="#CODE">&#8679</a> xe-detectcycles2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-detectcycles2 v 7: 7.April.2015 [JRH]
----------------------------------------------------------------------
Detect cycles in a given frequency range in a BINARY file
Non-numeric values will be interpolated
Includes padding and filtering function
USAGE:
	xe-detectcycles2 [input] [options]
	[input]: file name:  Format= 2 columns: &#60time&#62 &#60data&#62
VALID OPTIONS:
	-dt: type of data [3]
		0-9= uchar,char,ushort,short,uint,int,ulong,long,float,double
	-sf: sample frequency (sample/s) [1000.000000]
	-h: size of header (bytes) excluded from output [0]
	-s: start reading at this element (zero-offset) [0]
	-n: number of elements to read (0=all) [0]
		NOTE: -s and -n will be internally converted to bytes
	-low: minimum frequency to detect (-1 = no lower bound) [4]
	-high: maximum frequency to detect (-1 = no upper bound) [12]
	-res: filter resonance (0.1 to sqrt(2)=1.4142) [1]
		NOTE: low values can produce ringing in the output
		NOTE: high values can dampen the signal
	-o: output [1]: 
		1=cycle start peak stop and amplitude
			NOTE: amplitude= peak - ((start+stop)/2)
		2=filtered data
		3=average waveform of cycles, normalized to the width of the shortest cycle
	-z: amplitude normalization (output style 1 only) [-1]: 
		-1= none
		 0= proportion of peak
		 1= standard score, z= (value-mean)/stddev
EXAMPLES:
OUTPUT:
	See "-o" option, above
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-detectevents1"><a href="#CODE">&#8679</a> xe-detectevents1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-detectevents1 v 4: 12.November.2018 [JRH]
----------------------------------------------------------------------
Thresholded event-detection in a time series
- non-numeric and non-finite values will be interpolated
- optional notch and Butterworth filtering
- normalization to baseline or user-defined mean & std.dev
USAGE:
	xe-detectevents1 [input] [options]
	[input]: file name or "stdin" representing data series
VALID OPTIONS:
	-dt: type of data [-1]
		-1 = ascii
		0-9= uchar,char,ushort,short,uint,int,ulong,long,float,double
	-verb sets verbosity (0=simple, 1=verbose) [0]
 ...filter options...
	-sf sample-frequency (Hz) - must be &#620 if filters are used [-1]
	-notchw: notch filter width (Hz, 0=none) [0]
	-notchf: notch filter stop-band, Hz) [50]
	-low: Butterworth filter low freq. limit (0=none) [0]
	-high: Butterworth filter high freq. limit (0=none) [0]
 ...z-score normalization options...
	-base1: start-sample for baseline-derived z-score [-1]
	-base2: stop-sample  for baseline-derived z-score [-1]
		-1,-1= skip, 0,-1= use total dataset
	-z1: manually define subtractor (mean, 0=none) [0]
	-z2: manually define divisor (stddev, 1=none) [1]
 ...threshold options...
	-t: detecton lower threshold [3]
		NOTE: can be positive or negative
	-e: multiple of -t (0-1) defining event edges) [0.5]
	-u: multiple of -t (&#621) defining rejection limit [10]
		- event peak values must fall between (-t) and (-u)*(-t) 
	-s: detecton sign (-1=negative, +1=positive, 0=either) [0]
		NOTE: for -ive, -t may also need to be -ive
	-min: minimum event length (0=none) [1]
	-max: maximum event length (0=none) [0]
	-ref: impose refractory period between peaks (0=none) [0]
	-pre: reserved samples before each event peak [0]
	-post: reserved samples after each event [0]
		- pre and post determine the first and last input sample
		  which can be used for detection of valid events
		- eg. -pre 5 rejects events before input sample 5
EXAMPLES:
	xe-detectevents1 data.txt -t 3  -e 0.5 -s 1 -min 12000 -max 120000
	cat temp.txt | xe-detectevents1 stdin -t 3
OUTPUT:
	event	start	peak	stop	pval	apval

	event: event-number (starts from 0)
	start: sample-number for leading edge of event
	peak:  sample-number for peak (minimum of maximum) of event
	stop:  sample-number for trailing edge of event
	pval:  data-value at peak (filtered, but pre-normalization)
	npval: normalized pval (see z-score options)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-detectnoise1"><a href="#CODE">&#8679</a> xe-detectnoise1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-detectnoise1 v 1: 6.October.2017 [JRH]
----------------------------------------------------------------------
Detect single-frequency deflections in a frequency power spectrum
	- signal must drop off either side of the noise peak
	- hence no detection at edges of spectra
	- non-numeric and non-finite values will be interpolated
USAGE:
	xe-detectnoise1 [input] [options]
	[input]: file name or "stdin" in format &#60freq&#62 &#60amp&#62
VALID OPTIONS:
	-t: change-threshold (+ive, or -1=auto) [-1]
		-if auto, thresh= 1.5*std.dev
	-w: window-size (odd number-of-frequencies) [3]
	-min: lowest noise-search frequency (-1=auto) [-1]
	-max: lowest noise-search frequency (-1=auto) [-1]
	-list: CSV list of frequencies to estimate noise levels at []
		- NOTE: will override -t
	-verb sets verbosity (0=simple, 1=verbose) [0]
EXAMPLES:
	xe-detectnoise1 spectxt -t 3 
	cat temp.txt | xe-detectnoise1 stdin -t 3
OUTPUT: for each detected noise peak...
	freq	noise

	freq: frequency at which noise was found
	noise: mean change from window-middle to each edge
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-detectsync1"><a href="#CODE">&#8679</a> xe-detectsync1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-detectsync1 v 1: 28.March.2014 [JRH]
----------------------------------------------------------------------
Detect valid sync-pulse-sequences in a series of timestamps
USAGE:
	xe-detectsync1 [input] [options]
	[input]: file name or "stdin"
		- a list of individual sync pulse times (any units)
		- assumes one valid numeric value per input line
		- blank lines and non-numeric values will be ignored
VALID OPTIONS:
	-count: number of sync-pulses required in a row [1]
	-dur: duration (units) within which the sequence must be detected [0]
	-gap: gap (units) required before start & end of the sequence [0]
EXAMPLES:
	to detect 4-sync-pulses within 0.5s surrounded by a 1s gap...
	xe-detectsync1 sync.txt -count 4 -dur 0.5 -gap 1
OUTPUT:
	time representing the first pulse in each valid sequence
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-detrend1"><a href="#CODE">&#8679</a> xe-detrend1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-detrend1 v 1: 19.March.2014 [JRH]
----------------------------------------------------------------------
Remove linear trend from a data series
Will interpolate invalid or non-finite data points
USAGE:
	xe-detrend1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
EXAMPLES:
	xe-detrend1 data.txt 
	cat temp.txt | xe-detrend1 stdin 
OUTPUT:
	single column of de-trended data
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-distvel3"><a href="#CODE">&#8679</a> xe-distvel3</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-distvel3 v 2: 2.August.2012 [JRH]
----------------------------------------------------------------------
Calculate distance travelled and velocity in a time-x-y series
USAGE:
	xe-distvel3 [position data] [options]
	[position data]: filename or "stdin", format: &#60time&#62&#60x&#62&#60y&#62
VALID OPTIONS (defaults in []):
	-t: time (s) over which to integrate movement distance [0.4]
EXAMPLES:
OUTPUT: 
	a series of distance-travelled and velocity values 
NOTES:
	- output is for last sample in each integration window
	- one line output for each non-blank line of input
	- blank lines will cause misalignment with original data series
	- invlid times or x/y values result in "-1 -1" output
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-elp-readscore1"><a href="#CODE">&#8679</a> xe-elp-readscore1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-elp-readscore1 v 5: 1.July.2013 [JRH]
----------------------------------------------------------------------
Read a SCORE raw file and output as ASCII or binary stream
Non-numeric values will be recoded "NaN"
USAGE:
	xe-elp-readscore1 [input] [options]
	[input]: file name
		NOTE: input is pre-read to determine size
VALID OPTIONS:
	-h: output ASCII headers only (0=NO, 1=YES) [0]
	-asc: ASCII output, 1=YES 0=NO, (USE BINX binary format) [1]
	-start: first block of 10-seconds to output[1]
	-stop: last block of 10-seconds to output (0 = all) [0]
EXAMPLES:
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-energyvec1"><a href="#CODE">&#8679</a> xe-energyvec1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-energyvec1 v 1: 26.October.2013 [JRH]
----------------------------------------------------------------------
Output the energy envelope in a signal at frequency f
Complex wavelet convolution is used to filter & transform the signal
Assumes one value per input line
Non-numeric values will be ignored
USAGE:
	xe-energyvec1 [input] [options]
	[input]: file name or "stdin", format= single column
VALID OPTIONS:
	-sf: sample frequency of input (sample/s) [24000.000000]
	-f: central frequency for band-pass filtering [8.000000]
	-c: number of cycles in the wavelet [7]
	-v: verbocity (0=energyvec, 1=detailed, 2=wavelet) [1]
		* detailed output = [output-label] [sample] [output]
		* labels: 0=original 1=filtered 3=energy envelope
EXAMPLES:
	xe-energyvec1 data.txt -sf 400 -f 60 
	cat temp.txt | xe-energyvec1 stdin -sf 1500 -f 60 -v 1 
OUTPUT:
	-v 0: single column, energy-vector
	-v 1: [label] [time] [data] (1=original, 2=filtered, 3=envelope)
	-v 2: single column, wavelet
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-energyvec2"><a href="#CODE">&#8679</a> xe-energyvec2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-energyvec2 v 2: 15.February.2014 [JRH]
----------------------------------------------------------------------
Output the energy envelope in a signal at frequency f
Biquad Butterworth filter applied and sliding-window RMS calculated
Assumes one value per input line
Non-numeric values will be ignored
USAGE:
	xe-energyvec2 [input] [options]
	[input]: file name or "stdin", format= single column
VALID OPTIONS:
	-sf: sample frequency (sample/s) [100.000000]
	-f: central frequency for band-pass filtering [0.000000]
	-res: resonance (0.1 to sqrt(2)=1.4142) [1]
		NOTE: low values can produce ringing in the output
		NOTE: high values can dampen the signal
	-pad: apply cosine-tapered padding? (-1=AUTO,0=NO,&#620=SAMPLES) [-1]
		*note: auto = 1/4 record or 4*interval if -f is specified
	-c: number of cycles spanned by window for RMS calculation [5]
	-v: set verbose output (0=NO,1=YES) [0]
EXAMPLES:
	xe-energyvec2 data.txt -t 1
	cat temp.txt | xe-energyvec2 stdin -t 3
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-fftcoh3"><a href="#CODE">&#8679</a> xe-fftcoh3</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-fftcoh3 v1: 27.May.2019 [JRH]
--------------------------------------------------------------------------------
Calculate coherence between two inputs using FFT (Kiss-FFT)
Assumes data consists of real values only
FFT is performed on overlapping windows in which data is de-meaned and tapered
USAGE:	xe-fftcoh3 [in1] [in2] [options] 
	[in1]: first input file stream 
	[in2]: second input file, of the same length 
VALID OPTIONS (defaults in [])
	-dt: data type (-1=ASCII, 0-9=BINARY) [1]
	    0-9: uchar,char,ushort,short,uint,int,ulong,long,float,or double
	-sf: sampling frequency of the input, in Hz [1]
	-max: highest frequency to output [default= sr/2]
	-min: lowest frequency to output [default= 800/datalength]
	    : note: typically produces decent-looking 400-timepoint coherograms
	-w: length of data windows passed to FFT function) (0=AUTO) [0]
	    : must be an even number, AUTO= 2*(sr/min)
	-scrf: screening file (.ssp) for defining blocks of data [unset]
		* NOTE: use only to define large blocks of data (minutes)
		* if unset, single block for entire input is assumed
		* -o 0: output's mean spectrum for all windows and all blocks
		* -o 1: each matrix will have a block-header
	-a: windows accumulated before calculating coherence, min=2 [8]
	-adj: adjust coherence to correct for accumulation (0=NO 1=YES) [1]
	-s: number of steps for the sliding window to span one buffer length [1]
	    : e.g. if -b 8 -s 2, the buffer moves by 8/2=4 samples per FFT
	    : note: more steps = more data overlap (artificially high coherence)
	-t: tapering, 0=NO, 1=YES (Hann taper) [1]
	    : note: tapering inflates coherence (same taper applied to both inputs)
	-v: set verbocity of output to quiet (0) or report (1) [0]
	-o: output style (0,1, or 2) [0]
	    : 0=average spectrum, 1=time_v_freq matrix, 2=list of columns
	    : if set to 1, each line is the coherence for two buffers
	-g: apply Gaussian smoothing to output (avg.spectrum only) (0= none) [0]
	    : -g must be 0 or an odd number 3 or larger)
EXAMPLES: xe-fftcoh3 [input] [options] 
	xe-fftcoh3 data.txt -sf 24000 
	cat data.bin | xe-fftcoh3 stdin -sf 1000 -s 8
OUTPUT: 
	if -out 0:  &#60frequency&#62 &#60coherence&#62
	if -out 1:  matrix of coherence values, row=buffer (time), column=frequency
	if -out 2:  &#60time1&#62 &#60time2&#62 &#60frequency&#62 &#60coherence&#62
		&#60time1&#62 and &#60time2&#62 bound the window in which coherence is calculated

</blockquote></pre>

<font color="Black"><h3 id="code-xe-fftfilt1"><a href="#CODE">&#8679</a> xe-fftfilt1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-fftfilt1 v 3: 15.March2014 [JRH]
--------------------------------------------------------------------------------
Use KISS-FFT functions to filter data using overlap-and-add method
Requires input from a file or standard input, one column only
FFT is performed on overlapping chunks of buffered data
Produces one column of filtered output
USAGE:	xe-fftfilt1 [input] [options] 
	[input]: provide a filename or "stdin" to receive piped data
VALID OPTIONS (defaults in [])
	-asc: is input/output ASCII? (1=YES, 0=NO, BINX binary input is assumed) [1.5316e-322]
	-sf: sampling frequency (Hz) of the input [1]
	-min: lowest frequency to output [default= 2/nsamples]
	-max: highest frequency to output [default= sr/2]
	-b: length of buffers (windows) of data passed to FFT function) [-1 = auto]
		* must be an even number, not necessarily a power of two
		* by default, auto = 2*(sr/min)
		* longer window = more detailed output but lower temporal resolution
		* frequency resolution = sample_frequency / buffer_size
	-s: number of steps for the sliding window to span one buffer length [2]
		* NOTE: CURRENTLY MUST BE TWO!
	-v: set verbocity to quiet (0) report (1) or tapers-only (-1) [0]
EXAMPLES: xe-fftfilt1 [input] [options] 
	xe-fftfilt1 data.txt -t bin -sf 1500 
	cat data.bin | xe-fftfilt1 stdin -t asc 
OUTPUT: 
	if -out 0:  &#60frequency&#62 &#60power&#62
	if -out 1:  matrix of power values, row=buffer (time), column=frequency
	if -out 2:  &#60time&#62 &#60frequency&#62 &#60power&#62

</blockquote></pre>

<font color="Black"><h3 id="code-xe-fftpow1"><a href="#CODE">&#8679</a> xe-fftpow1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-fftpow1 v 31: 11.November.2014 [JRH]
--------------------------------------------------------------------------------
Use KISS-FFT functions to produce a power spectrum density output
Requires input from a file or standard input, one column only
FFT is performed on overlapping chunks of buffered data
Power at each frequency is then averaged for entire file
Produces two columns: freq, power
USAGE:	xe-fftpow1 [input] [options] 
	[input]: provide a filename or "stdin" to receive piped data
VALID OPTIONS (defaults in [])
	-asc: is input/output ASCII? (1=YES, 0=NO, BINX binary input is assumed) [1]
	-sf: sampling frequency (Hz) of the input [1000]
	-min: lowest frequency to output [default= 2*sf/n or 0.1, whichever is higher]
	-max: highest frequency to output [default= sf/2]
	-b: length of buffers (windows) of data passed to FFT function) [-1 = auto]
		* must be an even number, not necessarily a power of two
		* by default, auto = 2*(sr/min)
		* longer window = more detailed output but lower temporal resolution
		* frequency resolution = sample_frequency / buffer_size
	-s: number of steps for the sliding window to span one buffer length [2]
		* e.g. if -b 8 -s 4, the buffer moves by 8/4=2 samples per FFT
		* NOTE: must be a factor of the buffer length
	-f: file containing start-samples for windows
		* this will override the -s option
		* if unset, windows are automativcally defined to span the data 
	-m: mean-correct data in each window (0=NO, 1=YES) [1]
		* mean-correction will slow processing
		* benefit may be seen with &#622 tapers, reducing low-frequency power
	-t: number of tapers to use, 5 is typical [1]
		* if set to 0, no tapering is applied
		* if set to 1, a single Hann taper is applied
		* otherwise, uses Sleppian (DPSS) tapers, multi-taper method applied
	-p: order of the tapers, typically 1 to 5, or -1=auto (ntapers+1) [-1]
	-g: apply Gaussian smoothing to output (avg.spectrum only) (0= none) [0]
		* note: -g must be 0 or an odd number 3 or larger)
	-u: set the units for spectrum output [0]
		0=peak amplitude (PA) = 2 x sqrt(FFTreal^2 + FFTimag^2)/windowsize
		1=RMS .......= PA x (sqrt(2)/2) 
		2=power......= RMS-squared
		3=dB PA......= 20*log10(PA)
		4=dB RMS.... = 20*log10(RMS)
		5=dB power...= 10*log10(power)
	-v: set verbocity to quiet (0) report (1) or tapers-only (-1) [0]
	-o: output average spectrum (0) or matrix of values (1) [0]
		* NOTE: if set to 1, each line is the spectrum for one buffer
		* this can be used to plot the spectrum over time
EXAMPLES: xe-fftpow1 [input] [options] 
	xe-fftpow1 data.txt -t bin -sf 1500 
	cat data.bin | xe-fftpow1 stdin -t asc 
OUTPUT: 
	if -out 0:  &#60frequency&#62 &#60power&#62
	if -out 1:  matrix of power values, row=buffer (time), column=frequency
	if -out 2:  &#60time&#62 &#60frequency&#62 &#60power&#62

</blockquote></pre>

<font color="Black"><h3 id="code-xe-fftpow2"><a href="#CODE">&#8679</a> xe-fftpow2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-fftpow2 v 6: 11.September.2018 [JRH]
--------------------------------------------------------------------------------
Use KISS-FFT functions to produce a power spectrum density output
Requires input from a file or standard input, one column only
FFT is performed on data windows which can overlap
Power at each frequency is then averaged for entire file
Produces two columns: freq, power
USAGE:	xe-fftpow2 [input] [options] 
	[input]: binary or single-column ASCII input, filename or "stdin"
VALID OPTIONS (defaults in [])
	-dt: data type [-1]
		-1  : ASCII
		0-9 : uchar,char,ushort,short,uint,int,ulong,long,float,double
	-sf: sampling frequency (Hz) of the input [1000]
	-min: min freq. [-1= default= 2*sf/n or 0.1, whichever is higher]
	-max: max freq. [-1= default= sf/2]
	-w: samples per FFT window (must be even, -1= scaled to min) [-1]
		* longer window = detailed output, low temporal resolution
		* frequency resolution = sample_frequency / window_size
	-s: steps for the sliding window to span one window length [1]
		* e.g. if -w 8 -s 4, the window moves by 8/4=2 samples per FFT
		* NOTE: must be a factor of the window length
	-scrf: screening file (.ssp) for defining blocks of data [unset]
		* NOTE: use only to define large blocks of data (minutes)
		* if unset, single block for entire input is assumed
		* -o 0: output's mean spectrum for all windows and all blocks
		* -o 1: each matrix will have a block-header
	-m: mean-correct data in each window (0=NO, 1=YES) [1]
	-t: taper type: 0=none, 1=Hann [1]
	-p: power to raise the taper, higher values increase slope [1]
	-g: apply Gaussian smoothing to output (avg.spectrum only) [0]
		* note: -g must be 0 (none) or an odd number 3 or larger)
	-u: set the units for spectrum output [0]
		0=peak amplitude (PA)= 2x sqrt(FFTreal^2 + FFTimag^2)/windowsize
		1=PA expressed as decibels
		2=RMS .......= PA x (sqrt(2)/2) 
		3=power......= RMS-squared
	-v: set verbosity to quiet (0) report (1) or taper-only (-1) [0]
	-o: output format (0-3) [0]
		0= spectrum averaged across windows and blocks
		1= matrix of values, row= time (window) column=frequency
		2= like (1) but with timestamp in 1st column
			- time is sample-number relative to input start
			- this takes into account block-reading (-scrf option)
		3= like (2) but with AUC for freq. bands instead of full spectrum
			delta = 0.5 - 4 Hz
			theta = 4 - 12 Hz
			beta  = 13 - 30 Hz
			gamma = 30 - 100 Hz
	-binout: binary (64-bit double) output (0=NO 1=YES) [0]
		* NOTE: binary output mean spectra do not include frequencies
		* NOTE: binary output matrices do not include block separators
		* NOTE: not available for -o 3
EXAMPLES: xe-fftpow2 [input] [options] 
	xe-fftpow2 data.txt -t bin -sf 1500 
	cat data.bin | xe-fftpow2 stdin -t asc 
OUTPUT: 
	if -o 0:  &#60frequency&#62 &#60power&#62
	if -o 1:  spectral matrix, row=window (time), column=frequency
	if -o 2:  &#60time&#62 &#60spectrum&#62
	if -o 3:  &#60time&#62 &#60deltapower&#62 &#60thetapower&#62 &#60betapower&#62 &#60gammapower&#62

</blockquote></pre>

<font color="Black"><h3 id="code-xe-filesize1"><a href="#CODE">&#8679</a> xe-filesize1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-filesize1 v 1: 24.March.2019 [JRH]
----------------------------------------------------------------------
Determine binary file size and/or record-count, duration etc
USAGE: xe-filesize1 [infile] [options]
	[input]: binary file name
VALID OPTIONS: defaults in []
	-sf: sample frequency (Hz) [1]
	-dt: data type [1]
		0: unsigned char
		1: signed char
		2: unsigned short
		3: signed short
		4: unsigned int
		5: signed int
		6: unsigned long
		7: signed long
		8: float
		9: double
	-head: header-bytes to be excluded from byte-count [0]
	-nch: number of interlaced channels [1]
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-filesize1 data.txt -t 1
OUTPUT:
	1st column: lower limit of each bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-filter_butterworth1"><a href="#CODE">&#8679</a> xe-filter_butterworth1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-filter_butterworth1 v 16: 16.March.2019 [JRH]
----------------------------------------------------------------------
Apply a bi-quad Butterworth filter to the input
	- high- and low-pass filtering performed in sequence
	- filtering is bidirectional to avoid temporal shifting of data
	- non-numeric values, NAN or INF will invalidate the output
USAGE:
	xe-filter_butterworth1 [input] [options]
	[input]: file name or "stdin" comprised of a single column
VALID OPTIONS:
	-dt: type of data [-1]
		-1 = ascii
		0-9= uchar,char,ushort,short,uint,int,ulong,long,float,double
	-sf: sample frequency (sample/s) [100.000000]
	-low: low frequency limit, 0=NONE [0]
	-high: high frequency limit, 0=NONE [0]
	-res: resonance (0.1 to sqrt(2)=1.4142) [1.4142]
		NOTE: low values can produce ringing in the output
		NOTE: high values can dampen the signal
	-m: de-mean the data (can reduce straight-line artefacts) [0]
		0: no de-meaning
		1: remove the mean before filtering
		2: as above but re-apply the mean after filtering
	-pad: apply data-padding? (-1=AUTO,0=NO,&#620=#SAMPLES) [-1]
		- AUTO: &#60=n, 200, 1sec, or if -sf&#60=1, 200 samples
		- padding duplicates last sample (sample & hold)
	-op: output padding as well as original data (0=NO,1=YES) [0]
	-int: interpolate across invalid data (0=NO,exit instead, 1=YES [1]
	-v: set verbose output (0=NO,1=YES) [0]
EXAMPLES:
	xe-filter_butterworth1 data.txt -t 1
	cat temp.txt | xe-filter_butterworth1 stdin -t 3
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-filter_clip1"><a href="#CODE">&#8679</a> xe-filter_clip1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-filter_clip1 v5: 16.September.2015 [JRH]
----------------------------------------------------------------------
Apply a clipping filter to the input
Clips data at user-defined min/max values
Clips data at user-defined min/max values
Non-numeric values, NAN or INF will also be "clipped"
USAGE:
	xe-filter_clip1 [input] [options]
	[input]: file name or "stdin" comprised of a single column
VALID OPTIONS:
	-dt: type of data  [-1]
		-1= ASCII
		 0-9= uchar,char,ushort,short,uint,int,ulong,long,float,double
	-dtout:output format (see -dt for options) [-1]
	-h: for binary input, size of header (bytes) excluded from output [0]
	-min: minimum valid value [-10]
	-max: maximum valid value [10]
		NOTE: if -min or -max are set to NAN, no filtering is performed
	-newmin: replacement minimum value [-min, by default]
	-newmax: replacement maximum value [-max by default]
	-nseq: required number of sequential values meeting criteria [1]
	-v: set verbose output (0=NO,1=YES) [0]
EXAMPLES:
	xe-filter_clip1 original.txt -max 0  &#62 clipped.txt
	xe-filter_clip1 original.bin -ascin -1 -dt 8 -max 0 -ascout -1 &#62 clipped.bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-filter_FIR1"><a href="#CODE">&#8679</a> xe-filter_FIR1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-filter_FIR1 v 3: 30.April.2016 [JRH]
----------------------------------------------------------------------
FIR filter program source-code
Assumes one valid numeric value per input line
Non-numeric values will be interpolated across
USAGE:
	xe-filter_FIR1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-sf: sample frequency (sample/s) [1.000000]
	-freq: corner freq. (LP,HP) or central freq. (BP, notch) [0.1]
	-pt: pass type 1=LP, 2=HP, 3=BP, 4=notch [1]
	-wt: window type (none,kaiser,sync) [kaiser]
		: windowing helps reduce ripple & other artefacts
	-bw: bandwidth, for BP and notch only [3]
	-ntaps: number of taps (51-255 recommended) [41]
		: 51 gives results similar to Butterworth
	-beta: transition bandwidth (0-10) for Kaiser or Sinc windows [0]
		: low values vive sharper cutoffs
	-out: output 0=coefficients, 1=filtered data [1]
	-shift: correct for shift (0-2) [2]
		0: no correction, data will be shifted forward
		1: back-shift data to correct, last-sample-padding added
		2: also avoid starting-artefact (add equal front-padding)
	-bad: alternative value to interpolate across [nan]
		NOTE: if data also contains NAN,INF or non-numeric
		values, then these may get used for interpolation
EXAMPLES:
	xe-filter_FIR1 data.txt -t 1
	cat temp.txt | xe-filter_FIR1 stdin -t 3
OUTPUT:
	1st column: lower limit of each bin
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-filter_notch1"><a href="#CODE">&#8679</a> xe-filter_notch1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-filter_notch1 v5: 18.September.2015 [JRH]
----------------------------------------------------------------------
Apply a bidirectional recursive notch filter to the input
	- filtering is bidirectional to avoid temporal shifting of data
	- non-numeric values, NAN or INF will invalidate the output
USAGE:
	xe-filter_notch1 [input] [options]
	[input]: file name or "stdin" comprised of a single column
VALID OPTIONS:
	-dt: type of data  [-1]
		-1= ASCII
		 0-9= binary uchar,char,ushort,short,uint,int,ulong,long,float,double
		NOTE: binary input will produce binary (float) output
	-h: for binary input, size of header (bytes) excluded from output [0]
	-sf: sample frequency (sample/s) [100.000000]
	-n: notch (centre of stop-band, Hz) [0]
	-w: notch width (Hz) [0]
	-m: de-mean the data before filtering (0=NO, 1=YES) [0]
	-pad: apply cosine-tapered padding? (-1=AUTO,0=NO,&#620=SAMPLES) [-1]
		NOTE: if -low is set, default=  4x the low freq. wavelength
		NOTE: if -low is not set, default=  1/4 the input length
	-int: interpolate across invalid data (0=NO,exit instead, 1=YES [1]
	-op: output padding as well as original data (0=NO,1=YES) [0]
	-v: set verbose output (0=NO,1=YES) [0]
EXAMPLES:
	xe-filter_notch1 data.txt -t 1
	cat temp.txt | xe-filter_notch1 stdin -t 3
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getdelta1"><a href="#CODE">&#8679</a> xe-getdelta1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getdelta1 v 2: 3.June.2016 [JRH]
----------------------------------------------------------------------
Produce the change (delta) between consecutive values in a column
USAGE:
	xe-getdelta1 [input] [options]
	[input]: file name or "stdin", single column of numbers
VALID OPTIONS: defaults in []
	-t(ype) of numbers: 1=integers 2=float [2]
EXAMPLES:
	xe-getdelta1 data.txt -t 1
	cat temp.txt | xe-getdelta1 stdin -t 2
OUTPUT:
	n-1 delta scores
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getdelta2"><a href="#CODE">&#8679</a> xe-getdelta2</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getdelta2 v 1: 3.June.2016 [JRH]
----------------------------------------------------------------------
Produce the change (delta) between values in a pair of columns
USAGE:
	xe-getdelta2 [input] [options]
	[input]: file name or "stdin", double-column of numbers
VALID OPTIONS: defaults in []
	-t(ype) of numbers: 1=integers 2=float [2]
EXAMPLES:
	xe-getdelta2 data.txt
	cat temp.txt | xe-getdelta2 stdin
OUTPUT:
	delta scores
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getintervals1"><a href="#CODE">&#8679</a> xe-getintervals1</h3></font>
[<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getintervals1 v 3: 9.November.2018 [JRH]
----------------------------------------------------------------------
Get time intervals during which a data condition (min,max) is met
USAGE: xe-getintervals1 [input] [options]
	[input]: input file or "stdin", of format &#60time&#62 &#60value&#62
VALID OPTIONS (defaults in []):
	-min: minimum value [-1.79769e+308]
	-max: maximum value [1.79769e+308]
	-imin: min interval length for output [0)
	-imax: max interval length [unset by default]
		: will cause longer intervals to be split
		: set the same as -imin to enforce uniform intervals
NOTE: relaxed criteria = fewer intervals, longer summed durations
EXAMPLEs: 
	cut -f 1,5 crunch_pos.txt | xe-getintervals1 stdin 0 20 0
	xe-getintervals1 pos.txt 0 20 -imin .1 -max .1
OUTPUT:
	start and end ttimes for valid intervals
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getkey2"><a href="#CODE">&#8679</a> xe-getkey2</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getkey2 v 1: 4.November.2016 [JRH]
----------------------------------------------------------------------
Detect a key's value when the pair are white-space separated
- similar to xe-getkey1, but this program won't break quoted text
- in other words, place values containing spaces in quotes
- for shell input this requires double-quoting values, e.g. '"a b c"'
USAGE:
	xe-getkey2 [input] [key] [options]
		[input]: file name or "stdin"
		[key]: the key for which the value is required
VALID OPTIONS:
	-m: key match mode, 1=contains, 2=exact [2]
EXAMPLES:
	xe-getkey2 data.txt RATE
	echo name Joe greet '"good morning"' | xe-getkey2 stdin greet
OUTPUT:
	key value (the next word on the line after the key)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getkey"><a href="#CODE">&#8679</a> xe-getkey</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getkey v 4: 8.September.2015 [JRH]
----------------------------------------------------------------------
Output the value following a keyword on each line
- assumes words on each line are white-space delimited unless -d is set
USAGE:
	xe-getkey [input] [key] [options]
		[input]: file name or "stdin"
		[key]: the keyword to be matched (any word on the line)
VALID OPTIONS:
	-d: specify alternative delimiter(s)  [default is " \t"]
	-m: keyword match mode, 1=contains, 2=exact [2]
	-f: output first match only (0=NO 1=YES) [0]
EXAMPLES:
	xe-getkey data.txt RATE
	cat temp.txt | xe-getkey stdin PHONE -d ":"
OUTPUT:
	keyword value (the next word on the line after the keyword)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getkeycol"><a href="#CODE">&#8679</a> xe-getkeycol</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getkeycol v 2: 24.March.2019 [JRH]
----------------------------------------------------------------------
Identify the column-number in an ASCII file header matching a keyword
- Other progs can use this number to read the correct data column
- NOTE: multiple delimiters are treated as a single delimiter
USAGE:
	xe-getkeycol [in] [key] [options]
	[in]: file name or "stdin"
	[key]: the keyword to be matched (any word on the line)
VALID OPTIONS...
	-c: case sensitive? (0=no, 1=yes, default=1)
	-d: characters to use as column-delimiters [ ,\t\n])
		- include ""\n to find keys at the end of the lineEXAMPLES:
	xe-getkeycol data.txt rate -c 0 -d '\t -'
	cat temp.txt | xe-getkeycol stdin PHONE
OUTPUT:
	column in the first line matching the keyword
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getkeyline1"><a href="#CODE">&#8679</a> xe-getkeyline1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getkeyline1 v 1: 12.January.2018 [JRH]
----------------------------------------------------------------------
Output lines following a key-line containing patterns
USAGE:
	xe-getkeyline1 [input] "[patterns]" [options]
		[input]: file name or "stdin"
		[patterns]: CSV list of patterns to match
VALID OPTIONS:
	-o: omit the key-line from output (0=NO 1=YES) [0]
	-n: number of lines after keyline to output (-1=ALL) [-1]
EXAMPLES:
	xe-getkeyline1 data.txt RATE,VALUE -o 1 
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getsamplefreq1"><a href="#CODE">&#8679</a> xe-getsamplefreq1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getsamplefreq1 v 1: 15.February.2015 [JRH]
----------------------------------------------------------------------
Determine the sampling frequency from a series of timestamps
Uses the median value for the interval between values
Non-numerical values, INF, NAN, or blank lines will result in errors
USAGE:
	xe-getsamplefreq1 [input] [options]
	[input]: file name or "stdin", single column of numbers
VALID OPTIONS: defaults in []
	-n : maximum numbers to read [1000]
	-mult : multiplier to convert timestamps to seconds [1]
EXAMPLES:
	xe-getsamplefreq1 data.txt -n 100
	cat temp.txt | xe-getsamplefreq1 stdin -n 1000 -m 60
OUTPUT:
	A single value representing 1 / &#60median interval&#62
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-getsequence1"><a href="#CODE">&#8679</a> xe-getsequence1</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-getsequence1 v 1.6: 25.September.2012 [JRH]
----------------------------------------------------------------------
Extract lines of data in which a word-sequence is found in a given column 
That is, a column on line must match the correct item in the sequence
Start & end words can be the same, allowing contiguous sequences
Individual elements in contiguous sequences will only be output once.
Non-contiguous sequences will be separated by a space
USAGE:
	xe-getsequence1 [input] [col] [mode] [list]
	[input]: file name or "stdin"
	[col]: column containing the words of interest
	[mode]: match mode: "contains" or "exact"
	[list]: a sequence of up to 64 words to match
OUTPUT:
	Lines for which the set column matches the sequence
	Last output line reads "# total_sequences: "[total]
EXAMPLE: if this is the input file...
	1	dog
	2	cat
	3	pig
	4	cow
	Then executing this command...
		xe-getsequence1 data.txt 2 exact  cat pig cow
	Will produce this output...
	2	cat
	3	pig
	4	cow
	# total_sequences: 1
NOTE:
	Normal redirection to file excludes the total_sequences report
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-hist1"><a href="#CODE">&#8679</a> xe-hist1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-hist1 v 14: 9.November.2018 [JRH]
----------------------------------------------------------------------
Produces the values for a histogram
Input is a series of numbers - ideally one row or one column
Non-numeric and non-normal values (Nan and Inf) will be ignored
USAGE: xe-hist1 [input] [options]
	[input]: file name or "stdin", reads all columns & rows
VALID OPTIONS: defaults in []:
	-t(ype): 1(counts) 2(range 0-1) or 3(probability) [1]
	-b(ars) in histogram [25]
	-w(idth) of each bar, overrides "-b" [unset]
	-min sets bottom end of histogram scale [unset]
	-max sets upper end of histogram scale [unset]
	-label: bin-labels identify start(1) middle(2) or end(3) [2]
NOTE:
	- default outputs values for the middle of each bin
	- for integers this may produce seemingly unusual results
	- eg. for numbers 1-4, setting -w 1 produces 3 bins:
		1-2,2-3 & 3-4, and bin-labels 1.5,2.5 & 3.5
	- for integer-bins use -w 1 -max [max+1] -label 1 (e.g.below)
	
EXAMPLES:
	- decimal numbers of potential range 0-100:
		xe-hist1 data.txt -min 0 -max 100
	- integers ranging from 1-4:
		xe-hist1 data.txt -w 1 -max 5 -label 1
	- piping data to the program:
		cat temp.txt | xe-hist1 stdin -t 3
OUTPUT:
	1st column: bin-label
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-histstats1"><a href="#CODE">&#8679</a> xe-histstats1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-histstats1 v 1.4: 9.November.2018 [JRH]
----------------------------------------------------------------------
Calculate statistics on a histogram
USAGE:
	xe-histstats1 [input] [options]
	[input]: 2-column input file or "stdin" in format [x],[y]
VALID OPTIONS:
	-xmin: minimum x-value in histogram for inclusion (unset by default)
	-xmax: maximum x-value in histogram for inclusion (unset by default)
	-ref: reference for y-values used in AUC calculations [0]
		0: reference to zero (use original y-values)
		1: reference to line joining ends of curve
	-d: detrend before calculating statistics (0=NO, 1=YES) [0]
	-f: output format (0=line, 1=line+header,2=keywords) [2]
EXAMPLES:
	xe-histstats1 data.txt
	cat temp.txt | xe-histstats1 stdin 
OUTPUT:
	N: number of good x-y pairs
	XMIN: x-value corresponding with the lowest y-value
	YMIN: the lowest y-value
	XMAX: x-value corresponding with the highest y-value
	YMAX: the highest y-value
	AUC: area under the curve, using polygons formed by connecting values
	ANEG: the negative area under the curve
	APOS: the positive area under the curve
	MEDIAN: the x-value dividing the distributon into two equal halves
	COM: centre-of-mass = the avg.observation = sum(x*y) / (sum(y)
	BIAS: d2-score for y-values when x is +ive vs. -ive
NOTE:
	- for MEDIAN & COM, x/y-values are adjusted so all are positive
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-insert1"><a href="#CODE">&#8679</a> xe-insert1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-insert1 v 1: 22.November.2018 [JRH]
----------------------------------------------------------------------
Insert into file1 the contents of file2
- default is to simply concatenate file2 to the end of file1 
USAGE:
	xe-insert1 [file1] [file2]
	[file1]: file to be added to
	[file2]: file whose contents is to be added
VALID OPTIONS: defaults in []
	-start: insert when this quoted text is found in file1 [unset]
	-pos:   position to insert (-1=before,1=after) [1]
EXAMPLES:
	xe-insert1 data.txt temp.txt -s1 "# block1" 
OUTPUT:
	the desired block of text, sent to stdout
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-interp1"><a href="#CODE">&#8679</a> xe-interp1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-interp1.2.c v 4: 30.April.2016 [JRH]
----------------------------------------------------------------------
Interpolate across blank lines, non-numerical data and NaN/Inf values
Outputs exactly the same number of lines as the input
USAGE: xe-interp1.2.c [input] [options]
	[input]: single-column data file or stdin
VALID OPTIONS (defaults in []):
	-bad: alternative value to interpolate across [nan]
		NOTE: if data also contains NAN,INF or non-numeric
		values, then these may get used for interpolation
	-v: verbose output (0=no, 1=yes) [0]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-interpspectrum1"><a href="#CODE">&#8679</a> xe-interpspectrum1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-interpspectrum1 v 1: 02.February.2016 [JRH]
----------------------------------------------------------------------
Interpolate problem-frequencies in a spectrum
Typically used to smooth over mains-noise (50 or 60 Hz) artefacts
USAGE:
	xe-interpspectrum1 [input] [options]
	[input]: file name or "stdin" in format &#60frequency&#62 &#60value&#62
VALID OPTIONS: defaults in []
	-freq:  CSV list of frequencies to interpolate [none by default]
	-width: width of band around each exclusion-frequency 1 [1]
EXAMPLES:
	xe-interpspectrum1 spectrum.txt -freq 50,100,150 -w 2
OUTPUT:
	interpolated spectrum
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-keyupdate1"><a href="#CODE">&#8679</a> xe-keyupdate1</h3></font>
[<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-keyupdate1 v 1.1: JRH, 24.September.2012
----------------------------------------------------------------------
Update the value following a key-word in a file
If the key-word is not found it will be added
Overwrites the original file
USAGE:
	xe-keyupdate1 [filename] [key] [value]
VALID OPTIONS:
	[filename]: file name or "stdin"
	[key]: the setkeyword to be matched (any word on the line)
	[value]: the value to be added or updated
EXAMPLES:
	xe-keyupdate1 data.txt RATE 24000
	cat temp.txt | xe-keyupdate1 stdin PHONE 123-456-7890
OUTPUT:
	updated file
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas2-makecmt1"><a href="#CODE">&#8679</a> xe-ldas2-makecmt1</h3></font>
[<a href="#tag-ethovision">ethovision</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas2-makecmt1 v 10: 8.October.2012 [JRH]
----------------------------------------------------------------------
Creates a comment (.cmt) file from a .EVtcv file
Program indicates key events such as zone entry/exit, reward etc.
Tracks changes in active trigger zone (TZ) or reward-zone (RZ)
Looks for changes in zone-occpancy (TZ_IN or RZ_IN)
Ignores repeated entries into the same zone
START_TRACK keyword used to re-zero times & ignore initializations
R_WAITING set to 1 results in CORRECT_CHOICE output
R_WAITING set to 0 results in REWARD_RETRIEVED output
NREWARDS keyword results in REWARD_DELIVERED output

USAGE:
	xe-ldas2-makecmt1 [EVtcv]
	[EVtcv]: conditioned version of an Ethovision trial-control record
VALID OPTIONS:
	-s: start time (-1 to use START_TRACK) [0]
		Used to ignore variable initializations
		NOTE: timestamps are also aligned so this becomes zero
EXAMPLES:
	xe-ldas2-makecmt1 028-120420_02.EVtcv -s 2.0
OUTPUT:
	1st column: time
	2nd column: event
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas2-pathstats2"><a href="#CODE">&#8679</a> xe-ldas2-pathstats2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-behaviour">behaviour</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas2-pathstats2 v 3: 14.August.2012 [JRH]
----------------------------------------------------------------------
Calculate statistics on paths defined by time windows
USAGE:
	xe-ldas2-pathstats2 [position data] [winfile] [options]
	[position data]: filename or "stdin", format: &#60time&#62&#60x&#62&#60y&#62
	[winfile]: file listing time windows - format &#60start&#62&#60stop&#62
VALID OPTIONS (defaults in []):
	-int: time (s) over which to integrate movement distance [0.4]
EXAMPLES:
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas3-escapelatency1"><a href="#CODE">&#8679</a> xe-ldas3-escapelatency1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-behaviour">behaviour</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas3-escapelatency1 v 1: 24.September.2012 [JRH]
----------------------------------------------------------------------
Calcualte escape latency from a comment file input
Assumes input format = &#60time&#62&#60TAB&#62&#60comment&#62
	TONE_ON marks the start of a trial
	ENTER_Z2 marks when the subject escapes to the platform
	ENTER_Z2 marks when the subject leaves the platform
	if the subject is on the platform at trial-start, the result is "NAN"
	if the subject does not escape before the next trial the result is "OMIT"
USAGE:
	xe-ldas3-escapelatency1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
EXAMPLES:
	xe-ldas3-escapelatency1 001-120426_00.cmt
	cat 001-120426_00.cmt | xe-ldas3-escapelatency1 stdin
OUTPUT:
	trial, start-time and escape latency
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clucombine1"><a href="#CODE">&#8679</a> xe-ldas5-clucombine1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clucombine1 v 4: 17.March.2017 [JRH]
----------------------------------------------------------------------
Combines clusters with common refractoriness and similar waveforms
- autocor refract= histogram +-2ms spike-count vs. +-15ms
- crosscor refract= histogram +-2ms spike-count vs. +-10ms
- one-sided t-tests for spiking probability (0-2 vs 2-10ms)
- cluster-pairs meeting criteria are combined as they are tested
USAGE:
	xe-ldas5-clucombine1 [in1] [in2] [in3] [arguments]
VALID ARGUMENTS (defaults in []):
	[in1]: timestamps (.clubt) file for a given probe
	[in2]: cluster-id (.club) file for a given probe
	[in3]: waveform (.wfm) file a given probe
	-sign: spike detection, -1=NEG, 1=POS [-1]
	-pass: set number of passes[1]
	-hist: output histograms (.hist file) (0=NO 1=YES) [0]
	-v: verbocity [2]
		0= report only, no combining, single pass, all pairs
		1= combine only, no report
		2= combine + report: 
- combine criteria:
	-s: minimum spikes (central histogram) [25]
	-a: max auto-refractoriness for both clusters [0.02]
	-ad: max auto-refract. change, relative to worst of pair [0.02]
	-r: maximum xcor refractoriness (both sides) [0.8]
	-t: minimum t-score (either side) [3]
	-p: maximum p-value (either side) [0.5]
	-w: minimum multi-channnel waveform peak-correlation [0.9750]
		- signed R-sq. for values at peak, in depth order
EXAMPLES:
	xe-ldas5-clucombine1 file.clubt file.club file.wfm
FILE OUTPUT (-v 1 or 2):
	modified .club file temp_xe-ldas5-clucombine1.club
	modified .wfm file temp_xe-ldas5-clucombine1.wfm
	histogram file (optional) temp_xe-ldas5-clucombine1.hist
REPORT OUTPUT (-v 0 or 2):
	c1 c2 tot   rl tl pl   rr tr pr   wavecor combine

	[c1 c2 tot]: cluster IDs and histogram spike-count
	[rl tl pl]: left-side refractoriness, t-stat & prob.
	[rr tr pr]: as above for right-hand side
	[wavecor]: waveform correlation, 5 channels centred on
	           channel with largest mean spike (see -sign)
	[combine]: combine criteria bit-flag, 1=histogram, 2=wavecor
	           NOTE: must be 3 (both criteria met) to combine
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clucombinelist1"><a href="#CODE">&#8679</a> xe-ldas5-clucombinelist1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clucombinelist1 v 1: 4.April.2017 [JRH]
----------------------------------------------------------------------
Combines cluster-pairs using a list
USAGE:
	xe-ldas5-clucombinelist1 [in1] [in2] [in3] [list] [options]
	[in1]: timestamps (.clubt) file for a given probe
	[in2]: cluster-id (.club) file for a given probe
	[in3]: waveform (.wfm) file a given probe
	[list]: list of cluster-pairs to combine
VALID OPTIONS (defaults in []):
	-verb: verbocity [0]
		0= combine only, no report
		1= combine + report: 
EXAMPLES:
	xe-ldas5-clucombinelist1 file.clubt file.club file.wfm
FILE OUTPUT (-v 1 or 2):
	modified .club file temp_xe-ldas5-clucombinelist1.club
	modified .wfm file temp_xe-ldas5-clucombinelist1.wfm
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-cluhist1"><a href="#CODE">&#8679</a> xe-ldas5-cluhist1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-cluhist1 v 1: 28.July.2017 [JRH]
----------------------------------------------------------------------
Calculate spike-histogram-related statistics for club(t) records
- auto- or cross-corerelograms
- binsize fixed at 1ms
USAGE:
	xe-ldas5-cluhist1 [infile1] [infile2] [options]
	[infile1]: .clubt timestamp file
	[infile2]: .club cluster-id file
VALID OPTIONS (defaults in []:
	-list: CSV list of clusters to analyze [all]
	-cor: auto-(1) or cross-(2) corellogram? [1]
	-t: type, 1(counts) 2(range 0-1) or 3(probability) [1]
	-sf: sample freq. to convert samples to seconds [19531.250]
	-width: histogram half-width (milliseconds) [50]
	-bins: override default number of bins (0= 1ms/bin) [0]
		NOTE: use only for histogram output (-out 0)
	-z1: zone1 half-width (milliseconds) [15]
	-z2: zone2 half-width (milliseconds) [2]
	-skipz: skip cluster zero (0=NO, 1=YES) [0]
	-out: output (0=histograms, 1=stats) [1]
		NOTE: for stats, use a window &#62= +-50ms
	-verb: verbose output (0=NO 1=YES) [0]
OUTPUT (-out 0, histograms):
	cluster	time	count
OUTPUT (-out 1, statistics):
	cluster   n   histn1   histn2   refract   mean   burst
	- cluster: cluster id
	- n: total spikes fired by this cell
	- histn1: spikes in histogram
	- histn2: spikes in zone1
	- histn3: spikes in zone2
	- refract: refractory score (spikes in zone2/zone1)
	- mean: mean (ms) for positive portion of histogram
	- burst: burst-firing tendency of the cell (0-1)
EXAMPLES:
	xe-ldas5-cluhist1 data.clu.3 data.res.3 -sf 24000
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clukiller1"><a href="#CODE">&#8679</a> xe-ldas5-clukiller1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clukiller1 v 1: 10.November.2016 [JRH]
----------------------------------------------------------------------
Reset non-refractory or noisy clusters to category zero (noise)
Analysis is based on the 100ms autocorellation histogram
No reset is if the central +-15ms of the histogram is sparse
- refract= ratio of spikes in the central +-2ms vs +-15ms portions
	- this captures clusters violating refractoriness requirements
- noise= variance in the normalized (0-1), differenced histogram
	- this captures highly temporally-stereotypic artefacts
USAGE:
	xe-ldas5-clukiller1 [clubt] [club] [options]
	[clubt]: binary file containing club-times (long int)
	[club]: binary file containing club-IDs (short int)
VALID OPTIONS (defaults in []):
	-sf (sample freq): convert samples to seconds [19531.25]
	-ks: skip clusters with &#60 this minimum +-15ms spike-count [75]
	-kr: maximum refractory score [0.0800]
	-kn: maximum noise score [2]
	-v: verbocity (0=report only, 1=cull, 2=cull+report) [1]
- examples:
	xe-ldas5-clukiller1 data.club.3 data.clubt.3 -sf 20000
- output:
	modified .club file
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clukillerlist1"><a href="#CODE">&#8679</a> xe-ldas5-clukillerlist1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clukillerlist1 v 1: 3.April.2017 [JRH]
----------------------------------------------------------------------
Reallocates cluster ID's in a .club file
USAGE:
	xe-ldas5-clukillerlist1 [infile1] [infile2] [list] [options]
	[infile1]: .clubt timestamp file
	[infile2]: .club cluster-id file
	[list]: comma-separated list of cluster-id's to kill
VALID OPTIONS, defaults in []:
	-w: specify a waveform file to also be updated [(null)]
	-kz: remove cluster zero (0=NO 1=YES) [0]
EXAMPLES:
	xe-ldas5-clukillerlist1 data.clubt data.club 4,13,27
OUTPUT:
	modified .clubt file (temp_xe-ldas5-clukillerlist1.clubt)
	modified .club file (temp_xe-ldas5-clukillerlist1.club)
	modified .wfm file (temp_xe-ldas5-clukillerlist1.wfm)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clumatch1"><a href="#CODE">&#8679</a> xe-ldas5-clumatch1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clumatch1 v 1: 2.June.2017 [JRH]
----------------------------------------------------------------------
Match clusters from different clustering runs based on timestamps
- how are reference cluster spikes found in comparison clusters?
USAGE:
	xe-ldas5-clumatch1 [clubt1] [club1] [clubt2] [club2] [options]
	[clubt1]: reference .clubt file
	[club1]:  reference .club file
	[clubt2]: comparison .clubt file
	[club2]:  comparison .club file
VALID OPTIONS:
	-diff: max offset (samples) between matched timestamps [0]
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-clumatch1 A.clubt A.club B.clubt B.club -diff 5
OUTPUT:
	[c0] [n] [p] [x1:m1] [x2:m2] [x3:m3] ... etc
		[c0]: reference cluster ID
		[n]: spike count for reference cluster
		[p]: proportion of [n] found in comparison cluster
			- NOTE: typically 0-1, but may be &#621
		x+: comparison cluster ID
		m+: comparison cluster timestamps matching [c0]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clurate1"><a href="#CODE">&#8679</a> xe-ldas5-clurate1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clurate1 v 1: 24.November.2017 [JRH]
----------------------------------------------------------------------
Calculate firing-rate timecourse for clusters
- 
USAGE:
	xe-ldas5-clurate1 [clubt] [club] [options]
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
VALID OPTIONS:
	-clu: screen using CSV list of cluster IDs [unset]
	-scrf: screen-file (binary ssp) defining bounds for infile1 [unset]
	-scrl: screen-list (CSV) defining bounds for infile1 [unset]
	-winsize: density-window-size (seconds) [1.000]:
	-sf: sample freq to convert winsize to samples [19531.250]
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-clurate1 data.clubt data.club -s 1 -sl 100,200,1500,1600
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-clusort1"><a href="#CODE">&#8679</a> xe-ldas5-clusort1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-clusort1 v 1: 1.July.2017 [JRH]
----------------------------------------------------------------------
Sort cluster ID's by channel with max-amplitude peak in .wfm file
- assumes channels are in depth-order
USAGE:
	xe-ldas5-clusort1 [clubt] [club] [wfm] [options]
	[clubt]: .clubt timestamp file
	[club]: .club cluster-id file
	[wfm]: .wfm waveform file
VALID OPTIONS, defaults in []:
	-sign: wave amplitude sign (1=positive -1=negative) [-1]
	-low: filter low-cut (0=none) [300]
	-high: filter high-cut (0=none) [5000]
	-verb: verbode output (0=NO 1=YES) [1]
EXAMPLES:
	xe-ldas5-clusort1 data.clubt data.club 4,13,27
OUTPUT:
	modified .club file (temp_xe-ldas5-clusort1.club)
	modified ..wfm file file (temp_xe-ldas5-clusort1.wfm)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-cofiring1"><a href="#CODE">&#8679</a> xe-ldas5-cofiring1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-cofiring1 v 1: 27.November.2017 [JRH]
----------------------------------------------------------------------
Calculate co-firing of cell pairs
USAGE:
	xe-ldas5-cofiring1 [clubt] [club] [ssp] [options]
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
	[ssp]: binary start-stop-pair file defining time-windows
VALID ARGUMENTS (defaults in []) ...
	-clu: CSV list of clusters to use [unset]
	-win: break SSPs into windows of this size (samples, -1=NO) [-1]:
	-ms: minimum spikes from both cells in a pair across all windows [0]
	-verb: verbose output (0=NO 1=YES) [0]
EXAMPLES:
	xe-ldas5-cofiring1 data.txt cells_place.txt times.txt
	cat data.txt | xe-ldas5-cofiring1 stdin list.txt times.txt
OUTPUT: c1 c2 cofir totfir ratio  r F p
	c1,c2: cell id's for each pair
	cofir: sum of spikes from c1+c2 ocurring inside time windows
	totfir: sum of spikes from c1+c2, regardless of timing
	ratio: cofiring ratio score [0-1]
		NOTE: this may be an unreliable scrore - correlates poorly with r, below
		NOTE: cofir correlates well, but maybe c1*c2 would be better than c1+c2
	n: number win time windows
	r,F,p: Pearson's-r results for c1 vs. c2 clucounts in each window
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-datwavemean1"><a href="#CODE">&#8679</a> xe-ldas5-datwavemean1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>][<a href="#tag-math">math</a>]<br>
<blockquote><pre>----------------------------------------------------------------------
xe-ldas5-datwavemean1 v 2: 20.July.2017 [JRH]
----------------------------------------------------------------------
Calculate mean waveform from a given trial (all probes)
USAGE:
	xe-ldas5-datwavemean1 [dat] [clubt] [club] [options]
	[dat]: interlaced binary data file (short int)
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
VALID OPTIONS: defaults in []
	-nch: number of channels in input [16]
	-chl: channel-list (CSV) specifying order of channels [(null)]
	-chg: CSV list of good (1, default) or bad (0) channels for -chl [(null)]
	-spklen: samples comprising the waveform on each channel [40]
	-spkpre: samples before spike-detection event to be included [8]
	-sr: .dat sample-rate (Hz) [19531.2]
	-gain: gain (amplification factor) [70]
	-vmax: maximum voltage [0.8]
	-out: output: 1=.wfm file, 2=cluster,sample,mean,std.dev [1]
OUTPUT: Waveform file, format= [c] [n] [voltages]
	[c]: cluster id for this probe
	[n]: number of spikes contributing to the mean waveform
	[voltages]: series of [nsamps] mean voltages, in uV
EXAMPLES:
	xe-ldas5-datwavemean1 tr01.dat tr01.clubt tr01.club -spklen 32 -spkpre 8

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-expandclub1"><a href="#CODE">&#8679</a> xe-ldas5-expandclub1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-expandclub1 v 1: 1.May.2016 [JRH]
----------------------------------------------------------------------
Restore .club(t) files with sections removed using an SSP file
- output is either converted to ASCII or kept in binary form
USAGE:
	xe-ldas5-expandclub1 [clubt] [club] [options]
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
VALID OPTIONS:
	-scrf: binary ssp-file defining bounds for kept data [unset]
	-scrl: list (CSV) defining bounds for kept data
	-out: output format [-1]:
		-1= ASCII, one timestamp-id pair per line
		 0= binary files x2 (long,short)
		 	temp_xe-ldas5-expandclub1.clubt
		 	temp_xe-ldas5-expandclub1.club
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-expandclub1 data.clubt data.club -s 1 -sl 100,200,1500,1600
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-interp2"><a href="#CODE">&#8679</a> xe-ldas5-interp2</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-interp2 v 0: 29.November.2018 [JRH]
----------------------------------------------------------------------
Linear interpolation of multi-channel .dat files (signed short)
 - reads entire file into memory
 - processes channels in parallel for speed
 - output is a binary stream - redirect to a file
USAGE:
	xe-ldas5-interp2 [input] [options]
	[input]: file name or "stdin"
		- samples are 16-bit short signed integers
		- a sample refers to a multi-channel set of data
VALID OPTIONS:
	-nch: total number of channels [16]
	-bad: identify an invalid value (0,-1, or 1=max) [1]
		- these values will be interpolated across
		- should be set, as NAN is undefined for integers
	-min: minimum-number of sequential good values [0]
		- in each read-block, shorter sequences are set to bad
	-b: read-block size (multi-channel samples) (0=auto ~64KiB) [0]
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-interp2 old.dat -verb 1 &#62 new.dat
	cat old.dat | xe-ldas5-interp2 stdin -nch 32 &#62 new.dat
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-packetloss1"><a href="#CODE">&#8679</a> xe-ldas5-packetloss1</h3></font>
[<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-packetloss1 29.November.2018 [JRH]
----------------------------------------------------------------------
Calculate time-course of packet-loss in a .dat file
Assumes one valid numeric value per input line
Non-numeric values will be ignored
USAGE:
	xe-ldas5-packetloss1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-sf: sample frequency (Hz) [19531.2]
	-nch: total number of channels [16]
	-bad: invalid value (0,-1, or 1=SHRT_MAX) [1]
	-scrf: screen-file (binary ssp) defining inclusion bounds []
	-scrl: screen-list (CSV) defining inclusion bounds []
	-bin: binning factor (seconds) to apply [1]
	-verb: verbose output (0=NO 1=YES) [0]
EXAMPLES:
	xe-ldas5-packetloss1 data.txt -t 1
	cat temp.txt | xe-ldas5-packetloss1 stdin -t 3
OUTPUT:
	1st column: lower limit of each bin
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-packetloss2"><a href="#CODE">&#8679</a> xe-ldas5-packetloss2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-packetloss2 23.December.2018 [JRH]
----------------------------------------------------------------------
Calculate total packet-loss in a .dat file
	- uses channel-0, assumes packet loss will span all channels
USAGE:
	xe-ldas5-packetloss2 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-sf: sample frequency (Hz) [19531.250]
	-nch: total number of channels [16]
	-bad: invalid value (0,-1, or 1=SHRT_MAX) [1]
	-min: minimum-number of sequential good values [0]
		- in each read-block, shorter sequences are set to bad
	-scrf: screen-file (binary ssp) defining inclusion bounds []
		- NOTE: SSP/sample-numbers output will be inaccurate
	-scrl: screen-list (CSV) defining inclusion bounds []
		- NOTE: SSP/sample-numbers output will be inaccurate
	-out: output format [1]
		1: summary
		2: start-stop pairs for lost-data
		3: start-stop pairs for good-data
		4: sample-numbers of missing data (64-bit long int)
	-verb: verbose output (0=NO 1=YES) [0]
EXAMPLES:
	xe-ldas5-packetloss2 test.dat &#62 missing.txt
	xe-ldas5-packetloss2 test.dat -verb 1 | wc -l
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-packetloss3"><a href="#CODE">&#8679</a> xe-ldas5-packetloss3</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-packetloss3 24.March.2019 [JRH]
----------------------------------------------------------------------
Calculate packet-loss using a lost.ssp file
USAGE:
	xe-ldas5-packetloss3 [input] [options]
	[input]: binary .ssp file name or "stdin"
		- defines blocks of lost-packets (start-stop samples)
VALID OPTIONS: defaults in []
	-sf: sample frequency (Hz) [19531.250]
	-win: averaging-window size (seconds) [1]
	-min: minimum-sample (-1=auto) [-1]
	-max: maximum-sample (-1=auto) [-1]
	-scrf: screen-file (binary ssp) defining inclusion bounds []
		- NOTE: SSP/sample-numbers output will be inaccurate
	-scrl: screen-list (CSV) defining inclusion bounds []
		- NOTE: SSP/sample-numbers output will be inaccurate
	-out: output [2]
		1= sumamry
		2= density time-series, using sf,win,min,max
	-verb: verbose output (0=NO 1=YES) [0]
OUTPUT:
	time	%lost
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-placefields1"><a href="#CODE">&#8679</a> xe-ldas5-placefields1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-placefields1 v 2: 16.March.2019 [JRH]
----------------------------------------------------------------------
Read binary cluster-timestamps (.clubt) and cluster-ids (.club)
- output is either converted to ASCII or kept in binary form
- use a file or list of boundaries to screen the start-stop pairs
- this program does not accept input piped via stdin
USAGE:
  	xe-ldas5-placefields1 [clubt] [club] [xyd] [xydt] [options]
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
	[xydt]: binary file containing position-times (long int)
	[xyd]: binary file containing position-values (3x float)
VALID OPTIONS:
	-clu: screen using CSV list of cluster IDs [unset]
	-scrf: screen-file (binary ssp) defining bounds for infile1 [unset]
	-scrl: screen-list (CSV) defining bounds for infile1 [unset]
	-dwell: minimum samples for a dwell-map bin to be valid [0]
	-con: number of contiguous bins required to keep a bin [0]
	-vrate: video sample rate (samples/s) [25]
	-vrange: 4-item CSV list defining xmin,ymin,xmax,ymax [unset]
	-binsize : size of map-pixels (cm) [-1]
	-sx : 2D gaussian smoothing (bins) applied to rate matrix [0]
	-sy : 2D gaussian smoothing (bins) applied to matrix [0]
	-st : smoothing type (0,1 or 2) [2]
		0= no smoothing
		1= smooth dwellmap and spikemap before calculating rate
		2= smooth the ratemap
	-flip: flip position data in y-dimension [0]:
	-out: output format [4]:
		0= position traces only
		1= dwelltime density matrix
		2= path+spike x/y coordinates
		3= spike-density matrix (counts)
		4= spike-firing rate (Hz)
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-placefields1 data.clubt data.club -scrl 100,200,1500,1600
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-placestats1"><a href="#CODE">&#8679</a> xe-ldas5-placestats1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-placestats1 v 3: 21.October.2017 [JRH]
----------------------------------------------------------------------
Perform place-field analysis on a multi-matrix file
 - this peak starts at the highest-value pixel and propogates outward
 - diagonal propogation is not permitted
 - if peak size is below a minimum, another attempt is made
 - attempts are made until no peak is detected at all
USAGE:
	xe-ldas5-placestats1 [dwell] [rate] [options]
		[dwell]: dwelltime matrix file
		[rate]: firing-rate multi-matrix file
			- matrices separated by "# &#60id-number&#62" lines
VALID OPTIONS (defaults in []):
	-vrange: 4-item CSV list defining xmin,ymin,xmax,ymax [unset]
	-smooth : 2D gaussian smoothing (bins) applied for field-detection [4]
	-thresh : edge-detection threshold (proportion of peak) [0.25]
	-size   : size threshold (number of pixels, zero=any) [0]
	-out    : output [1]
		1: map-pixel statistics are sent to stderr
			cluster: cell-ID
			rmax: highest firing-rate pixel
			rmean: firing-rate mean
			rbase: firing rate 10th-percentile - "background" rate
			rmed: firing-rate 50th-percentile
			rpeak: firing rate 97.5th percentile - "peak" rate
			info: information content
			spar: spatial-sparsity
			coh: spatial coherence
			fmax: field-max-rate after smoothing
			fsize: field-size (pixels)
			fx: field centroid position (pixel), x-axis
			fy: field centroid position (pixel), y-axis
		2: the final place-field mask sent to stdout
		3: both 1 & 2
EXAMPLES:
	{ xe-ldas5-placestats1 matrix.txt -thresh 1 -first 0 &#62 matrix2.txt ; } 2&#62 report.txt 
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readclub1"><a href="#CODE">&#8679</a> xe-ldas5-readclub1</h3></font>
[<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-readclub1 v 6: 16.March.2019 [JRH]
----------------------------------------------------------------------
Read binary cluster-timestamps (.clubt) and cluster-ids (.club)
- output is either converted to ASCII or kept in binary form
- use a file or list of boundaries to screen the start-stop pairs
- this program does not accept input piped via stdin
USAGE:
	xe-ldas5-readclub1 [clubt] [club] [options]
	[clubt]: binary file containing cluster-times (long int)
	[club]: binary file containing cluster-IDs (short int)
VALID OPTIONS:
	-clu: screen using CSV list of cluster IDs [unset]
	-scrf: screen-file (binary ssp) defining bounds for infile1 [unset]
	-scrl: screen-list (CSV) defining bounds for infile1 [unset]
	-sort: sort records by ascending timestamps (0=NO 1=YES) [0]
	-out: output format [-1]:
		-2= summary (ID and COUNT) for each cluster
		-1= ASCII, one timestamp-id pair per line
		 0= binary files x2 (long,short)
		 	temp_xe-ldas5-readclub1.clubt
		 	temp_xe-ldas5-readclub1.club
	-sf: sample freq to calculate firing rates [19531.250]
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-readclub1 data.clubt data.club -s 1 -sl 100,200,1500,1600
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readdat1"><a href="#CODE">&#8679</a> xe-ldas5-readdat1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-readdat1v 7: 12.September.2016 [JRH]
----------------------------------------------------------------------
Extract values from an interlaced binary dat file
	- reads chunks at a time - suitable for very large files
	- can extract particular channel(s) or a block of data
	- can invert data and convert from unsigned to signed values
USAGE:
	xe-ldas5-readdat1 [input] [options]
	[input]: file name or "stdin"
		- samples are 16-bit short integers
		- a sample refers to a multi-channel set of data
		- channel and sample indices are zero-offset
		- eg. samp2/ch5 of a 16ch input is indexed 2*16+5
VALID OPTIONS:
	-h: file header size (bytes) [0]
	-b: read-block size (multi-chan. samples) (0=auto ~64KiB) [0]
		NOTE: overridden by -dec
	-s: start reading at this sample (zero-offset) [0]
	-n: number of samples to read (0=all) [0]
	-nch: total number of channels [1]
	-ch: CSV list of channels to extract: 0-(nch-1) [unset= all]
	-u: convert all data from unsigned (0=NO 1=YES) [0]
	-adj: adjust non-16-bit data (max-bits, or 0=skip) [0]
		- NOTE: only applies to data converted from unsigned
		- e.g. if input was derived from 12bit numbers, then
		  shift the data to maintain the original "zero"
	-bad: identify an invalid value (0=none -1=-1, 1=max) [0]
		- protects invalid values from -u conversion
		- min/max refer to pre-conversion (-u) values
		- min/max: system-defned values for short integers
	-rep: replace bad values by most recent good (0=NO 1=YES) [0]
	-f: flip good data values (0=NO 1=YES) [0]
	-add: arbitrary value to add to all data [0]
	-mul: arbitrary value to multiply all data by [1]
	-dec: decimate to every nth sample (0=NO)[0]
	-ref: reference channel to be subtracted (-1=none) [-1]
	-out: output format [0]:
		0= ASCII
		1= binary interlaced file
		NOTE: to write channels to separate files, call this
		      program multiple times
	-verb: verbose output (0=low,1=high,2=highest) [0]
EXAMPLES:
	xe-ldas5-readdat1 data.txt -nch 64 -ch 0,1,2
	cat temp.txt | xe-ldas5-readdat1 stdin -nch 64 -ch 62,63
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readdat2"><a href="#CODE">&#8679</a> xe-ldas5-readdat2</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-readdat2 v 0: 31.January.2019 [JRH]
----------------------------------------------------------------------
Extract & process 1 channel from an interlaced binary dat file
	- data is read into memory for processing
	- allows flipping, interpolation, conversion, and downsampling
	- use this program with caution for very large files
USAGE:
	xe-ldas5-readdat2 [input] [options]
	[input]: file name or "stdin"
		- samples are 16-bit short integers
		- a sample refers to a multi-channel set of buffpoint
		- channel and sample indices are zero-offset
		- eg. samp2/ch5 of a 16ch input is indexed 2*16+5
VALID OPTIONS:
	-nch: total number of channels [1]
	-ch: channel to extract: 0-(nch-1) [0]
	-s: start reading at this sample (zero-offset) [0]
	-n: number of samples to read (0=all) [0]
		NOTE: if unset, all channels are output
	-bad: invalid value (0,-1, or 1=SHRT_MAX) [1]
	-mg: minimum good values in a row to keep data [0]
		- sequences of less than this will be set to invalid
	-f: flip good data values (0=NO 1=YES) [0]
	-int: interpolate across invalid values (0=NO 1=YES) [0]
	-mean: size of sliding-window used to demean input (0=SKIP) [0]
	-dec: decimate to every nth sample (0=NO)[0]
		NOTES: non-integers are allowed,, for precise downsampling
		     : an FIR anti-aliasing filter will be applied
		     	- 101 taps, Kaiser window, beta=3
		     	- will require setting -sf (below)
		     	- will reduce amplitude for high decimation
	-sf: sampling frequency (Hz), required for decimation [-1]
	-con: convert data to float for processing (0=NO 1=YES) [0]
	-out: output format (0=ASCII, 1=binary) [0]:
		NOTE: binary out is short (-con 0) or float (-con 1)
	-verb: verbose output (0=low,1=high,2=highest) [0]
EXAMPLES:
	xe-ldas5-readdat2 buffpoint.txt -nch 64 -ch 0,1,2
	cat temp.txt | xe-ldas5-readdat2 stdin -nch 64 -ch 62,63
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readssp1"><a href="#CODE">&#8679</a> xe-ldas5-readssp1</h3></font>
[<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-readssp1 v 3: 15.March.2019 [JRH]
----------------------------------------------------------------------
Process binary start-stop-pair (.ssp) files
- output is either converted to ASCII or kept in binary form
- use a file or list of boundaries to screen the start-stop pairs
USAGE:
	xe-ldas5-readssp1 [input] [options]
	[input]: binary file containing start-stop pairs, or "stdin"
		- pairs are 64-bit long integers (signed)
		- pairs generally refer to sample-numbers
VALID OPTIONS: operations shown in execution-order defaults in []:
	-scr: screen using start-stop boundary pairs [0]
		0: no screening (reset to 1 if -scrf or -scrl is set)
		1: each pair must fall within one of tinvhe listed bounds
		2: each pair must not span any of the listed bounds
	-scrf: screen-file (binary ssp) defining bounds for infile1 [unset]
	-scrl: screen-list (CSV) defining bounds for infile1 [unset]
	-inv: invert SSPs, returning gaps only (0=NO 1=YES) [0]
	-a: start for a new first-SSP (-1=none) [-1]
		- adds a record
		- uses pre-inversion start[0] as new stop[0]
	-z: stop for a new last-SSP (-1=none) [-1]
		- adds a record
		- uses pre-inversion stop[n-1] as new start[n-1]
	-split: split SSPs into n-sample sub-SSPs (0=none) [0]
	-div: SSPs divisor (allows alignment to downsampled data) [1]
		- NOTE: this is only applied at the output stage
	-com: compress SSPs (0=NO 1=YES) [0]
		- indicates boundaries in a file merged using the input
	-out: output format [-1]:
		-2= summary only (total SSP pairs and duration)
		-1= ASCII, one start-stop-pair per line
		 7= binary (long int), start-stop pairs in sequence
	-verb: set verbocity of output (0=low, 1=high) [0]
EXAMPLES:
	xe-ldas5-readssp1 pairs.ssp -s 1 -sl 100,200,1500,1600,2350,2450
	cat thetacycles.ssp | xe-ldas5-readssp1 stdin -s 1 -sf trials.ssp
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readwave1"><a href="#CODE">&#8679</a> xe-ldas5-readwave1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>----------------------------------------------------------------------
xe-ldas5-readwave1 v 1: 6.July.2017 [JRH]
----------------------------------------------------------------------
Read waveform file (.wfm)
USAGE:
	xe-ldas5-readwave1 [.wfm file] [options]
	[.wfm file]: file containing mean waveforms for each cluster
VALID OPTIONS: defaults in []
	-low: filter low-cut (0=none) [0]
	-high: filter high-cut (0=none) [0]
	-clust: restrict output to a CSV list of clusters) [(null)]
		- if unset (null), all clusters are output
	-verb: verbose output (0=NO 1=YES) [0]
	-out: output format [1]
		0= header only
		1= .wfm format (header + waveforms & metadata)
		2= [cluster] [channel] [time:ms] [value]
...if -out is set to 2...
	-chan: restrict output to channel-ID (-1 = no restriction) [-1]
		NOTE: derived from CHANNEL_LIST, not sequence

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-readxyd1"><a href="#CODE">&#8679</a> xe-ldas5-readxyd1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-behaviour">behaviour</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-readxyd1 v 2: 21.January.2018 [JRH]
----------------------------------------------------------------------
Read binary position timestamps (.xydt) and position values (.xydt)
- output is either converted to ASCII or kept in binary form
- use a file or list of boundaries to screen the start-stop pairs
- this program does not accept input piped via stdin

USAGE:
	xe-ldas5-readxyd1 [xydt] [xyd] [options]
	[xydt]: binary file containing position-times (long int)
	[xyd]: binary file containing position-values (3x float)

VALID OPTIONS:
	-sf: sample-frequency of clock used to timestamp video [19531.2]
	-vf: video sample-frequency [25]
	-scrf: screen-file (binary ssp) defining inclusion bounds []
	-scrl: screen-list (CSV) defining inclusion bounds []
	-int: max interpolation gap (video-samples) [0]
		-1: no limit - interpolate all missing data
		 0: no interpolation
		 for 25Hz video, 10-25 (0.4-1.0 sec) recommended
	-verb: set verbocity of output (0=low, 1=high) [0]
	-vf: sample-rate for video (Hz) [25]
	-sf: sample-rate  for electrophysiology [19531.2]
		used for ASCII output - elapsed time
	-out: output format [1]:
		0= summary: duration, velocity mean & median
		1= ASCII, one timestamp-id and x,y,d triplet per line
		2= binary files x2
		 	temp_xe-ldas5-readxyd1.xydt (long)
		 	temp_xe-ldas5-readxyd1.xyd  (float triplets)
		3= binary SSPs delineating velocity criteria (see below)

Velocity criterion for -out 3 option ...
	-velint: time (sec) over which velocity is integrated [0.4]
	-velmin: minimum (cm/s, nan = no limit) [nan]
	-velmax: maximum (cm/s, nan = no limit) [nan]
	-veldur: minimum duration (s) [0]

EXAMPLES:
	xe-ldas5-readxyd1 data.xydt data.xyd -scr 1 -scrl 10,20,40,50
	xe-ldas5-readxyd1 A.xydt A.xyd -velmin 5 -out 3 &#62 B.ssp
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-ripdet1"><a href="#CODE">&#8679</a> xe-ldas5-ripdet1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-ldas5-ripdet1 v 1: 6.March.2018 [JRH]
--------------------------------------------------------------------------------
Detect ripple oscillations in a binary file (short or float accepted)
Based on methodology published by Sullivan & Buzsaki, 2011
	A. read, extract the data for each channel, and interpolate
	B. copy1 (detection): 
	 	- band-pass filter in the defined ripple range
	 	- rectify, smooth,  and convert to Z-scores
		- detect events &#622 SD (edge=0.5 SD) lasting 25-150ms
	C. copy2 (validation): 
	 	- high-pass filter (defined by -low and -high)
	 	- extract a data chunk centred on each event
		- FFT on each chunk (100ms window, mode determined by -taps, below)
		- smooth the mean spectrum for each event (3-point Gaussian)
		- reject events with a peak outside ripple range 
		- reject events with higher-freq. peaks &#62 0.5x the ripple peak
USAGE:	xe-ldas5-ripdet1 [input] [options] 
	[input]: binary input file
READ OPTIONS (defaults in [])
	-dt: type of data (3=short int, 8=float) [3]
	-nch: total number of channels [16]
	-ch: specify the channel to detect on (-1 = ALL) [-1]
	-sf: sampling frequency (Hz) of the input [19531.25]
	-scrf: screen-file (binary SSP) defining read-chunks [unset]
	-scrl: screen-list (CSV) defining read-chunks [unset]
		NOTE: -scrf & -scrl define start/stop sample pairs
		NOTE: setting any stop to zero indicates read-to-end-of-file
DETECTION OPTIONS
	-riplow: ripple low-frequency boundary [140]
	-riphigh: ripple low-frequency boundary [220]
	-b: boxcar smoother half-width (samples: -1= AUTO, 7.5ms) [-1]
	-emin: threshold (Z-score) for detecting events [2]
	-emax: max-allowable event size (Z-score) [20]
	-ampmin: minimum amplitude (spectral AUC) for "good" ripples [0]
VALIDATION OPTIONS
	-low: filter low-cut filter  (0=none, -1= riplow/2, minimum=50) [-1]
	-high: filter high-cut filter(0=none, -1= riphigh*2), maximum=sf/2 [0]
	-taps: number of tapers (0=none 1=Hann &#621=multi-taper) [2]
		0-1: 6x 100ms sliding windows estimate ripple spectrum
		&#62=2: Slepian tapers in a fixed 100ms window (mid-event-centred)
	-ord: taper order (rate of change to zero) (-1 = auto = taps+1) [-1]
	-win: size of FFT-window (seconds) - will be adjusted [0.1]
	-min: min FFT freq. [-1= default= sf/windowsize]
	-max: max FFT freq. [-1= default= sf/2]
	-avg: method for spectral averaging (1=arithmetic, 2=adaptive) [2]
	-g: half-width (samples) for Gaussian smoothing of spectrum only [3]
		NOTE: -g must be 0 (none) or an odd number &#62=3)
	-out: output [4]
		0: tapers only
		1,2: spectra for all(1) or good(2) events (event,freq,amp)
		3,4: times for all(3) or good(4) events (event,start,peak,stop,amp)
	-wave : file to write ripple waveforms to (NULL=omit) [(null)]
	-v: set verbosity to quiet (0) or report (1) [0]
EXAMPLES: xe-ldas5-ripdet1 [input] [options] 
	xe-ldas5-ripdet1 data.txt -t bin -sf 1500 
	cat data.bin | xe-ldas5-ripdet1 stdin -t asc 

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-samp2time1"><a href="#CODE">&#8679</a> xe-ldas5-samp2time1</h3></font>
[<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-samp2time1 v 1: 5.March.2016 [JRH]
----------------------------------------------------------------------
Calculate the date and time corresponding with a given sample-number
USAGE:
	xe-ldas5-samp2time1 [start] [samp] [options]
	[start]: file or "stdin", specifying start date/time 
		- this is the date & time for sample-zero
		- single-column input
		- format: YYY:MMM:DDD:hh:mm:ss
		- start times must be rounded to nearest second
	[samp]: sample number (zero-offset)
VALID OPTIONS: defaults in []
	-sf: sample frequency [19531.2]
EXAMPLES:
	xe-ldas5-samp2time1 data.txt 20000 -sf 20000
	echo 16:12:31:23:59:15 | xe-ldas5-samp2time1 stdin 20000 -sf 20000
OUTPUT:
	date/time in format YY:MM:DD:hh:mm:ss
	NOTE: seconds might include a decimal portion
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-screentxt1"><a href="#CODE">&#8679</a> xe-ldas5-screentxt1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-screentxt1 v 1: 29.July.2016 [JRH]
----------------------------------------------------------------------
Extract lines if timestamp falls between start-stop-pairs (SSPs)
- NOTE: it is assumed timestamps are long-integers (sample-numbers)
USAGE:
	xe-ldas5-screentxt1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-scrf: screen-file (binary ssp) defining inclusion bounds []
	-scrl: screen-list (CSV) defining inclusion bounds []
	-ct: column containing long-integer timestamps [1]
EXAMPLES:
	xe-ldas5-screentxt1 data.txt -scrf times_immobile.ssp
	cat data.txt | xe-ldas5-screentxt1 stdin -scrl 0,1000,30000,31000
OUTPUT:
	all lines with timestamps falling within one of the SSPs
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-sliceEPSP"><a href="#CODE">&#8679</a> xe-ldas5-sliceEPSP</h3></font>
[<a href="#tag-SLICE">SLICE</a>][<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-sliceEPSP v 1: 6.September.2018 [JRH]
----------------------------------------------------------------------
Slice-ephys analysis: fibre-volley (FV) and fEPSP
- detect stim artefact (ART), FV & fEPSP with separate filters
- FV: 
	- find neg or pos inflection between max1 and max2
	- find next pos or previous neg inflection, respectively
	- check that duration &#60= 1.5*(max2-max1)
	- otherwise use (max1+max2)/2 as FV start and stop time
- fEPSP slope: top half of line connecting FV and fEPSP minimum
	- looks for most negative slope in 0.5ms sliding windows
	- seeks from FV +ivity to fEPSP trough
	- if no FV, use middle of max1-to-max2 (see below)

USAGE:  xe-ldas5-sliceEPSP [input] [channel] [options]
	[input]: WinLTP output filename or  "stdin"
	[channel]: channel to analyze- typically AD0 or AD1

VALID OPTIONS: defaults in []
  high-cut filter options (Hz)
	-high1 artefact filter [1500]
	-high2 fibre-volley & slope-detection filter [1800]
	-high3 fEPSP filter [250]
  maximum-times (ms) for phenomena
	-max1  ART +ivity, also minimum for FV -ivity [1.25]
	-max2  FV -ivity [2.5]
	-max3  fEPSP trough [15]
  other options
	-pos: FV detected as first(1) or last(2) inflection [2]
	-fout  output trace is filtered? (0=NO 1=high1, 2=high2, 3-high3) [2]
	-verb  sets verbosity (0=simple, 1=verbose) [0]

EXAMPLES:
	xe-ldas5-sliceEPSP 63290358.P0 AD1 -verb 1
	cat 63290358.P0 | xe-ldas5-sliceEPSP stdin AD1

SCREEN OUTPUT:
	artmv	fvms	fvmv	epspms	epspmv	epspslope

FILE OUTPUT:
	temp_xe-ldas5-sliceEPSP_trace.txt
		- trace in format &#60time&#62 &#60voltage&#62
	temp_xe-ldas5-sliceEPSP_nodes.txt
		- fEPSP & fibre-volley nodes (used for plotting)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-slicePOP"><a href="#CODE">&#8679</a> xe-ldas5-slicePOP</h3></font>
[<a href="#tag-SLICE">SLICE</a>][<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-slicePOP v 1: 31.August.2018 [JRH]
----------------------------------------------------------------------
Slice-electrophysiology analysis tool: POP-spike analysis
- calculate post-synaptic population-spike AUC and total RMS power
- POP-spike is the lowest-value between [min1] and [max1] (below)

USAGE:  xe-ldas5-slicePOP [input] [channel] [options]
	[input]: WinLTP output filename or  "stdin"
	[channel]: channel to analyze- typically AD0 or AD1

VALID OPTIONS: defaults in []
	-high1 :  POP-spike node-detection high-cut filter (Hz) [500]
	-min1  :  earliest time (ms) for pop-spike detection [2.5]
		- filtering starts at min1/2 to avoid stim-artefact
	-max1  :  latest time (ms) for pop-spike detection [15]
	-fout  :  output trace is filtered? (0=NO 1=YES) [1]
	-verb  :  sets verbosity (0=simple, 1=verbose) [0]

EXAMPLES:
	xe-ldas5-slicePOP 63290358.P0 AD0 -verb 1
	cat 63290358.P0 | xe-ldas5-slicePOP stdin AD0

SCREEN OUTPUT:
	pop1ms	pop1mv	pop3ms	pop3mv	popauc	rms

FILE OUTPUT:
	temp_xe-ldas5-slicePOP_trace.txt
		- trace in format &#60time&#62 &#60voltage&#62
	temp_xe-ldas5-slicePOP_nodes.txt
		- POP-spike nodes (used for plotting)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-spectproc1"><a href="#CODE">&#8679</a> xe-ldas5-spectproc1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>][<a href="#tag-filter">filter</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas5-spectproc1 v 1: 30.May.2018 [JRH]
----------------------------------------------------------------------
Process neurophysiological power spectra 
- adaptive smoothing (more smoothing at higher frequencies)
- FIR filtering to flatten the spectrum and reduce -ive AUC results
- calculates AUC for peaks, relative to line connecting valleys
USAGE: 
	xe-ldas5-spectproc1 [infile]
	[infile]: file or stdin in format [freq] [power]
VALID OPTIONS: defaults in []
	-bands: CSV band-triplets (start,mid,stop) [unset=auto]
	-out: stdout output (0= file-only, 1=spectrum, 2=bands) [0]
	-verb: verbose output (0=NO 1=YES) [0]
...smoothing options...
	-div: divisor in width= freq/div  (0=SKIP) [2]
...filter options (high-pass FIR, 101 taps)...
	-filt: HP filter frequency (0=SKIP) [0.0125]
OUTPUT:
	temp_xe-ldas5-spectproc1_spect.txt: the modified spectrum
	temp_xe-ldas5-spectproc1_bands.txt: stats for each detected band
		min mid max peak relpeak  auc aucpos aucneg  aucfull
		min: low-frequency boundary for the band
		mid: frequency at the band-peak
		max: high-frequency boundary for the band
		peak: absolute amplitude at the peak
		relpeak: amplitude relative to line joining min-max
		auc: half-width area-under-the-curve (maximises info)
		aucpos: as above, positive-values only
		aucneg: as above, negative-values only
		aucful: complete AUC between min and max
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas5-wavestats1"><a href="#CODE">&#8679</a> xe-ldas5-wavestats1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-spikes">spikes</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>----------------------------------------------------------------------
xe-ldas5-wavestats1 v 1: 24.March.2018 [JRH]
----------------------------------------------------------------------
Calculate waveform statistics from a multi-channel .wfm file
USAGE:
	xe-ldas5-wavestats1 [.wfm file] [options]
	[.wfm file]: file containing mean waveforms for each cluster
VALID OPTIONS: defaults in []
	-sign: peak detect sign (-1:negative 1:positive) [-1]
	-low: filter low-cut (0=none) [300]
	-high: filter high-cut (0=none) [5000]
	-thresh: proportion-of-peak at which to calculate width [0.25]
OUTPUT:
	[cluster] [width] [peak] [corr]

	cluster : cluster-ID
	n : number of spikes in cluster
	pchan: channel-ID containing the peak (depends on -sign)
	peak (uV) : amplitude in pchan at time zero
	width (ms): for max-peak channel, width at half-amplitude
	corr : mean Pearson's correlation for all good channel-pairs
	pmin : minimum value across channels at peak-time
	pmax : maximum value across channels at peak-time
	pdiff : the difference between pmax and pmin
	pratio: pmin/pmax (range 0-1, 1= identical values)
		- if pmin&#600 & pmax&#600, then the ratio is pmax/pmin
		- if pmin&#600 & pmax&#620, -1= max opposite values

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-align1"><a href="#CODE">&#8679</a> xe-ldas-align1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>][<a href="#tag-filter">filter</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-align1 v 29: 1.August.2017 [JRH]
----------------------------------------------------------------------
Align data to start/stop signals in a separate file
MEMORY_REQUIREMENTS: 4*double (32 bytes) for every &#60time&#62&#60data&#62 pair
USAGE: xe-ldas-align1 [input] [cfile] [options]
	[input]: data file or "stdin" in format &#60time&#62 &#60data&#62
	[cfile]: comment file of format &#60time&#62 &#60comments&#62
VALID OPTIONS (defaults in []):
	-low: low frequency limit [0]
	-high: high frequency limit [0]
	-start: keyword [cfile] signalling start a data block [start]
		NOTE: consecutive starts force insertion of an stop
		NOTE: an exact match is not required
		e.g.: -start "A" will detect "A_on" and "A_off"
	-stop: keyword in comment signalling stop of a data block [stop]
		NOTE: if undefined, blocks run to next start or end of file
	-dur: fixed duration of output after each start [0, i.e. unset]
		NOTE: if set, this overrides -stop 
		NOTE: blank lines in [cfile] will invalidate unfinished blocks
	-pre: time before block-starts to also include [0]
	-pn:  time before block start for normalization [default: same as -pre]
	-norm: normalization style for each block [0]
		0: none
		1: subtract sample from time-zero (start)
		2: subtract the mean of the -pn period (excludes start)
		3: convert to a Z-score based on -pn
	-rmshresh: RMS threshold for block-rejection (0=NONE) [0]
	-sdthresh: std.dev. threshold for block-rejection (0=NONE) [0]
		+ive: an absolute std.dev threshold
		-ive: a multiple of the std.dev spanning all blocks
	-first: first block to use (numbered from zero) [0]
	-last:  last block to use (-1=to the last one) [-1]
	-sz: sample at -pre becomes zero in output (0=NO 1=YES) [1]
	-bin: size (secs) of time-bins used to average data (0=none) [0]
		NOTE: if -pre is not a multiple of -bin, time values 
		      will be adjusted so that time zero is output,
		      but consequently the first aligned time may
		      be different from -pre (0-centred time averaging)
	-flip: flip data (multiply by -1) (0=NO 1=YES) [0]
	-verb: verbosity of reporting (0=none,1=report to stderr) [1]
EXAMPLES:
	xe-ldas-align1 sub001.dat sub001.cmt -start "pump on"
	cat my.dat | xe-ldas-align1 stdin temp.cmt -start "ON" -dur 5
OUTPUT:
	- [block] [time-in-block] [datavalue]
	- file temp_xe-ldas-align1.txt (AUC for each block)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-align2"><a href="#CODE">&#8679</a> xe-ldas-align2</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>][<a href="#tag-filter">filter</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-align2 v 10: 6.April.2015 [JRH]
----------------------------------------------------------------------
Align data to start signals in a separate file
	- this version assumes binary input with constant sampling rate
	- all "times" are expressed as samples
MEMORY_REQUIREMENTS: 4*double (32 bytes) for every &#60time&#62&#60data&#62 pair
USAGE: xe-ldas-align2 [input] [start] [options]
	[input]: data file
	[start]: file containing block start-samples (zero-offset)
VALID OPTIONS (defaults in []):
	-dt: type of data [0]
		-1  = ASCII
		0-9 = uchar,char,ushort,short,uint,int,ulong,long,float,double
	-sf: sample frequency (Hz) - used to adjust output-samples to times [1]
	-low: low frequency limit, 0=NONE [0]
	-high: high frequency limit, 0=NONE [0]
	-pre: samples preceding block-starts to include [0]
	-post: samples after block-starts to include [10]
		NOTE: total block size = pre+post+1, as the new "0" is included
	-pn: pre-start samples to include for normalization [default:same as -pre]
		NOTE: includes the new "0", so #samples actually = pn+1
	-pnx: samples (including start) to exclude from normalization [0]
		- use if input was smoothed, to exclude predictive samples
		- e.g. if -pnx = 1, only new sample "0" will be excluded
		- e.g. if -pnx = -pn, only 1 sample will be used!
	-norm: normalization method [0]
		0:none, 1: sample zero (start), 2: -pn average, 3:z-score
		4:de-mean 5: de-trend (4 & 5 apply to entire block
	-first: select first block to use (numbered from zero) [0]
	-last: select last block to use (-1=to the last one) [-1]
	-nbins: number of non-overlapping bins to average output (0=none) [0]
	-flip: flip data (multiply by -1) (0=NO, 1=YES) [0]
	-out: output type (0=average, 1=all aligned blocks) [0]
	-verb: verbosity of reporting (0=none,1=report to stderr) [0]
EXAMPLES:
	xe-ldas-align2 sub001.dat sub001.cmt -start "pump on"
	cat temp.dat | xe-ldas-align2 stdin temp.cmt -start "ON" -dur 60
OUTPUT - ASCII version of data as follows:
	if -out 0: [time-in-block] [average]
	if -out 1: [block] [time-in-block] [original-value]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-invalidcmt1"><a href="#CODE">&#8679</a> xe-ldas-invalidcmt1</h3></font>
[<a href="#tag-ldas">ldas</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-invalidcmt1 v 2: 14.August.2012 [JRH]
----------------------------------------------------------------------
A tool to select trials with a particular response-time from a series
Invalidates pairs of lines in a comment (.cmt) file based on interval
That is, if two comments in a row occur at the wrong interval, replace
  one or both of them with the word "INVALID"
Only comment-pairs occurring in the specified sequence will be checked
USAGE:
	xe-ldas-invalidcmt1 [input] [mode] [c1] [c2] [options]
	[input]: a filefile or "stdin" in [time][TAB][comment] format
	[mode]:  match mode, "contains" or "exact"
	[c1]: first comment in pair to match
	[c2]: second comment in pair to match
  [options] defaults in []:
	  -min: minimum interval between c1 and c2 (0)
	  -max: maximum interval between c1 and c2 (100)
	  -inv: invalidate mode: 0=neither, 1=c1, 2=c2, 3=both [3]
OUTPUT:
	The original input, with some comments replaced with the word "INVALID"
NOTE:
	Start and end words cannnot be the same
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-medcmt1"><a href="#CODE">&#8679</a> xe-ldas-medcmt1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-MED">MED</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-medcmt1 v 1: 24.September.2012 [JRH]
----------------------------------------------------------------------
Output event-comments from a Med-Associates file
Assumes the input file has subject headers and blocks of [time].[event]
- a colon separates labels from header values and data
- data blocks are separated by letter-IDs (A: B: C: etc.)
- each data line begins with the index-number of the first datum
- time is the part of the datum before the decimal
- event type (eg 100) comes after the decimal. 000 indicates no event
- sample input file...

	Start Date: 04/26/12
	Subject: 9
	Experiment: CAR_002
	Group: Box
	Box: 1
	A:
	     0:      965.100       46.100      109.100      135.000
	     4:        0.000
	C:
	     0:       20.100       26.200       33.100       26.200
	     4:       33.100       33.200       25.100        0.000
	     8:        0.000        0.000        0.000        0.000

USAGE:
	xe-ldas-medcmt1 [input] [options]
		[input]: Med-Associates input file or "stdin"

VALID OPTIONS (defaults in []):
	-b(lock) to output (a single capital letter) [K]
	-t(time) multiplier, as time may not be seconds [0.1]
		e.g. if time is in seconds, set to 1
		e.g. if time is in tenths of seconds, set to 0.1
		e.g. if time is in tens of seconds, set to 10

EXAMPLES:
	xe-ldas-medcmt1 data.txt -b A
	cat temp.txt | xe-ldas-medcmt1 stdin -b K -t 10

OUTPUT: multiple files called [sub]-[yymmdd].med2  (e.g. 009-001231.med2)
	1st column: time in seconds
	2nd column: event label (eg. 100, 200, etc)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-readchart1"><a href="#CODE">&#8679</a> xe-ldas-readchart1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-readchart1 v 17: 12.March.2015 [JRH]
----------------------------------------------------------------------
Read biosensing data output from Chart program
Assumptions:
	- input has header specifying date, channel names, labels etc.
	- data format: time ch1 ch2 &#60etc&#62... comment1 comment2 &#60etc&#62
	- tab separates columns for time, data and comments
	- for old CHART files: 
		"#" separates the comment for each channel
		simultaneous comments for a given channel are disallowed
	- for newer CHART files: 
		a tab separates comments for each channel
		"#"  preceeds each comment for a given channel
Calculates sample frequency based on median sample-interval
Will handle comments and channel names with spaces
Will correct for time-stamp resets mid-trial by adjusting timestamps
	after the reset, adding the previous timestamp + 2x the sample interval
	(ie. times will be made to run in order, with a small gap as a reminder
Automatically detemines number of channels from file header
Assigns channel-number to output  based on the order they appear in the 
	input (001, 002, 003 etc.)
USAGE:
	xe-ldas-readchart1 [input][options]
	[input]: file name (CHART txt export file with header)
VALID OPTIONS (defaults in []):
	-chancol: column containing channel to be extratced [2]
		NOTE: time is in col.1, and columns may not map onto channels
	-channame: name of channel to extract []
		NOTE: overrides -chancol. Unset by default
	-time: output time records? (0=no, 1=yes) [1]
EXAMPLES:
	xe-ldas-readchart1 data.txt -t 1
OUTPUT:
	[base].[channel].dat : all samples from one channel
	[base].[channel].cmt : comments (time comment) from one channel
	[base].time : timestamps for all samples
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-ldas-txt2clb1"><a href="#CODE">&#8679</a> xe-ldas-txt2clb1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-SCORE">SCORE</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-ldas-txt2clb1 v 2: 6.October.2014 [JRH]
----------------------------------------------------------------------
Convert ASCII input stream to 3EG .clb file (16-bit short int)
Assumes one valid numeric value per input line
Assumes the data type is "waveform" (continuously sampled data)
Non-numeric values will be ignored
Timestamps assigned to records reflect time of conversion
USAGE:
	xe-ldas-txt2clb1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS (defaults in []):
	-sf: sample rate (Hz) [400]
	-dur: duration (seconds) of each record [10]
	-out: output file name, or "stdout" [stdout]
	-version: define CLB/XML version to use [1]
EXAMPLES:
	xe-ldas-txt2clb1 data.txt -sf 400 -dur 60 -out data.clb
	cat data.txt | xe-ldas-txt2clb1 stdin -sf 100 -dur 20 -out stdout
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-lombscargle1"><a href="#CODE">&#8679</a> xe-lombscargle1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-lombscargle1 v 4: 21.August.2018 [JRH]
--------------------------------------------------------------------------------
Calculate the Lombs-Scargle periodogram for an autocorrelation
USAGE:
	xe-lombscargle1 [input] [options]
	[input]: file name or "stdin", format = autocorrelation &#60interval&#62 &#60count&#62
		- recommend 1using +-500ms autocorellogram with 200 bins (5ms width)
		- note only intervals &#620 will be considered
		- input counts will be normalized (mean=0, s.d.=1)
VALID OPTIONS:
	-min: lowest frequency to analyze (-1 = AUTO) [-1]
	-max: highest frequency to analyze (-1 = AUTO) [-1]
	-nfreq: number of frequencies to output [100]
	-bands: comma-separated freq-bands-pairs for ratio calculation [unset]
	-g: apply Gaussian smoothing (samples) to output [0]
		- must be an odd integer &#62=3, or 0= no smoothng)
		- no effect on calculations (applied to output only)
	-out: output (1=summary, 2=periodogram) [1]
	-norm: normalize LS-periodogram (-1=NO, 0=0-1, 1=Zscore) [-1]
	-verb sets verbosity (0=simple, 1=summary to stderr) [0]
EXAMPLES:
OUTPUT (-out1):
	summary stats
	AUC for each zone
	Ratio of AUCzone / (AUCzone + AUCtotal)
OUTPUT (-out2):
	1st column: Frequency
	2nd column: Periodogram value [scaling uncertain at this point]
	3rd column: Significance (p)
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-makedata1"><a href="#CODE">&#8679</a> xe-makedata1</h3></font>
[<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-makedata1 v 11: 23.January.2017 [JRH]
----------------------------------------------------------------------
Create a fake data signal at a given frequency with added white noise
Includes option to create periodic changes to the signal (events)

USAGE:
	xe-makedata1 [dur] [rate] [options]
	[dur]: length of output, in seconds (see -end option, below)
	[rate]: sampling rate in samples/second (e.g. 24000))

VALID OPTIONS (defaults in []):
	-t: signal type [1]
		0: cosine function
		1: sine function
	-p: phase offset (0-180) for signal types 0 and 1, above [0]
	-f: frequency (Hz) of signal to insert [10]
	-fsd: standard deviation (Hz) around the main frequency [0]
		NOTE: for some combinations of -f and rate, it may not
		be possible to produce a cycle at exacly frequency -f,
		especially as -f exceeds 1/10 the sample rate. This
		can be corrected by increasing sampling rate or -vf.
	-a: amplitude multiplier for signal (base = -1 to 1)  [1]
	-n: amplitude multiplier for noise (base value is 0-1) [0]
	-g: noise distribution (0=uniform, 1=gaussian) [0]
		NOTE: generated using Box-Muler method
		NOTE: for Gaussian noise, -n determines the std.deviation
	-end: also output data for [dur] timestamp (0=NO 1=YES)  [0]
	-o: output format: 1=&#60data&#62, 2=&#60time&#62&#60tab&#62&#60data&#62 [1]

OPTIONS FOR DEFINING PERIODIC EVENTS:
(changes in frequency, frequency std.dev., amplitude or noise
	-et: event type (0=none, 1=complete each cycle, 2=force change) [0]
		NOTE: event type must be &#620 for any events to be generated
		NOTE: -et 1 may cause variation (&#601 cycle) in event times
		NOTE: -et 2 may cause abrupt changes at event boundaries
	-ed: event duration, in seconds [0.000000]
	-ei: interval between events, in seconds [0.000000]
	-ef: signal frequency during event (-1:no change)[-1]
	-efsd: std.dev of freq. durng event (-1:no change)[-1]
	-ea: amplitude during event (-1:no change)[-1]
	-en: noise level during event (-1:no change) [-1]

EXAMPLE: 10s @24KHz of 4Hz signal, amplitude x2 for 1s every 5s:
	xe-makedata1 10 24000 -f 4 -n 0 -et 1 -ei 5 -ed 1 -ea 2

OUTPUT:
	1st column: mytime (seconds)
	2nd column: fake signal = attenuation*(sinewave-noise)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-makedata2"><a href="#CODE">&#8679</a> xe-makedata2</h3></font>
[<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-makedata2 v 1: 23.January.2017 [JRH]
----------------------------------------------------------------------
Create a fake data signal at a given frequency with added white noise
Includes option to create periodic changes to the signal (events)

USAGE:
	xe-makedata2 [dur] [rate] [options]
	[dur]: length of output, in seconds (e.g. 10)
	[rate]: sampling rate in samples/second (e.g. 24000))

VALID OPTIONS (defaults in []):
	-p: pulse duration (s) [1]
	-i: pulse interval (s) [-1]
	-fsd: standard deviation (Hz) around the main frequency [0]
		NOTE: for some combinations of -f and rate, it may not
		be possible to produce a cycle at exacly frequency -f,
		especially as -f exceeds 1/10 the sample rate. This
		can be corrected by increasing sampling rate or -vf.
	-a: amplitude multiplier for signal (base = -1 to 1)  [1]
	-n: amplitude multiplier for noise (base value is 0-1) [0]
	-g: noise distribution (0=uniform, 1=gaussian) [0]
		NOTE: generated using Box-Muler method
		NOTE: for Gaussian noise, -n determines the std.deviation
	-t: signal type [0]
		0: half-sine
		1: square-wave
	-end: also output data for [dur] timestamp (0=NO 1=YES)  [0]
	-o: output format: 1=&#60data&#62, 2=&#60time&#62&#60tab&#62&#60data&#62 [1]

OPTIONS FOR DEFINING PERIODIC EVENTS:
(changes in frequency, frequency std.dev., amplitude or noise
	-et: event type (0=none, 1=complete each cycle, 2=force change) [0]
		NOTE: event type must be &#620 for any events to be generated
		NOTE: -et 1 may cause variation (&#601 cycle) in event times
		NOTE: -et 2 may cause abrupt changes at event boundaries
	-ed: event duration, in seconds [0.000000]
	-ei: interval between events, in seconds [0.000000]
	-ep: signal frequency during event (-1:no change)[-1]
	-epsd: std.dev of freq. durng event (-1:no change)[-1]
	-ea: amplitude during event (-1:no change)[-1]
	-en: noise level during event (-1:no change) [-1]

EXAMPLE: 10s @24KHz of 4Hz signal, amplitude x2 for 1s every 5s:
	xe-makedata2 10 24000 -f 4 -n 0 -et 1 -ei 5 -ed 1 -ea 2

OUTPUT:
	1st column: mytime (seconds)
	2nd column: fake signal = attenuation*(sinewave-noise)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-makepairs1"><a href="#CODE">&#8679</a> xe-makepairs1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-makepairs1 v 1: 16.April.2019 [JRH]
----------------------------------------------------------------------
Make a list of all possible item-pairs
USAGE: xe-makepairs1 [in] [options]
	[in]: input file name or "stdin" in CSV format
		- NOTE: newlines will be treated as commas
VALID OPTIONS: defaults in []
	-NONE-
EXAMPLES:
	echo "a,b,c,d" | xe-makepairs1 stdin 
OUTPUT:
	CSV pairs of items, newline separated
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matchlist"><a href="#CODE">&#8679</a> xe-matchlist</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
**************************************************************************
xe-matchlist v 2.0: JRH, 6.June.2010
- Match data-file columns against list-file columns (numeric only, max 15)
- Use this to select lines from large data files
- USAGE: xe-matchlist [datafile] [listfile] [arguments]
- Arguments - defaults in ()...
	-dc [col1,col2...]: datafile columns which must match (1)
	-lc [col1,col2...]: listfile columns defining "good" values (1)
- Example: match "a.txt" cols 1,4&5 against "list.txt" cols 1,2&3 (respectively):
	xe-matchlist  a.txt  list.txt -dc 1,4,5  -lc 1,2,3

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matchtimes1"><a href="#CODE">&#8679</a> xe-matchtimes1</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matchtimes1 v 6: 11.February.2014 [JRH]
----------------------------------------------------------------------
Extract lines from a data file falling between start-stop times in timefile
infile may specify time in 1 or 2 columns times per line
Two columns specify a range which must fall within those in the timefile
USAGE: 
	xe-matchtimes1 [datafile] [timefile] [options]
		[datafile]: filename or "stdin" containing time+data
		[timefile]: filename containing start-stop times
VALID OPTIONS:
	-d1: time column in infile [1]
	-d2: optional end-time column in infile (-1 = ignore) [-1]
	-t1: start-time column in timefile [1]
	-t2: end-time column in timefile [2]
	-inv: inverse match - OMIT matching lines (-1=NO,1=YES) [-1]
	-pad: define a pad string (eg "-1") for out-of-range lines
		if undefined, out-of-range lines are omitted
		NOTE: padding only affects non-time columns, so if infile
		only has time columns, padding will not be apparent!
	-out destination filename or stdout or stderr (stdout)
EXAMPLE:
	xe-matchtimes1 a.txt times.txt -d1 1 -d2 -1 -out results.txt
OUTPUT:
	[tab]-delimited contents of each line meeting time-criteria

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matchtimes2"><a href="#CODE">&#8679</a> xe-matchtimes2</h3></font>
[<a href="#tag-database">database</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matchtimes2 v 1: 3 December 2012
----------------------------------------------------------------------
Extract lines from a data file falling between start-stop times in timefile
Output is to a separate file for each window
Data may include a time-column or fixed sample-freq. can be assumed
Note that if windows overlap, earlier window "grabs" overlapping portion
USAGE: 
	xe-matchtimes2 [infile] [timefile] [options]

		[infile]: data file with or without time-column
		[timefile]: file containing start and stop times (s)
VALID OPTIONS:
	-d1: time column in infile [1]
	-sf: sample-freq. (Hz) of input - assumes constant interval [-1]
		NOTE : if &#620, this will override -d1
	-z: set time of first sample (only used if -sf &#620) [-1]
	-t1: start-time column in timefile [1]
	-t2: end-time column in timefile [2]
EXAMPLE:
	xe-matchtimes2 a.txt times.txt -d1 1 
OUTPUT:
	- a chunk of the data file for each window
	- files are named temp_xe-matchtimes2_[window#].txt

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_abs1"><a href="#CODE">&#8679</a> xe-math_abs1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_abs1 v 1: 9.January.2016 [JRH]
----------------------------------------------------------------------
Convert a column of data to its absolute value
Non-numeric fields will not be modified
USAGE:
 	xe-math_abs1 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-cy column containing data (0=none, -1=all) [1]
Examples:
	cat datafile.txt | xe-math_abs1 stdin -cy 1
	xe-math_abs1 datafile.txt -cy 2
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_add1"><a href="#CODE">&#8679</a> xe-math_add1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_add1 v 2: 27.November.2017 [JRH]
----------------------------------------------------------------------
Add a number to a column of data
Non-numeric fields will not be modified
USAGE:
 	xe-math_add1 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-cy column containing data (0=none, -1=all) [1]
	-v value to add to this column [0]
	-long: assume input is long-integers (0=NO 1=YES) [0]
Examples:
	cat datafile.txt | xe-math_add1 stdin -cy 1 -v 25
	xe-math_add1 datafile.txt -cy 2 -v 1
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_div1"><a href="#CODE">&#8679</a> xe-math_div1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_div1 v 2: 27.November.2017 [JRH]
----------------------------------------------------------------------
- Divide a column of data by a number
- Non-numeric fields will not be modified
- NOTE: safe for input lines &#60 10000 characters
USAGE:
 	xe-math_div1 [infile] [options]
VALID OPTIONS (defaults) in []:
	-cy column containing data (0=none, -1=all) [1]
	-v value to divide this column by [1]
	-long: assume input is long-integers (0=NO 1=YES) [0]
EXAMPLES:
	cat datafile.txt | xe-math_div1 stdin -cy 1 -v 3.14
	xe-math_div1 datafile.txt -cy 2 -v 7
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_doublet"><a href="#CODE">&#8679</a> xe-math_doublet</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_doublet v 3: 20.January.2019 [JRH]
----------------------------------------------------------------------
Modify column-y by column-x
Non-numeric or non-finite fields produce NAN output (line-count preserved)
USAGE:
 	xe-math_doublet [input] [options]
		[input]: file name or "stdin" in format &#60col1&#62 &#60col2&#62
VALID OPTIONS: defaults in []:
	-cx: column containing the modifier [1]
	-cy: column to be modified [2]
	-long: assume input is long-integers (0=NO 1=YES) [0]
	-t type of operation[1]
		1: y+x addition
		2: y-x subtraction
		3: y*x multiplication
		4: y/x division
	-out: output modified column (0) or all columns (1) [0]
EXAMPLES:
	cat datafile.txt | xe-math_doublet stdin -t 2
	xe-math_doublet datafile.txt -t 1
OUTPUT:
	single column result
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_index1"><a href="#CODE">&#8679</a> xe-math_index1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_index1 24.February.2019 [JRH]
----------------------------------------------------------------------
Identify the index to an item in a list, given the list parameters
- use when there's no no index (e.g. time) associated with each value
USAGE: xe-math_index1 [min] [max] [n] [val]
	[min] : minimum value in series
	[max] : maximum value in series
	[n]   : number of items in  series
	[val] : value for which index is required
EXAMPLES: in a 15-second time series sampled at 100Hz...
 - find index to value at 7 seconds
	xe-math_index1 0 15 100 7
OUTPUT:
	- index to the value, rounded down to the nearest integer
	- NOTE: index is zero-offset
----------------------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_mult1"><a href="#CODE">&#8679</a> xe-math_mult1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_mult1 v 2: 27.November.2017 [JRH]
----------------------------------------------------------------------
Multiply a column of data by a number
Non-numeric fields will not be modified
USAGE:
 	xe-math_mult1 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-cy column containing data (0=none, -1=all) [1]
	-v value to multiply this column by [1]
	-long: assume input and value are long-integers (0=NO 1=YES) [0]
Examples:
	cat datafile.txt | xe-math_mult1 stdin -cy 1 -v 0.001
	xe-math_mult1 datafile.txt -cy 2 -v 100
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_power1"><a href="#CODE">&#8679</a> xe-math_power1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_power1 v 4: 27.November.2017 [JRH]
----------------------------------------------------------------------
Raise a column of data by a power eg. square (2), cube (3), square-root (0.5)
Non-numeric fields will not be modified
USAGE:
 	xe-math_power1 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-cy column containing data (0=none, -1=all) [1]
	-v power to raise this column by [0]
Examples:
	cat datafile.txt | xe-math_power1 stdin -cy 1 -v 3
	xe-math_power1 datafile.txt -cy 2 -v 0.5
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_round1"><a href="#CODE">&#8679</a> xe-math_round1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_round1v 12: 15.July.2016 [JRH]
----------------------------------------------------------------------
Round a column of data to the nearest base (0.1, 15, 230, etc.)
Non-numeric fields will not be modified
USAGE:
 	xe-math_round1 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-cy column containing data (0=none, -1=all)z[1]
	-b base for rounding to the nearest [1.00]
	-d round down instead? (0=NO, 1=YES) [0]]
	-o output original values as well (0=NO, 1=YES) [0]
Examples:
	cat datafile.txt | xe-math_round1 stdin -cy 1 -b 0.001
	xe-math_round1 datafile.txt -cy 2 -b 120
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_round2"><a href="#CODE">&#8679</a> xe-math_round2</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_round2 v 9: 15.July.2016 [JRH]
----------------------------------------------------------------------
Round columns of data to the nearest base (0.1, 15, 230, etc.)
Non-numeric fields will not be modified
USAGE:
 	xe-math_round2 [infile|stdin] [arguments]
Valid arguments - defaults in []:
	-c: columns to round, comma-separated, max 256 (default: round all)
	-b base for rounding to the nearest [1.00]
	-d round down instead? (0=NO, 1=YES) [0]
Examples:
	cat datafile.txt | xe-math_round2 stdin -c 1,2,9 -b 0.001
	xe-math_round2 datafile.txt -b 120
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-math_sum1"><a href="#CODE">&#8679</a> xe-math_sum1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-math_sum1 v 4: 27.November.2017 [JRH]
----------------------------------------------------------------------
Calculate the sum of a stream of numbers
Non-numeric values will be ignored
USAGE:
	xe-math_sum1 [input] [options]
	[input]: filename or "stdin", single-column of numbers
VALID OPTIONS (defaults) in []:
	-long: assume input is long-integers (0=NO 1=YES) [0]
EXAMPLES:
	xe-math_sum1 data.txt
	cut -f 1 data.txt | xe-math_sum1 stdin
	echo "1 2 3 4 5" | xe-math_sum1 stdin
OUTPUT:
	the sum
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixavg2"><a href="#CODE">&#8679</a> xe-matrixavg2</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-matrix">matrix</a>][<a href="#tag-noise">noise</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixavg2 v 1: 22.January.2019 [JRH]
----------------------------------------------------------------------
Average multiple matrices separated by blank-lines or comments
- first matrix defines matrix format (rows & columns)
- all matrices must have the same number of rows and columns
- non-numeric values will not contribute to the mean
- includes option to de-noise and filter the matrix, in that order
	- these assume columns=time (but see -r option below)

USAGE: xe-matrixavg2 [infile] [options]
	[infile]: file (or "stdin") containing data matrix/matrices
		- format: space-delimited numbers in columns and rows
		- matrix separator= blank or lines beginning with "#"
		- missing values require placeholders (NAN, "-", etc.)

DE-NOISING OPTIONS aplied to each matrix: defaults in []
	-z: Z-score threshold for noise at each freq (NAN=skip) [nan]
	-c: Z-score clipping-value, to avoid outliers (-1=noclip) [-1]
	-s: sign of thesholding (-1=NEG,+1=POS,0=BOTH) [0]
	-p: % of freq &#62 z needed to invalidate timepoint [25]
		- e.g. Z&#623 for 25% of the spectrum at column 872
	-r: 90-deg rotate for analysis (0=NO 1=YES) [0]
		- use for if input column=freq and row=time
		- matrix will be rotated back for output

NORMALIZATION OPTIONS (applied to rows): defaults in []
	-norm: normalization type: [-1]
		-1: no normalization 
		 0: 0-1 range
		 1: z-scores (see -n1/-n2)
		 2: difference from first valid sample (see -n1)
		 3: difference from mean (see -n1/-n2) 
		 4: ratio of mean (see -n1/-n2)
	-n1: start of normalization zone (samples) [-1]
	-n2: end of normalization zone (sample) [-1]
		- set n1|n2 to -1 to signify first|last valid sample

FILTER OPTIONS (applied to rows): defaults in []
	-fsr: sample-rate (Hz) [1]
	-flo: low-frequency cut (0=NONE) [0]
	-fhi: high-frequency cut (0=NONE) [0]

EXAMPLES:
	xe-matrixavg2 matrix.txt
OUTPUT:
	A single average of the individual matrices
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixcut1"><a href="#CODE">&#8679</a> xe-matrixcut1</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixcut1 v 1: 2.March.2018 [JRH]
----------------------------------------------------------------------
Extract a single matrix from a multi-matrix file
- looks for a unique numeric ID on a line starting with "# "
USAGE: xe-matrixcut1 [matrix] [options]
	[matrix]: file or "stdin" in (multi)matrix format
		- matrices separated by "# &#60id-number&#62" lines
VALID OPTIONS (defaults in []):
	-idcol: zero-offset column on comment-lines holding the ID [1]
	-id:  numeric ID to match [1]
	-head:  output header line (0=NO 1=YES) [1]
EXAMPLES:
	xe-matrixcut1 matrix.txt -id 001
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixcut2"><a href="#CODE">&#8679</a> xe-matrixcut2</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixcut2 24.February.2019 [JRH]
----------------------------------------------------------------------
Extract matrices (numbers only) from a multi-matrix file
- looks for a match with an ID on comment-lines separating matrices
- NOTE: max 256 characters are scanned from comment-lines
USAGE: xe-matrixcut2 [matrix] [options]
	[matrix]: file or "stdin" in (multi)matrix format
		- matrices separated by "# comment" lines
VALID OPTIONS (defaults in []):
	-col   : column on comment-lines holding the ID [1]
	-id    : ID to match (if unset, matches all matrices) []
	-match : mode (1=partial 2=exact, 3=integer 4=float) [2]
	-head  : output header line (0=NO 1=YES) [1]
EXAMPLES:
	xe-matrixcut2 matrix.txt -col 4 -id dose3 -match 2
	xe-matrixcut2 matrix.txt -col 7 -id 0.50 -match 4
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixcut2_inprogress"><a href="#CODE">&#8679</a> xe-matrixcut2_inprogress</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixcut2 24.February.2019 [JRH]
----------------------------------------------------------------------
Extract matrices (numbers only) from a multi-matrix file
- looks for a match with an ID on comment-lines separating matrices
- NOTE: max 256 characters are scanned from comment-lines
USAGE: xe-matrixcut2 [matrix] [options]
	[matrix]: file or "stdin" in (multi)matrix format
		- matrices separated by "# comment" lines
VALID OPTIONS (defaults in []):
	-col   : column on comment-lines holding the ID [1]
	-id    : ID to match (if unset, matches all matrices) []
	-match : mode (1=partial 2=exact, 3=integer 4=float) [2]
	-head  : output header line (0=NO 1=YES) [1]
EXAMPLES:
	xe-matrixcut2 matrix.txt -col 4 -id dose3 -match 2
	xe-matrixcut2 matrix.txt -col 7 -id 0.50 -match 4
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixdiff1"><a href="#CODE">&#8679</a> xe-matrixdiff1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixdiff1 v 2: 13.April.2013 [JRH]
----------------------------------------------------------------------
Calculate the difference between two matrices or multi-matrices
Second matrix is subtracted from the first
First matrix defines the matrix format (rows & columns)
All other matrices must have the same format
Uses a T-test to mask non-significant differences (set to NAN) 
Data may be treated as paired or independent
	- if unpaired, the input-avg. in each bin is calculated first
	- if paired, the average difference in each bin is used
	- if paired, each input must contain the same number of matrices
	- if paired, the order of the matrices specifies the pairing

USAGE:
	xe-matrixdiff1 [infile1] [infile2]

	[infile1]: file containing reference data matrix/matrices
		- format: space-delimited numbers in columns and rows
		- multiple matrices must be separated by a blank line
		- lines beginning with "#" may also separate matrices
		- missing values require placeholders (NAN, "-", etc.)
	[infile2]: the reference matrix is subtracted from this

VALID OPTIONS:
		-p(aired) t-test? (0=NO, 1=YES) [0]
		-a(lpha) significance level for masking output [0.05]
			valid alpha levels: 1, .05 .02 .01 .002 .001
		-t(ype) of output [1]
			1= difference (mean2-mean1)
			2= ratio (mean2/mean1)
			3= t-statistic on the differences
EXAMPLES:
	xe-matrixdiff1 matrix1.txt matrix2.txt -p 1 -a 0.01
OUTPUT:
	The average difference between the matrices, masked using -a
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixmod1"><a href="#CODE">&#8679</a> xe-matrixmod1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixmod1 v 21.October.2017 [JRH]
----------------------------------------------------------------------
Modify a matrix:
	flip/rotate/transpose,resample,smooth,Fisher-transform,normalize - in that order
USAGE:
	xe-matrixmod1 [input] [options]
	[input]: file or "stdin" in matrix format
VALID OPTIONS (defaults in []):
	-flip : flip matrix (0=NO, 1= x-flip, 2= y-flip) [0]
	-t : transpose (0=NO, 1=YES - cannot be combined with rotation) [0]
	-r : rotation, in degrees (choose 0,+-90,+-180,+-270) [0]
	-w : width, set (resample) number of columns [0]
	-h : height, set (resample) number of rows [0]
		NOTE: expands or averages data in each row/column as needed
		NOTE: set to zero to leave as-is
	-sx : 2D gaussian smoothing factor to apply to matrix [0]
	-sy : 2D gaussian smoothing factor to apply to matrix [0]
	-pn : preserve NANs when smoothing (0=NO 1=YES) [0]
	-n : normalization, 0=no, 1=0-1 range, 2=z-scores [0]
	-f : Fisher z' transformation : 0=no, 1 or 2 = yes [0]
			transform for r-values
			set to 1 of numbers range from -1 to 1
			set to 2 of numbers range from  0 to 1
EXAMPLES:
	xe-matrixmod1 matrix.txt -n 0 -sx 1 -sy 2 
OUTPUT:
	An [width]x[height] modified matrix
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixpeak1"><a href="#CODE">&#8679</a> xe-matrixpeak1</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixpeak1 v 3: 15.February.2019 [JRH]
----------------------------------------------------------------------
Detect contiguous pixels exceeding a threshold in individual matrices 
 - this peak starts at the highest-value pixel and propogates outward
 - diagonal propogation is not permitted
 - if peak size is below a minimum, another attempt is made
 - attempts are made until no peak is detected at all
USAGE: xe-matrixpeak1 [matrix] [options]
	[matrix]: file or "stdin" in (multi)matrix format
		- matrices separated by "# &#60id-number&#62" lines
VALID OPTIONS (defaults in []):
	-idcol: the column on comment-lines holding the ID [1]
	-thresh : edge-detection threshold (proportion of peak) [0.25]
	-size   : size threshold (number of pixels, zero=any) [0]
	-first  : output first good peak only (0=NO 1=YES) [1]
	-out    : output [1]
		1: peak statistics are sent to stderr
		2: the mask sent to stdout
		3: both
EXAMPLES:
	{ xe-matrixpeak1 matrix.txt -thresh 1 -first 0 &#62 matrix2.txt ; } 2&#62 report.txt 
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixsplit1"><a href="#CODE">&#8679</a> xe-matrixsplit1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixsplit1 v 1: 13.October.2014 [JRH]
----------------------------------------------------------------------
Split a large matrix (y-axis= time, top=zero) into blocks
Uses a start/stop file to determine which rows 
Non-numeric values will be ignored
USAGE:
	xe-matrixsplit1 [input] [blockfile] [options]
	[input]: file name or "stdin"
	[blockfile]: file containing &#60start&#62 &#60stop&#62 pairs defining blocks
		- &#60start&#62 and &#60stop&#62 are row-numbers, starting at zero
		- blocks must not overlap
		- however &#60stop&#62 for one block may be &#60start&#62 for the next
		- the &#60stop&#62 sample is not included in the curent block
VALID OPTIONS:
	-dt: type of data [-1]
		-1  = ASCII
		0 to 9 = uchar,char,ushort,short,uint,int,ulong,long,float,double
		NOTE: if data is not ASCII, matrix width (-w) must be defined
EXAMPLES:
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixstats1"><a href="#CODE">&#8679</a> xe-matrixstats1</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixstats1 v 1: 19.March.2018 [JRH]
----------------------------------------------------------------------
Analyze content of a single- or multi-matrix ASCII file
USAGE: xe-matrixstats1 [matrix] [options]
	[matrix]: file or "stdin" in (multi)matrix format
		- matrices separated by "# &#60id-number&#62" lines
VALID OPTIONS (defaults in []):
	-idcol: the column on comment-lines holding the ID [1]
	-binsize: 4-item CSV list defining xmin,ymin,xmax,ymax [unset]
EXAMPLES:
	xe-matrixstats1 matrix.txt -thresh 1 -first 0 &#62 matrix2.txt ; } 2&#62 report.txt 
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-matrixsub1"><a href="#CODE">&#8679</a> xe-matrixsub1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-matrixsub1 v 6: 28.November.2012 [JRH]
----------------------------------------------------------------------
Subtract the values in one matrix from those in another
Rows in a given matrix may have different number of columns
But both matrices must be similar in format:
	- the first matrix is taken as the reference for formatting
	- any difference in the number of lines in a matrix results in an error
	- if a row has more data than it should, the extras are dropped
	- if a row has fewer data than it should, NANs are inserted
Non-numbers in either matrix will result in NAN in output matrix
USAGE:	xe-matrixsub1 [in1] [in2]
		[in1] matrix of interest
		[in2] reference matrix from which [in1] is subtracted
VALID OPTIONS:
EXAMPLES:
	xe-matrixsub1 matrix1.txt matrix2.txt
OUTPUT:
	A difference matrix matching the original matrix format
	[in2] minus [in1]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-mxcor2"><a href="#CODE">&#8679</a> xe-mxcor2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
********************************************************************
xe-mxcor2 v 2.1: 7.February.2019 [JRH]
Calculate spatial correlation between pairs of matrix-format rate maps
Reads one CRUNCH matrix output file containing multiple matrices
Requires either cell-ids for a pair to analyze, or a pair-list file
Outputs the spatial correlation for every cell pair specified
USAGE: xe-mxcor2 [matrixfile] [arguments]
- valid arguments: 
	-c1: cell 1 of a pair [1]
	-c2: cell 2 of a pair [1]
	-cf: file listing cell pairs
		NOTE: this overrides -c1 and -c2
Examples:
	xe-mxcor2 crunch_matrix.txt -c1 12 -c2 13
	xe-mxcor2 crunch_matrix.txt -cf cellpairs.txt

</blockquote></pre>

<font color="Black"><h3 id="code-xe-nlx2bin"><a href="#CODE">&#8679</a> xe-nlx2bin</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-neuralynx">neuralynx</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-nlx2bin v 1: 11.November.2019 [JRH]
----------------------------------------------------------------------
Convert a Neuralynx CSC (.ncs) file to a flat-binary .bin file (float)
USAGE: xe-nlx2bin [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-dt: type of data to write [-1]
		-1: ASCII
		0: unsigned char
		1: signed char
		2: unsigned short
		3: signed short
		4: unsigned int
		5: signed int
		6: unsigned long
		7: signed long
		8: float
		9: double
	-scale: scaling factor to apply to data (eg -1 to invert) [1]
	-verb: verbose output (0=NO 1=YES) [0]
EXAMPLES:
	xe-nlx2bin data.txt -t 1
	cat temp.txt | xe-nlx2bin stdin -t 3
OUTPUT:
	
	
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-norm2"><a href="#CODE">&#8679</a> xe-norm2</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-norm2 v 11: 14.January.2019 [JRH]
Normalize or transform data in a specified column
Other columns and comment lines and will be output unaltered
Maxmimum line length = 1000 characters
Non-numbers in the column will be output unaltered but do not affect calculations
Values matching the invalid value will also be output as "-"
If input is piped to the program, input is sent to a temporary file
This allows reconstruction of the input, normalizing only the column of interest
USAGE:
 	xe-norm2 [input] [options]
REQUIED ARGUMENTS:
	[input]: a filename or "stdin"
VALID OPTIONS:
	-cy column containing data [1]
	-p output decimal precision (-1=auto (%f), 0=auto (%g), &#620=precision) [-1]
	-n normalization type: [1]
		-1: no normalization 
		 0: 0-1 range
		 1: z-scores (uses start/stop)
		 2: difference from first valid sample (uses start)
		 3: difference from mean (uses start/stop) 
		 4: ratio of mean (uses start/stop)
		 5: apply Fisher transform for Pearson's "r"
		 6: apply reverse Fisher transform for Pearson's "r"
		 7: log-transform input (log base-10)
	-start: start of normalization range (-n options 1-4) [-1]
	-stop:  end of normalization range (-n options 1-4) [-1]
		NOTE: stop = sample just AFTER the last to be included
		-1 = auto (first valid sample, respectively
			= first valid sample for start
			= last valid sample +1 for stop
	-invalid value to be ignored (unset by default)
	-sub define value to subtract from each datum (unset by default)
	-div define value to divide each datum by (unset by default)
		NOTE: setting -sub or -div overrides -n option
		NOTE: if only -sub was set, -div=1
		NOTE: if only -div was set, -sub=0
To preserve input/output line count, remove comments & blank lines first
Invalid values and non-normal numbers (NaN, Inf) will be padded with "-"
Examples:
	cat infile.txt | xe-norm2 stdin -cy 2 -n 1
	xe-norm2 infile.txt -n 0 -cy 2 -invalid 999
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-norm3"><a href="#CODE">&#8679</a> xe-norm3</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-norm3 v 1: 19.April.2019 [JRH]
----------------------------------------------------------------------
Normalise repeated-measures data, preserving grouping identifiers
- typically used to normalize subject x group x time data
- works on 4 input columns:
- 	id1: identifier (integer, typically subject)
- 	id2: identifier (integer, typically group)
- 	rep: repeated-measure (float, typically time)
- 	val: value to be normalized (float)
NOTE! assumes data are sorted by id1,id2 and rep (see below)
USAGE: xe-norm3 [in] [options]
	[in]: input file name or "stdin"
VALID OPTIONS: defaults in []
	-head: non-comment lines at top of file to pass unaltered [0]
	-id1: col-no. for id#1 (integer), e.g. subject [1]
	-id2: col-no. for id#2 (integer), e.g. group [1]
	-rep: col-no. for repeated category (float), e.g. time [3]
	-val: col-no. for values (float) [4]
	-norm: normalization type: [3]
		-1: no normalization 
		 0: 0-1 range
		 1: z-scores (see -n1/-n2)
		 2: difference from first valid sample (see -n1)
		 3: difference from mean (see -n1/-n2) 
		 4: ratio of mean (see -n1/-n2)
	-n1: beginning of normalization zone (units) [0]
	-n2: end of normalization zone (units) [1]
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-norm3 data.txt -t 1
	cat temp.txt | xe-norm3 stdin -t 3
OUTPUT:
	1st column: lower limit of each bin
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-normrow2"><a href="#CODE">&#8679</a> xe-normrow2</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-normrow2 7.April.2019 [JRH]
----------------------------------------------------------------------
Normalize data within each row of input
 - non-numeric and non-finite values will be ignored
 - accepted input delimiters: space,tab,comma
 - output will be tab-delimited
USAGE: xe-normrow2 [infile|stdin] [options]
VALID OPTIONS:
	-head: non-comment lines at top of file to pass unaltered [0]
	-skip: number of columns to skip (preserve) [0]
	-norm: normalization type: [1]
		-1: no normalization 
		 0: 0-1 range
		 1: z-scores (see start/stop)
		 2: difference from first valid sample (see start)
		 3: difference from mean (see start/stop) 
		 4: ratio of mean (see start/stop)
	-start: start of normalization range (-1= first valid) [0]
	-stop:  end of normalization range (-1= last valid) [-1]
		NOTE: start/stop are samples-after-skip
		NOTE: stop = sample just AFTER the last to be included
EXAMPLES:
	cat infile.txt | xe-normrow2 stdin -n 1
	xe-normrow2 infile.txt -n 0 -invalid -1
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-O2-readchart2"><a href="#CODE">&#8679</a> xe-O2-readchart2</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-O2">O2</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-O2-readchart2 v 3: 19.October.2015 [JRH]
--------------------------------------------------------------------------------
Read biosensing data output from Chart program
Calculates sample frequency based on median sample-interval
Will handle comments and channel names with spaces
Corrects time-stamp irregularities from stopping and re-starting recording
	- timestamps may temporarily jump backwards (jumpback)
	- timestamp interval may exceed median interval (delays)
Automatically detemines number of channels from file header
Channel-numbers assigned according to column-order (001,002,003 etc.)
Assumptions:
	- input header specifies ChannelTitle for each column
	- input format: time&#60tab&#62ch1&#60tab&#62ch2...&#60tab&#62allcomments
	- multiple comments separated by " #" may be in the last field
		- example multi-comment for channels 1,5 and 9 (single timestamp): 
		#1 1_TASK ON #5 2_TASK ON #9 3_TASK ON 

USAGE:
	xe-O2-readchart2 [input][options]
	[input]: file name (CHART txt export file with header)

VALID OPTIONS (defaults in []):
	-ch: channel number (1-16) to be extratced [1]
	-chname: name of channel to extract, overrides -ch []
	-time: output time records? (0=no, 1=yes) [1]
	-tx: correct timestamps? (0=no, 1=jumpbacks, 2=jumpbacks + delays) [2]
	-int: interpolate non-finite values? (0=no, 1=yes) [0]
	-mcmt: detect manual comments applied to all channels (0=no, 1=yes) [1]
		- these comments will begin with #*

EXAMPLES:
	xe-O2-readchart2 001-004-991231.txt -ch 5

OUTPUT:
	temp_xe-O2-readchart2.time : timestamps 
	temp_xe-O2-readchart2.dat : data samples for specified channel
	temp_xe-O2-readchart2.cmt : times & comments for specified channel
--------------------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-O2-readmed1"><a href="#CODE">&#8679</a> xe-O2-readmed1</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-O2-readmed1 v 1: 5.February.2014 [JRH]
----------------------------------------------------------------------
Convert a Med-Associates file for amperometry data
- read subject/date/group/experiment information
- output a single data block of particular element numbers
- define labels for chosen elements
Assumes:
	- input is white-space delimited
	- multiple consecutive delimiters are treated as one
	- leading blank-spaces distinguish section labels from data
	- input has sections for trial data trial-type definition
	- data section has multiple fixed-length blocks of trials

USAGE:
	xe-O2-readmed1 [input] [section] [elements] [labels] [options]
	[input]: Med-Associates input file (.txt) or "stdin"
	[section]: section containing data
	[elements]: comma-separated list of elements in [section] to output
	[labels]: comma-separated list of labels for [elements]

VALID OPTIONS (defaults in []):
	-r : output on a single row (0=NO, 1=YES)[0]

EXAMPLES:
	xe-O2-readmed1 data.txt   A:  3,5  ntrials,nhead

OUTPUT: [experiment] [subject] [date] [group] [data]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-O2-readmed2"><a href="#CODE">&#8679</a> xe-O2-readmed2</h3></font>
[<a href="#tag-O2">O2</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-O2-readmed2 v 4: 12.June.2018 [JRH]
----------------------------------------------------------------------
Convert a Med-Associates file for amperometry data
Assumes:
	- input is white-space delimited file
	- multiple consecutive delimiters are treated as one
	- leading blank-spaces distinguish section labels from data
	- input has sections for trial data trial-type definition
	- data section has multiple fixed-length blocks of trials
	- trials-per-block is defined in the trial-definition section
		NOTE: trial definition section known to have one extra entry
		NOTE: this extra should always be trial-type zero

USAGE:
	xe-O2-readmed2 [input] [options]
	[input]: Med-Associates input file (.txt) or "stdin"

VALID OPTIONS (defaults in []):
	-h : number of header entries in data-section to ignore [11]
	-s1 : data section [C:]
	-s2 : trial-definition section [Z:]
	-r : treat data-blocks as repeated measures (output in separate columns [0]

EXAMPLES:
	xe-O2-readmed2 data.txt -s1 "C:" -s2 "Z:" 
	cat temp.txt | xe-O2-readmed2 stdin -s1 "C:" -s2 "Z:"

OUTPUT: [block]	[trial] [trialtype] [data]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-oversample1"><a href="#CODE">&#8679</a> xe-oversample1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-oversample1 v 1: 17.March.2019 [JRH]
----------------------------------------------------------------------
Resample an input, adding points and smoothing (Butterworth filter)
- assumes one valid numeric value per input line
- non-numeric values will be interpolated
USAGE: xe-oversample1 [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-sr: sample-rate (Hz) of input [1000]
	-mul: multiplier for sample-rate [4]
	-low: low-cut filter (Hz, 0=NONE) [0]
	-high: high-cut filter (Hz, -1=AUTO, 0=NONE) [-1]
		AUTO= sr/2
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-oversample1 data.txt -sr 1000 -mul 4 -low 10 1
	cat temp.txt | xe-oversample1 stdin -sr 1000 -mul 2
OUTPUT:
	higher-resolution, filtered values
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-pac2"><a href="#CODE">&#8679</a> xe-pac2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-pac2 v 2: 2.March.2018 [JRH]
--------------------------------------------------------------------------------
Calculate coherence between two signals using FFT (Kiss-FFT)
Assumes data consists of real values only
FFT is performed on overlapping windows in which data is de-meaned and tapered
USAGE:	xe-pac2 [inA] [inB] [options] 
	[inA]: file containing the low, modulating frequency
	[inB]: file containing the high, modulated frequency (can be inA)
VALID OPTIONS (defaults in [])
	-dt: data type (-1=ASCII, 0-9=BINARY) [-1]
		* dt -1: input is assumed to be 1 column
		* dt 0-9: uchar,char,ushort,short,uint,int,ulong,long,float,or double
	-sf: sampling frequency of the input, in Hz [1]
	-min1: bottom of low freq. range [-1 = default= 800/datalength]
	-max1: top of low freq. range [-1 = default= sr/2]
	-min2: bottom of high-freq range [-1=default = min1]
	-max2: top of high-freq range [-1=default = min1]
	-res: Butterworth filter resonance (0.1 to sqrt(2)=1.4142) [0.5]
		NOTE: low values = sharper cutoff but produces ringing
		NOTE: high values = gentle rolloff and dampened signal
	-Ft: FIR filter number of taps [101]
	-Fw: FIR filter bandwidth [3]
	-Fb: FIR filter beta (edge bandwidth 0-10, lower=sharper but more ringing) [10]
	-Fs: FIR corection for phase-shift (0=NO 1=YES) [1]
	-Fy: FIR window type (none,kaiser,sync) [kaiser]
	-f: file containing start-samples for windows
		* this will override the -s option
		* if unset, windows are automatically defined to span the data 
	-w: length of data windows passed to FFT function) (0 = auto) [0]
		* must be an even number, not necessarily a power of two
		* by default, auto = 2*(sr/min)
		* larger window = more detailed output but lower temporal resolution
		* frequency resolution = sample_frequency / buffer_size
	-s: number of steps for the sliding window to span one buffer length [0]
		* e.g. if -b 8 -s 2, the buffer moves by 8/2=4 samples per FFT
		* note: more steps = more data overlap (artificially high coherence)
	-t: tapering, 0=NO, 1=YES (Hann taper) [0]
		* note: tapering inflates coherence (same taper applied to both inputs)
	-p: power calculation method (0=Goertzel, 1=Butterworth+RMS, 2=FIR+RMS) [1]
	-m: multiplier for high-freq. energy vector window (wavelengths) [7]
	-a: windows accumulated before calculating coherence (0 = auto) [0]
		* note: if not 0, must be at least 2
		* note: if -o 0 (avg.spectrum), auto value is "all windows"
		* note: if -o 1 or 2, auto value is smallest of 8 or "all windows"
	-adj: adjust coherence to correct for accumulation (0=NO 1=YES) [0]
	-o: output style (0,1, or 2) [0]
		* 0=average spectrum, 1=time_v_freq matrix, 2=list of columns
		* note: if set to 1, each line is the coherence for two buffers
	-g: apply Gaussian smoothing to output (avg.spectrum only) (0= none) [0]
		* note: -g must be 0 or an odd number 3 or larger)
		: low values vive sharper cutoffs
	-v: set verbocity of output to quiet (0) or report (1) [0]
EXAMPLES: xe-pac2 [input] [options] 
	xe-pac2 data.txt -sf 24000 
	cat data.bin | xe-pac2 stdin -sf 1000 -s 8
OUTPUT: 
	if -out 0:  &#60frequency&#62 &#60coherence&#62
	if -out 1:  matrix of coherence values, row=buffer (time), column=frequency
	if -out 2:  &#60time1&#62 &#60time2&#62 &#60frequency&#62 &#60coherence&#62
		&#60time1&#62 and &#60time2&#62 bound the window in which coherence is calculated

</blockquote></pre>

<font color="Black"><h3 id="code-xe-pad1"><a href="#CODE">&#8679</a> xe-pad1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-pad1 v 8: 7.May.2016 [JRH]
----------------------------------------------------------------------
Pad a series of numbers with extra values at the start, end, or both
Useful for avoiding edge-effects with filtering, but trim data afterwards
Non-numeric values will be assigned to NaN
USAGE:
	xe-pad1 [input] [options]
	[input]: file name or "stdin" - single column of data
VALID OPTIONS (deafulats in []):
	-n(umber) of padded values to add [5]
	-t(ype) of padding: 1(beginning) 2(end) or 3(both) [1]
	-e(dge) treatment: [1]
		0: zeros
		1: trend to zero rate-of-change
		2: reverse-copy, cosine-trended to zero
		3: mean of first and/or last n-values
		4: sample-and-hold first and/or last value
EXAMPLES:
	xe-pad1 data.txt -n 5 -t 1
	cat temp.txt | xe-pad1 stdin -t 2 -n 25
OUTPUT:
	Padded data in a single column
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-plotmatrix1"><a href="#CODE">&#8679</a> xe-plotmatrix1</h3></font>
[<a href="#tag-plot">plot</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-plotmatrix1 v 23: 1.January.2019 [JRH]
----------------------------------------------------------------------
Produces a postscript "heat-map" plot of a matrix of data
If some rows of input have fewer values, the blocks on that row will 
	be stretched to span the entire matrix
Non-numeric values will result in a blank (white) square in the plot
USAGE:
	xe-plotmatrix1 [filename] [options]

VALID OPTIONS (default in [])...
	[filename]: file name or "stdin"
	-bw: block-width fixed (0) or adaptive (1) [1]
		0 reduces file-size, 1 stretches blocks to fill rows
	-cp: colour palette (0=grey/black, 1=blue/cyan/yellow/red) [1]
		0=grey/black, white=minimum value, red=NAN
		1=blue/cyan/green/yellow/red, black=minimum value, white=NAN
	-cn: number of colours to use [99]
	-bg: NAN/INF background for colour plots [-1]
		0-1 (0=black, 1=white) or -1 (none)
	-xlabel, -ylabel: axis labels (1 word, use "_" for spaces)
	-title: plot title (enclose in quotes)
	-xscale, yscale: scale plot in x [0.3] and y [0.3] dimensions
	-zmin -zmax: colour-range (non-numeric=auto) [nan,nan]
	-zmid: set value for middle colour (non-numeric=auto) [nan]
		- attempts to equalize range around mid-point
		- may override zmin,zmax or both
	-zclip: ccompress (0) or clip (1) out-of-range values [0]
	-xmin -xmax -ymin -ymax: manually set data range
	-xstep -ystep: set interval between matrix values [nan,nan]
		- an alternative methods for data range-setting
		- if "nan", uses -x/ymin and -x/ymax instead
		- NOTE: works with -x/ymin, but overrides -x/ymax
	-xpad -ypad: pad between data range and plot axes
	-xint -yint: tic-intervals for x [0] and y [0] axes (0=AUTO -1=OMIT)
	-yflip: flip matrix on y-axis (0=NO, 1=YES) [0]
	-font: base font size [10]
	-frame: draw frame at bottom(1) left(2) top(4) right(8) [15]
	-tics: size of x- and y-tics (negative=outside frame) [-3]
	-hline: CSV list of positions for horizontal dashed lines [unset]
	-vline: CSV list of positions for vertical dashed lines [unset]
	-uc: user-line colour (0 to -cn, or -1 =white|yellow ) [-1]
	-us: user-line style (0=dashed, 1=solid) [0]
	-lwd: line width for data [1]
	-zx, -zy: page offset of the plot (-1 = default A4 top-left) [-1,-1]
	-out: output file name [temp_xe-plotmatrix1.ps]
EXAMPLES:
OUTPUT: postscript file
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-plotmerge1"><a href="#CODE">&#8679</a> xe-plotmerge1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-plotmerge1 v 1.6: 29.September.2017 [JRH]
----------------------------------------------------------------------
Merge postscript plot files created by _xe-plottable1
USAGE:
	xe-plotmerge1 [options] [file list]
	[file list]: list of file names to merge
	NOTE: Any option not beginning with a "-" is treated as a file-name
VALID OPTIONS:
	-notrans : remove tranlation from within merged files(0=NO 1=YES) [1] 
	-xo, -yo : x and y origin (top left of page) [60, 655] 
	-xinc, yinc : x and y pixel shifts between plots [140, 200] 
	-xmax, ymax : number of plts across and down a page [4, 5] 
	-scale : set the scale of the combined plot [1] 
	-out : define the output filebase-name [temp_xe-plotmerge1] 
		NOTE: the number before the .ps is the page-number
EXAMPLES:
	xe-plotmerge1 a.ps b.ps c.ps -scale 0.5 -xmax 6 -yo 1200
	xe-plotmerge1 -scale 0.5 -xmax 6 -yo 1200 *.ps
OUTPUT:
	- one or more plot files named temp_xe-plotmerge1.[page].ps
	- e.g. temp_xe-plotmerge1.001.ps
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-plotmerge2"><a href="#CODE">&#8679</a> xe-plotmerge2</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-plotmerge2 v 1: 20.March.2019 [JRH]
----------------------------------------------------------------------
Merge postscript files into a single multi-page document
USAGE:
	xe-plotmerge2 [file list]
	[file list]: list of file names to merge
EXAMPLES:
	xe-plotmerge2 a.ps b.ps c.ps 
OUTPUT:
	A single multi-paged postscript document, sent to stdout
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-plottable1"><a href="#CODE">&#8679</a> xe-plottable1</h3></font>
[<a href="#tag-plot">plot</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-plottable1 v 75: 1.January.2019 [JRH]
----------------------------------------------------------------------
Produces a postscript plot of data
Non-numeric values will be ignored
USAGE...
	xe-plottable1 [filename] [options]

VALID OPTIONS (default in [])...
	[filename]: file name or "stdin"
	-cx: x-data column (-1 to infer x from sample-number) [1]
	-cy: y-data column [2]
	-ce: y-error estimate column [-1]
	-cf: x-error estimate column [-1]
	-cg: group ID column [-1]
		- can be numerical or text (no spaces)32
		- if text, group-colour assigned by order of appearance
	-xmin -xmax -ymin -ymax: manually set data range
	-xpad -ypad: pad between data range and plot axes (-1=auto)
	-xint -yint: interval between axis-tics (0=AUTO -1=OMIT) [0 0]
	-jitter: apply this much jitter (max) to x-values [0]
		NOTE: do not use with -line option
	-line: draw line between data points (1=YES,0=NO)[0]
	-pt: plot type (squ cir tri box bar histo) [cir]
	-ps: point size (zero to omit) [5]
	-pf: point fill (0=no, -1=white, 1=datacolour) [1]
	-colour: colour for lowest group (-1 to 32) [0]
	-ebright: adjust error-bar colours up (typically 8,16,24) [0]
	-bw: box/bar width, as a fraction of xint (above) [0.75]
	-ew: error-bar width, fraction of xint (above) [0.375]
	-bz: boxes and histograms extend to zero? (1=YES,0=NO)[1]
	-gs: group-shift on x-axis (1=YES,0=NO) [0]
		NOTE: suitable for box bar or histo plots only
		NOTE: puts groups side by side centred on x-value
		NOTE: set -bw to 1/(#groups+1) for this to look nice
	-xlabel: x-axis label, in quotes [unset]
	-ylabel: y-ayis label, in quotes [unset]
	-title: plot title (enclose in quotes)
	-legend: display legend (0=NO, 1=bottom-left, 2=top-right)[0]
	-frame: draw frame at bottom(1) left(2) top(4) right(8) [3]
		-NOTE: these are additive, eg full box=15 [3]
	-tics: size of x- and y-tics (negative=outside frame) [-3]
	-hline: CSV list of y-values for horizontal lines [unset]
	-vline: CSV list of x-values for vertical lines [unset]
		NOTE: maximum 256 lines of each type
		NOTE: if &#62 data range, plot range will be expanded
	-yzero: draw zero-line if y-data spans zero (0=NO 1=YES) [1]
	-xscale: scale plot in x dimension [0.3] 
	-yscale: scale plot in y dimension [0.3] 
	-font: base font size [10]
	-lwd: line width for data [1]
	-lwe: line width for error-bars [0.75]
	-lwa: line width for axes [1]
	-lb: break lines in plot [0]
		(0) no line-breaks in plot
		(1) if there is missing data or blank lines
		(2) if a time-series repeats (x[ii]&#60x[i-1]) 
	-zx, -zy: page offset of the plot [-1,-1]
		NOTE: -1 = default A4 top-left
	-out: output file name [temp_xe-plottable1.ps]
	-verb: verbose output (0=NO, 1=YES) [0]
EXAMPLES:
	xe-plottable1 data.txt -cx 2 -cy 3 -line 1 -title "Sample-1"
OUTPUT:
	- postscript file, default name "temp_xe-plottable1.ps"
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-posstats1"><a href="#CODE">&#8679</a> xe-posstats1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-posstats1 v 3: 8.February.2015 [JRH]
----------------------------------------------------------------------
Analyze a position record
USAGE:
	xe-posstats1 [input] [options]
	[input]: file name or "stdin" in format &#60xpos&#62 &#60ypos&#62
VALID OPTIONS:
	-sf: sample frequency of input [1]
	-w: window size (sec) for integrating movement [0.4]
	-v: minimum velocity (cm/s) for calculating ang.velocity [1.00]
	-g1: Gaussian smoothing window (sec) for position [0]
		- applied before calculating velocity, angles and ang.velocity
	-g2: Gaussian smoothing window (sec) for angles [0]
		- applied before calculating ang.velocity
EXAMPLES:
	xe-posstats1 data.txt -t 1
	cat temp.txt | xe-posstats1 stdin -t 3
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-progdep"><a href="#CODE">&#8679</a> xe-progdep</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-progdep v 5: 26.January.2018 [JRH]
----------------------------------------------------------------------
Check dependencies in a script or program
Looks for any mention of a word containing xs-, xe-, or xf_ 
	- allows definition of dependency (e.g. prog=[progname) to be 
	detected, PROVIDED quotes are not used
	- any other reference to a script/prog/function may be falsely 
	detected, if NOT enclosed in quotes
Ignores additional references to the same script/program/function
Ignores comments:
	- all text between /* and */ 
	- everything after the first # or // on a given line
Ignores quoted text (between single or double-quotes)
Word delimiters: |(){}; "'\t\n
USAGE:
	xe-progdep [file-name]
EXAMPLES:
	xe-progdep xs-myscript
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-random1"><a href="#CODE">&#8679</a> xe-random1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-random1 v 5: 1.December.2015
----------------------------------------------------------------------
Produce a series of random integers from [min] to [max]
USAGE:
	xe-random1 [n] [optional arguments]
		[n]: number of random integers to generate
OPTIONAL ARGUMENTS:
	-g: uniform (0) or Gaussian (1) distribution [1]
    if uniform:
	-min: lowest number [0]
	-max: highest number [1]
    if Gaussian, mean is zero:
	-sd: standard deviation of distribution [1]
EXAMPLES:
	xe-random1 60
	xe-random1 25 -min -10 -max 10 -r 2
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-readbinary1"><a href="#CODE">&#8679</a> xe-readbinary1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-readbinary1 v 8: 13.May.2016 [JRH]
----------------------------------------------------------------------
Extract values from a simple binary file
Assumes data (numbers) are all of the same type
Allows for presence of a single header
Allows extraction of a chunk starting at a particular element

USAGE:
	xe-readbinary1 [input] [options]
	[input]: file name

VALID OPTIONS, defaults in []:
	-dt: type of data [0]
		0: unsigned char
		1: signed char
		2: unsigned short
		3: signed short
		4: unsigned int
		5: signed int
		6: unsigned long
		7: signed long
		8: float
		9: double
	-h: size of header (bytes) excluded from output [0]
	-s: start reading at this element (zero-offset) [0]
	-n: number of elements to read (0=all) [0]
		NOTE: -s and -n will be internally converted to bytes
		NOTE: if -n is zero, reads from start to the end
	-v set verbose mode (0=data only, 1=stderr-report, 2=logfile) [0]

EXAMPLES:
	xe-readbinary1 data.txt -h 500 -s 0 -n 1000 
	cat temp.txt | xe-readbinary1 stdin 

OUTPUT:
	ASCII numbers representing the data
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-readbinary2"><a href="#CODE">&#8679</a> xe-readbinary2</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-readbinary2 v 6: 12.October.2014 [JRH]
----------------------------------------------------------------------
Extract values from a binary file - ASCII output to screen
This version assumes data are short-integers (2 bytes)
USAGE:
	xe-readbinary2 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-ch: comma-separated channels to extract (zero to (nch-1), or "all")
	-nch: total number of channels[1]
	-s: start reading at this element (zero-offset) [0]
	-n: number of elements to read (0=all) [0]
	-sf: sample frequency (Hz): if +ive, times are output [0]
		NOTE: -s and -n will be internally converted to bytes
	-b: size of multi-channel data-blocks to read at a time [1000]
	-asc: ASCII output, 1=ASCII, 0=binary (short int) [1]
		NOTE: time output is not possible with binary
EXAMPLES:
	xe-readbinary2 data.txt -nch 64 -ch 0,1,2
	cat temp.txt | xe-readbinary2 stdin -nch 64 -ch 62,63
OUTPUT:
	time (if -sf&#620) and data for selected channel
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-readbinary3"><a href="#CODE">&#8679</a> xe-readbinary3</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-readbinary3 v 1: 16.September.2015 [JRH]
----------------------------------------------------------------------
Extract values from a simple binary file
Assumes data (numbers) are all of the same type
Allows for presence of a single header
Allows extraction of a chunk starting at a particular element
Data is processed in chunks: reduced memory load but reduced speed

USAGE:
	xe-readbinary3 [input] [options]
	[input]: file name

VALID OPTIONS, defaults in []:
	-dt: data type [0]
		0: unsigned char
		1: signed char
		2: unsigned short
		3: signed short
		4: unsigned int
		5: signed int
		6: unsigned long
		7: signed long
		8: float
		9: double
	-out: set output type, -1 (ASCII) or 3,5,7,8,9 as above [-1]
	-b: data block size (numbers to read at a time) [1000]
	-h: size of header (bytes) excluded from output [0]
	-s: start reading at this element (zero-offset) [0]
	-n: number of elements to read (0=all) [0]
		NOTE: -s and -n will be internally converted to bytes
	-v set verbose mode (0=data only, 1=stderr-report, 2=logfile) [0]

EXAMPLES:
	xe-readbinary3 data.txt -h 500 -s 0 -n 1000 
	cat temp.txt | xe-readbinary3 stdin 

OUTPUT:
	ASCII numbers representing the data
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-readscore1"><a href="#CODE">&#8679</a> xe-readscore1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-readscore1 v 9: 22.February.2016 [JRH]
----------------------------------------------------------------------
Read a SCORE raw file and output as ASCII or binary stream
Input assumed to be unsigned 8bit ints (1 byte characters)
Non-numeric values will be recoded "NaN"
USAGE:
	xe-readscore1 [input] [options]
	[input]: SCORE raw-file name or "stdin"
		NOTE: data assumed to be "unsigned char" (8-bit int)
VALID OPTIONS:
	-sf: sampling frequency (Hz) [400]
	-dur: duration (s) of each record [10]
	-head: size of record headers (bytes) [35]
	-start: record or time to start output at [0]
		two modes: record-number (integer &#62= zero) or time
		time must be in the format YY:MM:DD:hh:mm:ss
		NOTE: corrects for SCORE's use of MM:DD:YY format
		NOTE: if exact start-time is not found, there will be no output
	-n: max records to output (0 = all) [0]
	-lf: file listing record-numbers (0-offset) to output [unset]
	-out: output format (0=headers only, 1=ASCII, 2=binary) [1]
		0=headers only
		1=ASCII
		2=binary (unsigned 8-bit integer = unsigned char)
EXAMPLES:
	xe-readscore1 data30686.hpc4 -start 6 -n 1 -out 2 &#62 output.bin
OUTPUT:
	- all output is sent to stdout
	- if -out 0, header for each record + lipping
	- if -out 1, simple ASCII (1-column) data stream
	- if -out 2, binary (unsigned char, = 8bit int) data stream
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-readscore2"><a href="#CODE">&#8679</a> xe-readscore2</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-readscore2 v 5: 20.September.2013 [JRH]
----------------------------------------------------------------------
Read two SCORE raw files, interlace output as ASCII or binary stream
Non-numeric values will be recoded "NaN"
USAGE:
	xe-readscore2 [input1] [input2] [options]
	[input1]: first file name (1 channel of data)
	[input2]: second file (1 channel of data)
		NOTE: input is pre-read to determine size
VALID OPTIONS:
	-asc: ASCII output, 1=YES 0=NO, (USE BINX binary format) [1]
	-start: first block of 10-seconds to output[1]
	-stop: last block of 10-seconds to output (0 = all) [0]
EXAMPLES:
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-repeated1"><a href="#CODE">&#8679</a> xe-repeated1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-repeated1 v 5.May.2019 [JRH]
----------------------------------------------------------------------
Process repeated-measures data in blocks where key-values don't change
- input should be a multi-column table with a header-line
- one column holds the repeated measure (eg time), another the data
- key-columns (eg "subject") define blocks of repeats
- leading blank-lines and comments (#) will be ignored

USAGE: xe-repeated1 [in] [keys] [rep] [dat]   [options]
	[in]: file name or "stdin"
	[keys]: CSV list of column-names for static keys
		- equivalence from line-to-line defines the data block
	[rep]: column-name for repeated-measure variable
	[dat]: column-name for data

OPTIONS (defaults in []):
	-interp: interpolate invalid values (0=NO 1=YES) [0]
	-max: max number of replicates in a block [1000]
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
butterworth filter options:
	-low: low frequency limit, 0=SKIP [0]
	-high: high frequency limit, 0=SKIP [0]
normalization options:
	-norm: normalization type (0=SKIP, see xe-norm3): [-1]
	-n1: normalization zone (rep units) [0]
	-n2: end of normalization zone (rep units) [1]
binning options:
	-bin: time (rep) over which to average data (0=SKIP) [0]

EXAMPLES:
	xe-repeated1 data.txt "subject,group,day  time volts"
OUTPUT:
	columns [key1] [key2]... [rep] [dat]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-rms2"><a href="#CODE">&#8679</a> xe-rms2</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-rms2 v 2: 14.February.2014 [JRH]
----------------------------------------------------------------------
Calculate root mean square (RMS)  power for a data series
- RMS calculated in a sliding window shifted by one sample at a time
- add-one/drop-one method use for efficient calculation
- interpolates across non-numeric values, NAN and INF
- option remove linear trends from data
USAGE:
	xe-rms2 [input] [options]
	[input]: file name or "stdin", single column of numbers
VALID OPTIONS:
	-ws: window size (samples) for RMS calc. (-1 = whole record) [-1]
	-d: detrend - removes linear trends from input (0=NO 1=YES) [0]
	-o: output (0=average RMS, 1=RMS at each sample [0]
	-v: set verbosity (0=RMS only, 1=report) [0]
EXAMPLES:
	xe-rms2 data.txt 
	cat temp.txt | xe-rms2 stdin -ws 100
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-sizes1"><a href="#CODE">&#8679</a> xe-sizes1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-sizes1 v 2: 7.February.2014 [JRH]
----------------------------------------------------------------------
Programming tool: report size of numerical types
----------------------------------------------------------------------
char:		1 bytes	8 bits
short:		2 bytes	16 bits
int:		4 bytes	32 bits
long:		8 bytes	64 bits
long long:	8 bytes	64 bits
size_t:		8 bytes	64 bits
off_t:		8 bytes	64 bits
float:		4 bytes	32 bits
double:		8 bytes	64 bits
long double:	16 bytes	128 bits

max sizes as defined in &#60limits.h&#62 and &#60float.h&#62 headers:
NOTE: all are for unsigned values, except size_t:

char:		-128 to 127
short:		-32768 to 32767
int:		-2147483648 to  2147483647 (2.15 GB)
long:		-9223372036854775808 to 9223372036854775807
long long:	-9223372036854775808 to 9223372036854775807
size_t:		0 to -1
float:		-3.40282e+38 to 3.40282e+38
double: 	-1.79769e+308 to 1.79769e+308
long double:	-1.18973e+4932 to 1.18973e+4932

absolute numerical limits for given byte-sizes:

2^8: 256
2^16: 65536
2^32: 4.29497e+09
2^64: 9.22337e+18 x 2

</blockquote></pre>

<font color="Black"><h3 id="code-xe-smoothbox1"><a href="#CODE">&#8679</a> xe-smoothbox1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-smoothbox1 v 2: 14.December.2013 [JRH]
----------------------------------------------------------------------
Apply boxcar-averaging to data
Sliding window averages values to either side of central data-point
USAGE: xe-smoothbox1 [infile] [s]
	[infile]: data file or stdin
	[s]: samples either side of data to use for averaging [4294967295]
		- total size of averaging window = s+s+1
EXAMPLES:
	xe-smoothbox1 data.txt 5
	cat temp.txt | xe-smoothbox1 stdin
OUTPUT:
	smoothed data - non-numeric values converted to NaN
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-smoothgauss1"><a href="#CODE">&#8679</a> xe-smoothgauss1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-smoothgauss1 v 3: 28.March.2016 [JRH]
----------------------------------------------------------------------

Apply Gaussian smoothing kernel to data
Assumes data has a fixed sample-rate
USAGE: 
	xe-smoothgauss1 [infile][smooth]
	[infile]: data file or stdin
		- non-numeric data is ignored
		- ignores newlines
	[smooth]: size of smoothing window (samples)
		- must be an odd number
		- use "1" for no smoothing
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-spearmans1"><a href="#CODE">&#8679</a> xe-spearmans1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-spearmans1 v 1: 17.July.2018 [JRH]
----------------------------------------------------------------------
Calculate the Spearman's rank-order correlation (rho)
- non-parametric relatoinship between the rankings of two variables
- relationship need not be linear, merely monotonic
- similar to Pearson's r for eliptical distributions
- less sensitive to the influence of outliers
- non-numeric values ignored
USAGE:
	xe-spearmans1 [input] [options]
	[input]: file name or "stdin" with x and y values in columns
VALID OPTIONS: defaults in []
	-cx: column holding x-value (first col = 1) [1]
	-cy: column holding y-value (first col = 1) [2]
	-verb: verbose output (0=NO 1=YES, 999=DEBUG) [0]
EXAMPLES:
	xe-spearmans1 data.txt -cx 2 -cy 3
	cat temp.txt | xe-spearmans1 stdin
OUTPUT:
	rho= [Spearmans rank coefficient]
	n= [number of valid data-pairs]]
	F= [F-statistic] 
	prob= [probability]
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-spectdenoise1"><a href="#CODE">&#8679</a> xe-spectdenoise1</h3></font>
[<a href="#tag-matrix">matrix</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>][<a href="#tag-noise">noise</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-spectdenoise1 v 1: 22.January.2019 [JRH]
----------------------------------------------------------------------
Remove noise from a spectral-matrix (time x freq)
 - noise=  single-timepoint increases that span many frequencies
 - timeseries for each freq. converted to Z-scores for thresholding
 - outputs a modified matrix with noise-timepoints set to NAN
USAGE: xe-spectdenoise1 [in] [options]
	[in]: filename or "stdin", format: column=time row=freq
VALID OPTIONS: defaults in []
	-c: clipping value (de-noising only,-1=noclip) [-1]
	-z: Z-score threshold for noise at each freq (NAN=skip) [1]
	-s: sign of thesholding (-1=NEG,+1=POS,0=BOTH) [0]
	-p: % of freq &#62 z needed to invalidate timepoint [25]
		- e.g. if Z&#621 for 25% of the spectrum at column 123
	-r: 90-deg rotate for analysis (0=NO 1=YES) [0]
		- use for if input column=freq and row=time
		- matrix will be rotated back for output
OUTPUT:
	stdout: matrix with noise timepoints invalidated (NAN)
	stderr: summary
EXAMPLES:
	xe-spectdenoise1 matrix1.txt 2&#62 report.txt 1&#62 matrix2.txt
	cat matrix1.txt | xe-spectdenoise1 stdin -r 1 &#62 matrix2.txt
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-splitfile1"><a href="#CODE">&#8679</a> xe-splitfile1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>
--------------------------------------------------------------------------------
xe-splitfile1 v 2: 28.November.2018 [JRH]
--------------------------------------------------------------------------------
Split a file whenever zero is reached or if there is a time discontinuity
USAGE: 
	xe-splitfile1 [infile][options]
		[infile]: file or stdin with a time column and data column(s)

VALID OPTIONS (defaults in []):
	-t: time column in infile [1]
	-c: criterion for split [-1]
		-1: whenever the timestamp is lower than the previous one
		 0: whenever zero is encountered
		&#620: after this many seconds has elapsed
EXAMPLE:
	xe-splitfile1 a.txt times.txt -t 3 
OUTPUT:
	- a separate file for each block named temp_xe-splitfile1_[block].txt

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statscol1"><a href="#CODE">&#8679</a> xe-statscol1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statscol1 v 3: 1.April.2014 [JRH]
----------------------------------------------------------------------
Calculate statistics on columns of numbers
Non-numeric values will be ignored
USAGE:
	xe-statscol1 [input] [options]
	[input]: file with multiple columns of data"
VALID OPTIONS:
EXAMPLES:
	xe-statscol1 data.txt
	cut -f 1-3 temp.txt | xe-statscol1 stdin
OUTPUT:
	col  n  mean  stdev  sem
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsd1"><a href="#CODE">&#8679</a> xe-statsd1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsd1v 12  14.September.2016 [JRH]
----------------------------------------------------------------------
Calculates summary statistics for an array of double-precision data 
Non-numeric values will be ignored
INPUT: 
	A single stream of data - rows or columns
USAGE:
	xe-statsd1 [filename] [options]
		[filename]: file name or "stdin"
VALID OPTIONS ( defaults in [] ):
	-f format of output: verbose (1) or single-line (0) [1]
	-out specify an output file or "stdout" (screen) [stdout]
	-var variance & mean calculation for large datasets [2]
		1=computational, 2=per-sample with correction
	-per percentile calculation[0]
		0=skip, 1=calculate mdeian and other percentiles
EXAMPLES:
	xe-statsd1 data.txt -var 1
	cat temp.txt | xe-statsd1 stdin 
OUTPUT: Statistics specified by keyword
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsgrp0"><a href="#CODE">&#8679</a> xe-statsgrp0</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsgrp0 v 9: 16.November.2017 [JRH]
----------------------------------------------------------------------
Calculates summary statistics for a data set or grouped data
Grouping variables must be numbers
Non-numeric data, NAN, and INF will be excluded
USAGE: xe-statsgrp0 [filename] [arguments]
	[filename]: file name or "stdin"
	[options]...
		-a: alpha-% level for conf.intervals (1,5,10) [5]
		-cg: column containing numerical grouping values [1]
		-cy: column containing data to be summarized [2]
		-mult: factor by which to multiply grouping values [1]
			NOTE: this allows setting decimal-precision for floating-
			point grouping values, which must be converted to integers.
			The multiplier can also optimize memory usage for when the
			grouping values are evenly-spaced timestamps. In this case,
			set -mult to 1/sample-interval
		-per percentile calculation (0=NO 1=YES) [0]
		-out: specify an output file or "stdout" (screen) [stdout]
		-h: output header labelling columns? (0=NO, 1=YES) [1]
- examples:
	xe-statsgrp0 data.txt 
	cat temp.txt | xe-statsgrp0 stdin -mult 10
- output:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsgrp1"><a href="#CODE">&#8679</a> xe-statsgrp1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsgrp1 v 9: 29.April.2019 [JRH]
----------------------------------------------------------------------
Calculate stats on a data-column using grouping-columns
- input must be tab-delimited
- grouping-variables must be numeric (can be floating-point)
- non-numeric data-values will be ignored for stats calculations

USAGE: xe-statsgrp1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-cg1:  column defining grouping-variable 1  [1]
	-cy:   column containing dependent variable [2]
	-gint: output groups as integers? (0=NO 1=YES) [0]
EXAMPLES:
	xe-statsgrp1 data.txt -cg1 5
	cat temp.txt | xe-statsgrp1 stdin -gint 1
OUTPUT:
	grp1	n	mean	sd	sem	ntot

	NOTE:
		ntot= total datapoints for a given group-combination
		n= valid numbers contributing to statistical result
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsgrp2"><a href="#CODE">&#8679</a> xe-statsgrp2</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsgrp2 v 9: 29.April.2019 [JRH]
----------------------------------------------------------------------
Calculate stats on a data-column using grouping-columns
- input must be tab-delimited
- grouping-variables must be numeric (can be floating-point)
- non-numeric data-values will be ignored for stats calculations

USAGE: xe-statsgrp2 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-cg1:  column defining grouping-variable 1  [1]
	-cg2:  column defining grouping-variable 2  [2]
	-cy:   column containing dependent variable [3]
	-gint: output groups as integers? (0=NO 1=YES) [0]
EXAMPLES:
	xe-statsgrp2 data.txt -cg1 5 -cg2 7
	cat temp.txt | xe-statsgrp2 stdin -gint 1
OUTPUT:
	grp1	grp2	n	mean	sd	sem	ntot

	NOTE:
		ntot= total datapoints for a given group-combination
		n= valid numbers contributing to statistical result
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsgrp3"><a href="#CODE">&#8679</a> xe-statsgrp3</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsgrp3 v 9: 29.April.2019 [JRH]
----------------------------------------------------------------------
Calculate stats on a data-column using grouping-columns
- input must be tab-delimited
- grouping-variables must be numeric (can be floating-point)
- non-numeric data-values will be ignored for stats calculations

USAGE: xe-statsgrp3 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-cg1:  column defining grouping-variable 1  [1]
	-cg2:  column defining grouping-variable 2  [2]
	-cg3:  column defining grouping-variable 3  [3]
	-cy:   column containing dependent variable [4]
	-gint: output groups as integers? (0=NO 1=YES) [0]
EXAMPLES:
	xe-statsgrp3 data.txt -cg1 5 -cg2 7 -cg3 9
	cat temp.txt | xe-statsgrp3 stdin -gint 1
OUTPUT:
	grp1	grp2	grp3	n	mean	sd	sem	ntot

	NOTE:
		ntot= total datapoints for a given group-combination
		n= valid numbers contributing to statistical result
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-statsrow1"><a href="#CODE">&#8679</a> xe-statsrow1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-statsrow1 v 3: 24.November.2018 [JRH]
----------------------------------------------------------------------
Calculate the stats on individual rows of numbers
Non-numeric values will be ignored
USAGE:
	xe-statsrow1 [input]
	[input]: file name or "stdin"
VALID OPTIONS:
	-t(ype) of statistic to output: [3]
		1=counts
		2=sum
		3=mean
		4=standard deviation
		5=maximum value
		6=sample-number corresponding to maximum value
EXAMPLES:
OUTPUT:
	one statistic per row
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-strgroup1"><a href="#CODE">&#8679</a> xe-strgroup1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-strgroup1 v 1: 10.March.2019 [JRH]
----------------------------------------------------------------------
Group items in a list
USAGE: xe-strgroup1 [in1] [options]
	[in1]: file name or "stdin", each input row = list of items
VALID OPTIONS: defaults in []
	-d1: input item-delimiters (multi-char) [, \t]
	-d2: output within-group item-delimiter (single-char) [#]
	-n:  number of items in each group - does not span lines [2]
EXAMPLES:
	echo "1,,3,4,5,6" | xe-strgroup1 stdin -n 2 -d2 "#"
	output:	1#	3#4	5#6OUTPUT:
	- for each input line, tab-delimited groups of [n] items
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-stripcomments"><a href="#CODE">&#8679</a> xe-stripcomments</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-stripcomments v 1: 26.January.2018 [JRH]
----------------------------------------------------------------------
Remove comments from a file: shell, C/C++, or both types
	- all text between /* and */ 
	- everything after the first # or // on a given line
- ignores comment-markers contained within quotes
- a blank line will remain if required, to preserve the linecount
USAGE: xe-stripcomments [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-type: type of comments to remove [1]
		0= none
		1= # (shell single-line)
		2= /* */  or // (C and C++ style block or single-line)
		3= both 1 and 2
EXAMPLES:
	xe-stripcomments xs-myscript
OUTPUT:
	- the original input with comments removed
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-strsub1"><a href="#CODE">&#8679</a> xe-strsub1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-strsub1 v 3: 14.May.2018 [JRH]
----------------------------------------------------------------------
Replace character-strings (find and replace)
- no line-length limit
- newlines automatically signify start of new words
USAGE:
	xe-strsub1 [input] [old] [new]
	[input]: file name or "stdin"
	[old]: string to replace
	[new]: replacement string
VALID OPTIONS:
	-in: subtitution only in lines containing this pattern
	-ex: exclude subtitution in lines containing this pattern
		NOTE: both unset by default (all lines analyzed)
		NOTE: -ex will override -in
EXAMPLES:
	xe-strsub1 sdatafile " " "_"
	cat datafile | xe-strsub1 stdin ABC abc -ex "#"
	head datafile | grep Names | xe-strsub1 stdin Jones Janes
OUTPUT:
	modified lines
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-strsub2"><a href="#CODE">&#8679</a> xe-strsub2</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-strsub2 28.June.2019 [JRH]
----------------------------------------------------------------------
Replace all "words" in an input with something else
- delimiters (tabs and/or spaces) converted to tabs
- no line-length limit
- newlines automatically signify start of new words
USAGE:
	xe-strsub2 [input] [new]
	[input]: file name or "stdin"
	[new]: replacement string
VALID OPTIONS:
	-cols: subtitution only specified column numbers (NULL=all) [(null)]
	-maxcols: set maximum column [32767]
	-in: subtitution only in lines containing this pattern
	-ex: exclude subtitution in lines containing this pattern
		NOTE: default= both unset (all lines analyzed)
		NOTE: -ex will override -in
EXAMPLES:
	xe-strsub2 sdatafile " " "_"
	cat datafile | xe-strsub2 stdin NAN -ex "#" -cols 1,5-9
OUTPUT:
	modified lines, tab-delimited
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-strxmlparse1"><a href="#CODE">&#8679</a> xe-strxmlparse1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-strxmlparse1 v 6: 10.October.2018 [JRH]
----------------------------------------------------------------------
Parse XML input - extracts content between key tags
Assumes values are bounded by &#60[key]&#62 and &#60/[key]&#62
	- example: &#60name&#62John Smith&#60/name&#62
USAGE:
	xe-strxmlparse1 [input] [key] [options]
	[input]: file name or "stdin" containing XML content
	[key]: XML key (or nested list) to extract
		- specify nesting using a CSV list of keys
		- do not include the brackets as these will be added
		- multiple matches allowed
VALID OPTIONS: defaults in []
	-ok: output key tags for matching blocks (0=NO 1=YES) [0]
		- for lowest nest-level only
		- allows output to be further parsed
EXAMPLES:
	xe-strxmlparse1 data.xml group1,name

OUTPUT:
	all content between the each match for each listed key(s)
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-template"><a href="#CODE">&#8679</a> xe-template</h3></font>
[<a href="#tag-programming">programming</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-template v 1: 14.April.2014 [JRH]
----------------------------------------------------------------------
Template program source-code
Assumes one valid numeric value per input line
Non-numeric values will be ignored
USAGE: xe-template [infile] [options]
	[input]: file name or "stdin"
VALID OPTIONS: defaults in []
	-t(ype): 1(counts) 2(range 0-1) or 3(probability)
	-list: comma-separated list of numbers
	-verb: verbose output (0=NO 1=YES 999=DEBUG) [0]
EXAMPLES:
	xe-template data.txt -t 1
	cat temp.txt | xe-template stdin -t 3
OUTPUT:
	1st column: lower limit of each bin
	2nd column: value (eg. counts) in that bin
----------------------------------------------------------------------


*** xe-template [ERROR: this is the error message]

</blockquote></pre>

<font color="Black"><h3 id="code-xe-test1"><a href="#CODE">&#8679</a> xe-test1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-test1 v 1: 26.September.2016 [JRH]
----------------------------------------------------------------------
Perform a test on a pair of values
USAGE:
	xe-test1 [val1] [test] [val2] [options]
	[val1]: value to compare
	[val2]: reference value
	[test]: test to apply
		-eq: equals
		-ne: not-equal
		-lt: less than
		-le: les than or equal to
		-gt: greater than
		-ge: greater than or equal to
VALID OPTIONS: defaults in []
	-long: treat inputs as long-integers (0=NO 1=YES [0])
		- (0) treats input as double-precision float
		- (1) use long-integer math for greater precision
EXAMPLES:
	Test if 1.23 is greater than 4.56:
		xe-test1 123 -gt 456
	Test if 11111 is less than 99999 using long integers:
		xe-test1 11111 -lt 99999 -long 1
OUTPUT:
	1: test is true
	nothing: test is false
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-timeconv1"><a href="#CODE">&#8679</a> xe-timeconv1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-timeconv1 v 2: 21.May.2016 [JRH]
----------------------------------------------------------------------
Convert hh:mm:ss time format to seconds or vice-versa
Assumes one time per input line
Assumes colon is the delimiter if converting to seconds
USAGE:
	xe-timeconv1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-f input format (1= hh:mm:ss, 2= seconds) [1]:
EXAMPLES:
	xe-timeconv1 times.txt
	echo 12:59:59.123 | xe-timeconv1 stdin
OUTPUT:
	one modified time per valid input line
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-timestamp1"><a href="#CODE">&#8679</a> xe-timestamp1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-timestamp1 v 1: 8.March.2016 [JRH]
----------------------------------------------------------------------
Apply time-stamps to each line of a data series
USAGE:
	xe-timestamp1 [input] [options]
	[input]: newline-delimited data file or "stdin"
VALID OPTIONS:
	-dt: type of data  (ascii or binary types) [-1]
		-1= ASCII
		 0-9= uchar,char,ushort,short,uint,int,ulong,long,float,double
	-sf: sampling-frequency (Hz) to emulate [1]
	-si: sampling-interval (seconds) to emulate [unset]
		NOTE: cannot set both -sf and -si
	-o: start-sample offset (seconds) [0]
		e.g. you may want timestamps to begin at -5 seconds
	-p: decimal precision (-1=auto (%f), 0=none(integer), &#620=precision) [-1]
	-r: round down (0) or to the nearest integer (1) [0]
		NOTE: only applies to integer output (-p 0) 
	-head: optional timestamp-header text for files with headers [unset]
		NOTE: only applies to ASCII input (-dt -1)
		NOTE: assumes first line of input is the header
EXAMPLES:
	xe-timestamp1 data.txt -sf 1000 
	cat temp.txt | xe-timestamp1 stdin -sf 24000
OUTPUT:
	1st column: time (seconds)
	2nd column: data
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-timestamp2"><a href="#CODE">&#8679</a> xe-timestamp2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-timestamp2 v 1: 7.September.2015 [JRH]
----------------------------------------------------------------------
Generate time-stamps given a sample-frequency or interval
USAGE:
	xe-timestamp2 [n] [samp]
	[n]: number of values to generate
	[samp]: sample-frequency or interval
VALID OPTIONS:
	-f format (0=sample-frequency, 1=interval) [0]
	-o start-sample offset [0]
	-p decimal precision (-1=auto (%f), 0=none(integer), &#620=precision) [-1]
	-r round down (0) or to the nearest integer (1) [0]
		NOTE: only applies to integer output (-p 0) 
EXAMPLES:
	xe-timestamp2 100 25.0 -f 0 -p 7
	xe-timestamp2 100 0.04 -f 1 -p 0 -r 1 
OUTPUT:
	single column of timestamps
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-transpose1"><a href="#CODE">&#8679</a> xe-transpose1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-transpose1 v 1.2: 11.October.2016 [JRH]
----------------------------------------------------------------------
- Transpose multiple columns into column-number [tab] column-contents
- this program will handle long-line input
USAGE:
	xe-transpose1 [input] [options]
	[input]: file name or "stdin"
VALID OPTIONS:
	-start : first column to transpose
	     NOTE: preceeding columns will be output for every line
	-n: output original column numbers (0=NO 1=YES) [1]
	[-d]: characters to use as column-delimiters
		- unset by default: multiple whitespace treated as one
		- if set, any matching delimiter marks a new column
			- suitable for files with "empty" columns
EXAMPLES:
	xe-transpose1 data.txt 
	cat temp.txt | xe-transpose1 stdin -start 3 -n 0 
OUTPUT (by column):
	non-transposed columns (if -start defined)
	subsequent column numbers ( if -n is set to 1)
	subsequent column contents
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-transpose2"><a href="#CODE">&#8679</a> xe-transpose2</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-transpose2 v 1: 14.August.2012 [JRH]
----------------------------------------------------------------------
- Transpose input to a single row (remove newlines)
- Max input line length = 1000
USAGE:
	xe-transpose2 [input] [options]
	[input]: file name or "stdin" containing newline-separated data
VALID OPTIONS:
EXAMPLES:
	xe-transpose2 data.txt 
	cat temp.txt | xe-transpose2 stdin 
OUTPUT:
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-transpose3"><a href="#CODE">&#8679</a> xe-transpose3</h3></font>
[<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-transpose3 v 2: 9.July.2012 [JRH]
----------------------------------------------------------------------
- Actually de-transpose a column of data into multiple columns
- For 2-column input &#60group&#62&#60datum&#62, output a column for each &#60group&#62
- Assumes data from a given group appears on successive rows (not mixed)
- Max input line length = 1000
NOTE: group numbers are converted to integers
Number of elements in first group is used as the default number
	- if subsequent groups have more elements they will be ignored
	- if subsequent groups have fewer elements the column is paded
Number of elements in first group is used as the default number
USAGE:
	xe-transpose3 [input] [options]
	[input]: file name or "stdin" in format &#60group&#62&#60datum&#62
VALID OPTIONS:
EXAMPLES:
	xe-transpose3 data.txt 
	cat temp.txt | xe-transpose3 stdin 
OUTPUT:
	1st row: integer group numbers as defined in column-1 of input
	subsequent rows: data from each group in a separate column
	...so...
		100	1
		100	2
		100	3
		200	4
		200	5
		200.5	6
		300	7
		300	8
	...becomes...
		100	200	300	

		1	4	7
		2	5	8
		3	6	nan
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-transpose4"><a href="#CODE">&#8679</a> xe-transpose4</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-transpose4 v 8: 4.April.2018 [JRH]
----------------------------------------------------------------------
- Transpose data for mixed-design repeated measures analysis
- Data can be NAN, but grouping variables must be finite numbers
- Max input line length = 1000
USAGE:
	xe-transpose4 [input] [g1] [g2] [g3] [data]
	[input]: file name or "stdin"
VALID OPTIONS:
	-cg1 column defining subject [1]
	-cg2 column defining between-subjects groups  [2]
	-cg3 column defining repeated measure levels  [3]
	-cy column containing dependent variable [4]
	-gint: output groups as integers? (0=NO 1=YES) [0]
NOTE: 
	- if there is no between-subjects grouping column, set -cg2 to 0
	- in this case, all subjects are placed in group "1"
EXAMPLES:
	xe-transpose4 data.txt -cg1 1 -cg2 2 -cg3 3 -cy 7
	cat temp.txt | xe-transpose4 stdin 
OUTPUT:
	subj    grp    r_1    r_2    r_3    r_4    etc...
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-trimoutliers1"><a href="#CODE">&#8679</a> xe-trimoutliers1</h3></font>
[<a href="#tag-filter">filter</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-trimoutliers1 v 2: 14.August.2012 [JRH]
----------------------------------------------------------------------
Trim a data stream to remove outliers
Non-numeric values and NAN/INF are always removed
USAGE: xe-trimoutliers1 [filename] [options]
	[filename]: file name or "stdin"
OPTIONS ( defaults in [] ):
	-l lower percentile cutoff [0]
	-u upper percentile cutoff [100]
EXAMPLES:
	xe-trimoutliers1 data.txt -l 10 -u 90
	cat temp.txt | xe-trimoutliers1 stdin -l 25 -u 75
OUTPUT: trimmed and sorted dataset
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-winsplit1"><a href="#CODE">&#8679</a> xe-winsplit1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-winsplit1 v 1: 24.February.2014 [JRH]
----------------------------------------------------------------------
Split time-windows into smaller chunks
Can accept window start-stop pairs or just start-times if -d is set
Non-numeric values will be ignored
USAGE:
	xe-winsplit1 [input] [options]
	[input]: file name or "stdin"
		* if -d =0, assumed format is [start] [stop] 
		* if -d &#620, assumed format is [start] (only reads first column)
VALID OPTIONS:
	-dt: data type (7=long_integer, 8=double_precision_float) [8]
	-d: original duration of each window (if single-column input) [-1]
	-s: size of chunks to break windows down into [1]
		* best results if split is an integer fraction of the window size
EXAMPLES:
	xe-winsplit1 data.txt -d 100 -s 20
	cat temp.txt | xe-winsplit1 stdin -d -1 -s 1
OUTPUT:
	if -d =0: single column of revised [start] times
	if -d &#620: [start] [stop] pairs
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-wint1"><a href="#CODE">&#8679</a> xe-wint1</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-wint1 v 2: JRH, 10 October 2010
----------------------------------------------------------------------
Calculates intervals between 2 events (g1, g2) in time-windows
Windows can be: 
	- specified in a file (use -wf option)
	- event-centred and of a specified width (use -w option)
If -g1 and -g2 are the same, output is suitable for an autocorellogram
NOTE: event times must be in ascending  order
- USAGE:
	xe-wint1 [input] [optional arguments]
	[input]: file name or "stdin"
		- 2 columns: 1st= time, 2nd= event-id (integer)
- valid optional arguments...
	-g1: class-1 reference event identifier - default=1
	-g2: class-2 event identifier - default=2
	-w: windowsize in seconds - default=1.000000
		- number of windows = number of events in class g1
		- interval range is +- winsize/2, because windows are event-centred
	-wf: name a file listing window start and end times - unset by default
		- number of windows = number of lines in the window file
		- interval range is +- winsize
		NOTE: setting this variable overrides -w
		NOTE: windows must be sequential and non-overlapping
- examples:
	xe-wint1 data.txt -wf list.txt -g1 6 -g2 7 
	cat temp.txt | xe-wint1 stdin -w 0.1 -g1 4 -g2 4 
- output:
	time intervals (s) between events of each group
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xe-writebinary1"><a href="#CODE">&#8679</a> xe-writebinary1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>
----------------------------------------------------------------------
xe-writebinary1 v5: 16.September.2015 [JRH]
----------------------------------------------------------------------
Write an ASCII input to a simple binary file
Input and output will be treated as a single numerical data type
Multi-column input will be converted to a continous output stream
Choose appropriate -dt option to determine binary data type (see below)
Non-numeric data will be saved as 0 if -dt &#608, or NAN if -dt =8 or 9

USAGE:
	xe-writebinary1 [input] [options]
	[input]: ASCII file name or "stdin"

VALID OPTIONS, defaults in []:
	-dt: type of data to write [9]
		0: unsigned char
		1: signed char
		2: unsigned short
		3: signed short
		4: unsigned int
		5: signed int
		6: unsigned long
		7: signed long
		8: float
		9: double
	-v set verbose mode (0=data only, 1=stderr-report, 2=logfile) [0]

EXAMPLES:

OUTPUT:
	Binary stream
----------------------------------------------------------------------

</blockquote></pre>

<font color="Black"><h3 id="code-xf_auc1_d"><a href="#CODE">&#8679</a> xf_auc1_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the area under the curve using the trapezoid method
		- https://en.wikipedia.org/wiki/Integral
		- http://en.wikipedia.org/wiki/Trapezoidal_rule
	- assumes evenly sampled data
	- requires at least two valid points for meaningfull results
	- options:
		[ref] defines magnitude (y) at each point
		0: reference to zero (standard definition of AUC)
		1: reference to a line joining the ends
			- distance from this line instead of original y-value

USES:
	- measuring the effect-size of a drug response
	- measuring power in a region of an FFT spectrogram
	- calculation of population-spike for slice LTP experiments

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *curvey  : input array holding y-values
	long nn         : length of curvex and curvey (number of elements)
	double interval : fixed interval between curvey samples
	int ref         : y-value reference, 0 or 1 (see definition above)
	double *result  : pre-allocated array holding results (must hold 4 elements)
	char *message   : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result[0] = total AUC (positive + negative)
	result[1] = positive AUC
	result[2] = negative AUC


SAMPLE CALL: GET NEGATIVE-ONLY AUC FOR 100 POINTS, REFERENCED TO ZERO
	x= xf_auc1_d(datay,1000,.001,0,result,message)
	if(x!=0) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else auc=result[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_auc1_f"><a href="#CODE">&#8679</a> xf_auc1_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the area under the curve using the trapezoid method
		- https://en.wikipedia.org/wiki/Integral
		- http://en.wikipedia.org/wiki/Trapezoidal_rule
	- assumes unevenly sampled data
	- requires at least two valid points for meaningfull results
	- options:
		[ref] defines magnitude (y) at each point
		0: reference to zero (standard definition of AUC)
		1: reference to a line joining the ends
			- distance from this line instead of original y-value

USES:
	- measuring the effect-size of a drug response
	- measuring power in a region of an FFT spectrogram
	- calculation of population-spike for slice LTP experiments

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *curvey   : input array holding y-values
	long nn         : length of curvex and curvey (number of elements)
	double interval : fixed interval between curvey samples
	int ref         : y-value reference, 0 or 1 (see definition above)
	double *result  : pre-allocated array holding results (must hold 4 elements)
	char *message   : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result[0] = total AUC (positive + negative)
	result[1] = positive AUC
	result[2] = negative AUC


SAMPLE CALL: GET NEGATIVE-ONLY AUC FOR 100 POINTS, REFERENCED TO ZERO
	x= xf_auc1_f(datay,1000,.001,0,result,message)
	if(x!=0) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else auc=result[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_auc2_d"><a href="#CODE">&#8679</a> xf_auc2_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the area under the curve using the trapezoid method
		- https://en.wikipedia.org/wiki/Integral
		- http://en.wikipedia.org/wiki/Trapezoidal_rule
	- requires at least two valid points for meaningfull results
	- suitable for unevenly sampled data
	- options:
		[ref] defines magnitude (y) at each point
		0: reference to zero (standard definition of AUC)
		1: reference to a line joining the ends
			- distance from this line instead of original y-value
USES:
	- measuring the effect-size of a drug response
	- measuring power in a region of an FFT spectrogram
	- calculation of population-spike for slice LTP experiments

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *curvex : input array holding x-values
	double *curvey : input array holding y-values
	long nn        : length of curvex and curvey (number of elements)
	int ref        : y-value reference, 0 or 1 (see definition above)
	double *result : pre-allocated array holding results (must hold 4 elements)
	char *message  : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result[0] = total AUC (positive + negative)
	result[1] = positive AUC
	result[2] = negative AUC


SAMPLE CALL: GET NEGATIVE-ONLY AUC FOR 100 POINTS, REFERENCED TO ZERO
	x= xf_auc2_d(datax,datay,100,0,result,message)
	if(x!=0) fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else auc=result[2];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_auc2_f"><a href="#CODE">&#8679</a> xf_auc2_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the area under the curve using the trapezoid method
		- https://en.wikipedia.org/wiki/Integral
		- http://en.wikipedia.org/wiki/Trapezoidal_rule
	- requires at least two valid points for meaningfull results
	- suitable for unevenly sampled data
	- options:
		[ref] defines magnitude (y) at each point
		0: reference to zero (standard definition of AUC)
		1: reference to a line joining the ends
			- distance from this line instead of original y-value
USES:
	- measuring the effect-size of a drug response
	- measuring power in a region of an FFT spectrogram
	- calculation of population-spike for slice LTP experiments

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *curvex : input array holding x-values
	double *curvey : input array holding y-values
	long nn        : length of curvex and curvey (number of elements)
	int ref        : y-value reference, 0 or 1 (see definition above)
	double *result : pre-allocated array holding results (must hold 4 elements)
	char *message  : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result[0] = total AUC (positive + negative)
	result[1] = positive AUC
	result[2] = negative AUC


SAMPLE CALL: GET NEGATIVE-ONLY AUC FOR 100 POINTS, REFERENCED TO ZERO
	x= xf_auc2_d(datax,datay,100,0,result,message)
	if(x!=0) fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else auc=result[2];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin1a_d"><a href="#CODE">&#8679</a> xf_bin1a_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	- reduce data to a fixed number of averaged bins
	- non-finite values (INF, NAN) do not contribute to the averages
	- allows for different numbers of elements to go into different bins to evenly spread the results (fractional bin-widths)
	- allows definition of a "zero" sample which is guaranteed to be the first sample in the bin corresponding with the new "zero"
	- guarantees no bins will be under-sampled
		- once the bin-size is determined, edge bins will contain between 1x and just-under-2x bindwidth samples

USES:
	Downsampling data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data   : pointer to input array, which will be overwritten
	size_t *setn   : number of elements in data (overwritten - pass as address)
	size_t *setz   : element to treat as "zero" (overwritten - pass as address)
 	size_t setbins : desired length of data after binning (number of bins used for averaging)
	char *maessage : array to hold error message

RETURN VALUE:
	- size of bins used for averaging or 0 on fail
		- setz and setn are also updated
		- can be used to reconstruct timestamps


SAMPLE CALL:
	char message[256];
	double data[19];
	double aa,bb,binsize,sampinterval=1;
	size_t ii,setn=19, setz=6;
	for(ii=0;ii&#60setn;ii++) { data[ii]=(double)ii; printf("%g\n",data[ii]); }
	printf("zero=item number %ld\n",setz);
	printf("\n");

	binsize= xf_bin1a_f(data,&setn,&setz,3,message);
	if(binsize&#600) {fprintf(stderr,"*** %s\n",message); exit(1);}

	aa=(double)(setz)*(-1)*binsize*sampinterval;
	bb=binsize*sampinterval;
	for(ii=0;ii&#60setn;ii++)  { printf("%g\t%f\n",aa,data[ii]);	aa+=bb; }
	printf("new zero=item number %ld\n",setz);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin1a_f"><a href="#CODE">&#8679</a> xf_bin1a_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	- reduce data to a fixed number of averaged bins
	- non-finite values (INF, NAN) do not contribute to the averages
	- allows for different numbers of elements to go into different bins to evenly spread the results (fractional bin-widths)
	- allows definition of a "zero" sample which is guaranteed to be the first sample in the bin corresponding with the new "zero"
	- guarantees no bins will be under-sampled
		- once the bin-size is determined, edge bins will contain between 1x and just-under-2x bindwidth samples

USES:
	Downsampling data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data    : pointer to input array, which will be overwritten
	size_t *setn   : number of elements in data (overwritten - pass as address)
	size_t *setz   : element to treat as "zero" (overwritten - pass as address)
 	size_t setbins : desired length of data after binning (number of bins used for averaging)
	char *maessage : array to hold error message

RETURN VALUE:
	- size of bins used for averaging or 0 on fail
		- setz and setn are also updated
		- can be used to reconstruct timestamps


SAMPLE CALL:
	char message[256];
	float data[19];
	double aa,bb,binsize,sampinterval=1;
	size_t ii,setn=19, setz=6;
	for(ii=0;ii&#60setn;ii++) { data[ii]=(float)ii; printf("%g\n",data[ii]); }
	printf("zero=item number %ld\n",setz);
	printf("\n");

	binsize= xf_bin1a_f(data,&setn,&setz,3,message);
	if(binsize&#600) {fprintf(stderr,"*** %s\n",message); exit(1);}

	aa=(double)(setz)*(-1)*binsize*sampinterval;
	bb=binsize*sampinterval;
	for(ii=0;ii&#60setn;ii++)  { printf("%g\t%f\n",aa,data[ii]);	aa+=bb; }
	printf("new zero=item number %ld\n",setz);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin1b_d"><a href="#CODE">&#8679</a> xf_bin1b_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	- reduce data to averaged bins of a fixed size
	- non-finite values (INF, NAN) do not contribute to the averages
	- allows for different numbers of elements to go into different bins to evenly spread the results (fractional bin-widths)
	- allows definition of a "zero" sample which is guaranteed to be the first sample in the bin corresponding with the new "zero"
	- guarantees no bins will be under-sampled - edge bins will contain between 1x and just-under-2x bindwidth samples

USES:
	Downsampling data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data      : pointer to input array, which will be overwritten
	long *setn        : number of elements in data (overwritten - pass as address)
	long *setz        : element to treat as "zero" (overwritten - pass as address)
 	double setbinsize : desired bin-width (samples - can be a fraction)
	char *message     : array to hold error message

RETURN VALUE:
	- status (0=success, -1=fail)
	- setz and setn are also updated
		- can be used to reconstruct timestamps


SAMPLE CALL:
	char message[256];
	double data[19];
	double aa,bb,nbins,sampinterval=1,setbinsize=3.5;
	long ii,setn=19, setz=6;
	for(ii=0;ii&#60setn;ii++) { data[ii]=(double)ii; printf("%g\n",data[ii]); }
	printf("setz=item number %ld\n",setz);
	printf("\n");

	nbins= xf_bin1b_d(data,&setn,&setz,setbinsize,message);
	if(nbins==0) {fprintf(stderr,"*** %s\n",message); exit(1);}

	aa=(double)(setz)*(-1)*setbinsize*sampinterval;
	bb=setbinsize*sampinterval;
	for(ii=0;ii&#60setn;ii++)  { printf("%g\t%f\n",aa,data[ii]);	aa+=bb; }
	printf("new setz=item number %ld\n",setz);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin1b_f"><a href="#CODE">&#8679</a> xf_bin1b_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	- reduce data to averaged bins of a fixed size
	- non-finite values (INF, NAN) do not contribute to the averages
	- allows for different numbers of elements to go into different bins to evenly spread the results (fractional bin-widths)
	- allows definition of a "zero" sample which is guaranteed to be the first sample in the bin corresponding with the new "zero"
	- guarantees no bins will be under-sampled - edge bins will contain between 1x and just-under-2x bindwidth samples

USES:
	Downsampling data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data       : pointer to input array, which will be overwritten
	long *setn        : number of elements in data (overwritten - pass as address)
	long *setz        : element to treat as "zero" (overwritten - pass as address)
 	double setbinsize : desired bin-width (samples - can be a fraction)
	char *message     : array to hold error message

RETURN VALUE:
	- status (0=success, -1=fail)
	- setz and setn are also updated
		- can be used to reconstruct timestamps


SAMPLE CALL:
	char message[256];
	float data[19];
	double aa,bb,nbins,sampinterval=1,setbinsize=3.5;
	long ii,setn=19, setz=6;
	for(ii=0;ii&#60setn;ii++) { data[ii]=(flaot)ii; printf("%g\n",data[ii]); }
	printf("setz=item number %ld\n",setz);
	printf("\n");

	nbins= xf_bin1b_f(data,&setn,&setz,setbinsize,message);
	if(nbins==0) {fprintf(stderr,"*** %s\n",message); exit(1);}

	aa=(double)(setz)*(-1)*setbinsize*sampinterval;
	bb=setbinsize*sampinterval;
	for(ii=0;ii&#60setn;ii++)  { printf("%g\t%f\n",aa,data[ii]);	aa+=bb; }
	printf("new setz=item number %ld\n",setz);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin1b_s"><a href="#CODE">&#8679</a> xf_bin1b_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	- reduce data to averaged bins of a fixed size
	- non-finite values are impossible for short-integer input
	- allows for different numbers of elements to go into different bins to evenly spread the results (fractional bin-widths)
	- allows definition of a "zero" sample which is guaranteed to be the first sample in the bin corresponding with the new "zero"
	- guarantees no bins will be under-sampled - edge bins will contain between 1x and just-under-2x bindwidth samples

USES:
	Downsampling data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	short *data       : pointer to input array, which will be overwritten
	long *setn        : number of elements in data (overwritten - pass as address)
	long *setz        : element to treat as "zero" (overwritten - pass as address)
 	double setbinsize : desired bin-width (samples - can be a fraction)
	char *message     : array to hold error message

RETURN VALUE:
	- status (0=success, -1=fail)
	- setz and setn are also updated
		- can be used to reconstruct timestamps
</blockquote></pre>

<font color="Black"><h3 id="code-xf_bin2_d"><a href="#CODE">&#8679</a> xf_bin2_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	Averages data in non-overlapping time-windows
	NAN values do not contribute to the sum
	Alters input array, shortening overall length to (n-windows) worth of average values
	Time for each window corresponds with the beginning of each window
	NAN values will be ignored, but INF will affect the results

USES:
DEPENDENCY TREE:
	No dependencies
ARGUMENTS:
RETURN VALUE:
SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_binpeak1_f"><a href="#CODE">&#8679</a> xf_binpeak1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	Bin an array of data using non-overlapping windows, using peak-detection based on xe-bin1.6

	Overwrites the original data
	Ignores NAN or INF values

	NOTE: this function does not have the offset-zero capability of xf_bin1_f,
	      that is, there is no guarantee that any bin will be left-aligned with "zero",
		  unless this corresponds with the first element of the input dataa array

USES:
	Downsample a time-series with peak-detection to avoid losing significant features

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data1   : array holding data values
	long n         : number of elements in the array
	double binsize : size (number of elements) in the binning window - note that this can be fractional

RETURN VALUE:
	new size of binned data array, or -1 on error

SAMPLE CALL:
	n= xf_binpeak1_f(data,n,100,message);
	if(n&#62=0) for(i=0;i&#60n;i++) printf("%g\n",data_f[i]);
	else fprintf(stderr,"%s\n",message);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_binpeak4"><a href="#CODE">&#8679</a> xf_binpeak4</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	Bin an array of ydata, and output the max deviations in each bin (window)
		- NAN values will tend not to affect min or max
		- INF values will obviously affect max!
	Overwrites the original xdata and ydata arrays, beginning at element zero

	Changes this version (xf_binpeak4)
		- outputs values at the start & midpoint of each window
		- no setmid option, since peak-detection must output 2 points for every window anyway
		- use simple min/max algorithm instead of calculating deviation from mean

USES:
	Downsample a time-series with peak-detection to avoid loosing significant features

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *xdata	: array holding xdata values
	double *ydata	: array holding ydata values
	long n			: number of elements in the xdata and ydata arrays
	double winwidth : size of the binning window in units of [xdata]

RETURN VALUE:
	Number of elements in the revised xdata & ydata arrays
	-1 if not enough memory to hold the temporary array
	-2 if the window size is too large ( total xdata range &#60 2*winwidth )

SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_blockrealign1_ls"><a href="#CODE">&#8679</a> xf_blockrealign1_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Keep a subset of timestamps based on block-definitions, collapsing across the removed blocks
	Block-definitions in this case are in the form of start-stop pairs

USES:
	Adjust data to remove noisy sections
	Example:
		- an original time series of 0-10 in which a spike occurs at sample 8
		- say we want ti remove samples 2-6 due to noise
		- this is equivalent of keeping 2 blocks, defined using start-stop pairs 0,2 and 7,11
		- in the adjusted data, sample-8 is now sample-3

		original                  compressed
		    _________   *               *
		0 1 2 3 4 5 6 7 8 9 10    0 1 2 3 4 5


DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *samplenum : input holding timestamps (sample-numbers) needing realignment - assumes they are in ascending order
	short *class : input holding clssifier for each timestamp
	long nn : the size of the samplenum array
	long *bstart : array holding the start-samples (included) for each kept block of the original data
	long *bstop : array holding the stop-samples (not included) for each kept block
	long nblocks : the number of blocks
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	new sample-number array-length on success, -1 on error
	samplenum array will be adjusted
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_blockrealign2"><a href="#CODE">&#8679</a> xf_blockrealign2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Restore original timestamps based on block-definitions previously used to keep only subsections of a dataset
	Block-definitions in this case are in the form of start-stop pairs

USES:
	Say an original data series was adjusted to remove noisy data
	If spike events are identified in the modified time-series, adjustment is required to put the
		spike times back in register with the original time series
	Example:
		- an original time series of 0-10 in which a spike occurs at sample 8
		- say samples (2-6) were removed due to noise
		- this is equivalent of keeping 2 blocks, defined using start-stop pairs 0,2 and 7,11
		- spike detection on the compressed data would show spike detection at sample #3
		- this function will correct for compression, restoring the original timestamps

		original                  compressed    corrected
		    _________   *               *             *
		0 1 2 3 4 5 6 7 8 9 10    0 1 2 3 4 5   0 1 7 8 9 10


DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *samplenum : input holding timestamps (sample-numbers) needing realignment - assumes they are in ascending order
	long nn : the size of the samplenum array
	long *bstart : array holding the start-samples (included) for each kept block of the original data
	long *bstop : array holding the stop-samples (not included) for each kept block
	long nblocks : the number of blocks
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	samplenum array will be adjusted
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_compare1_d"><a href="#CODE">&#8679</a> xf_compare1_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Compare funtion to be used in conjunction with qsort
	This version compares double-precision floating point numbers

USES:
	When calling qsort, include this (or similar) function as the 4th argument

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	const void *a : pointer to first element in comparison
	const void *b : pointer to second element in comparison

RETURN VALUE:
	an integer determining if "a" if less than (-1) equal to (0) or greater than (1) "b"

SAMPLE CALL:

	qsort(array,n,sizeof(double),xf_compare1_d);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_compare1_f"><a href="#CODE">&#8679</a> xf_compare1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Compare funtion to be used in conjunction with qsort
	This version compares floating point numbers

USES:
	When calling qsort, include this (or similar) function as the 4th argument

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	const void *a : pointer to first element in comparison
	const void *b : pointer to second element in comparison

RETURN VALUE:
	an integer determining if "a" if less than (-1) equal to (0) or greater than (1) "b"

SAMPLE CALL:

	qsort(array,n,sizeof(float),xf_compare1_f);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_compare1_l"><a href="#CODE">&#8679</a> xf_compare1_l</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Compare funtion to be used in conjunction with qsort
	This version compares long integers

USES:
	When calling qsort, include this (or similar) function as the 4th argument

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	const void *a : pointer to first element in comparison
	const void *b : pointer to second element in comparison

RETURN VALUE:
	an integer determining if "a" if less than (-1) equal to (0) or greater than (1) "b"

SAMPLE CALL:

	qsort(array,n,sizeof(long),xf_compare1_l);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_conv1_f"><a href="#CODE">&#8679</a> xf_conv1_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Convolute two input signals

	Given signal 1 (X) and signal 2 (Y), this algorithm effectively slides a
	reversed version of Y[] along X[], multiplying each Y by the corresponding
	X, provided it exists, and summing the products to create a result.

	Example:

		signal1 (X) consists of seven numbers (0,1,2,3,4,5,6), so nX=7
		signal2 (Y) consists of three numbers (0,1,2), so nY=3

		The first row shows X[]
		Subsequent rows show Y[], reversed & shifted along X[]
		The result for each X is the sum (looking back) of Y*X
		At the end of X[] two additional values can be computed
		Total results therefore = nX+(nY-1) = in this case 7+(3-1) = 9
		However, you could ignore the last nY-1 results
		Missing values denoted by "_"

	_ _ 0 1 2 3 4 5 6 _ _

	2 1 0                  - result[0] = 2x_ + 1x_ + 0x0
	  2 1 0                - result[1] = 2x_ + 1x0 + 0x1
	    2 1 0              - result[2] = 2x0 + 1x1 + 0x2
		  2 1 0            - result[3] = 2x1 + 1x2 + 0x3
	...
	            2 1 0      - result[6] = 2x4 + 1x5 + 0x6
	              2 1 0    - result[7] = 2x5 + 1x6 + 0x_
	                2 1 0  - result[8] = 2x6 + 1x_ + 0x_



USES:

	Filtering sig1 using DSP parameters in sig2

DEPENDENCY TREE:

	No dependencies

ARGUMENTS:

	float *sig1 	: pointer to input array sig1 (X)
	size_t n1		: length of sig1
	float *sig2 	: pointer to input signal#1 (X)
	size_t n2		: length of sig2
	char message[]  : pointer to array to hold messages

RETURN VALUE:

	pointer to a results array with n1+(n2-1) elements
	NULL on failure

SAMPLE CALL:

	#define XDIM 320
	#define HDIM 60

	float *xf_conv1_f(float *sig1, size_t n1, float *sig2, size_t n2,char message[] );

	int main (int argc, char *argv[]) {

		size_t ii;
		float   fX[XDIM], fY[XDIM], fH[HDIM], *result=NULL;

		// DEFINE THE INPUT SIGNAL
		for (ii = 0; ii &#60 XDIM; ii++) fX[ii]=0;
		for (ii = HDIM; ii &#60 XDIM; ii++) fX[ii] = sin(2.0 * M_PI * (float)ii / HDIM) + sin(2.0 * M_PI * (float)ii / 10.0);
		// DEFINE IMPULSE RESPONSE (MAX NO. OF TERMS = HDIM)
		for (ii = 0; ii &#60 HDIM; ii++) fH[ii]=0;
		for (ii = 1; ii &#60= 10; ii++) fH[ii] = 0.1;

		result= xf_conv1_f(fX,XDIM,fH,HDIM,message);

		for(ii=0;ii&#60(n1+(n2-1));ii++) printf("%d %f\n",ii,result[ii]);

		free(result);
		exit(0);

	}


</blockquote></pre>

<font color="Black"><h3 id="code-xf_conv2_f"><a href="#CODE">&#8679</a> xf_conv2_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Convolute two complex input signals
	See xf_conv1_f for general principals

USES:
	Filtering sig1 using DSP parameters in sig2

DEPENDENCY TREE:

	No dependencies

ARGUMENTS:

	complex float *sig1 : pointer to input array sig1 (X)
	size_t n1           : length of sig1
	complex float *sig2 : pointer to input signal#1 (X)
	size_t n2           : length of sig2
	char message[]      : pointer to array to hold messages

RETURN VALUE:

	pointer to a results array with n1+(n2-1) elements
	NULL on failure

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate"><a href="#CODE">&#8679</a> xf_correlate</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	This fills a "results" array with details from a Pearson's correlation
	Requires two parallel arrays of floating point values
	Returns the number of valid sample-pairs included in the analysis
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_d"><a href="#CODE">&#8679</a> xf_correlate_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and return details including F and p statistics
	- this version for double-precision floating-point values of x and y
	Fills a "results" array with details from a Pearson's correlation
	Allows definition of an arbitrary "invalid" value to be ignored
	Assumes all data is stored in memory
	For faster processing with less analysis detail, use xf_correlate_simple_d

USES:
	Detailed correlation statistics on parallel arrays of data

DEPENDENCIES:
	float xf_prob_F(float F,int df1,int df2)

ARGUMENTS:
	double *x      : input, x-data array
	double *y      : input, y-data array
	long nn        : input, number of elements in x & y
	double setinv  : input, user-specified invalid value (typically NAN, but may be other)
	double *result : output, pre-allocated array to hold results - must allow at least 18 elements
	char *message  : output, pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error

	result array will hold statistics
	char array will hold message (if any)

	if r==0:
		check message (minimum correlation) - likely a vertical or horizontal line
		probability of "nan" will confirm this

	if F==99:
		indicates that r was nearly exxactly -1 or +1: F is arbitrarily assigned a large value

SAMPLE CALL:
	x=  xf_correlate_d(x,y,n,-1,result,message);
	if(x==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else if (result[1]==0) { fprintf(stderr,"*** %s/%s\n\n",thisprog,message);}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_f"><a href="#CODE">&#8679</a> xf_correlate_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and return details including F and p statistics
	- this version for floating-point values of x and y
	Fills a "results" array with details from a Pearson's correlation
	Allows definition of an arbitrary "invalid" value to be ignored
	Assumes all data is stored in memory
	For faster processing with less analysis detail, use xf_correlate_simple_d

USES:
	Detailed correlation statistics  on parallel arrays of data

DEPENDENCIES:
	float xf_prob_F(float F,int df1,int df2)

ARGUMENTS:
	float *x       : input, x-data array
	float *y       : input, y-data array
	long nn        : input, number of elements in x & y
	float setinv   : input, user-specified invalid value
	double *result : output, pre-allocated array to hold results - must allow at least 18 elements
	char *message  : output, pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error

	result array will hold statistics
	char array will hold message (if any)

	if r==0:
		check message (minimum correlation) - likely a vertical or horizontal line
		probability of "nan" will confirm this

	if F==99:
		indicates that r was nearly exxactly -1 or +1: F is arbitrarily assigned a large value

SAMPLE CALL:
	x=  xf_correlate_f(x,y,n,-1,result,message);
	if(x==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else if (!isfinite(result[1])) { fprintf(stderr,"*** %s/%s\n\n",thisprog,message);}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_i"><a href="#CODE">&#8679</a> xf_correlate_i</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and return details including F and p statistics
	- this version for integer values of x and y
	Fills a "results" array with details from a Pearson's correlation
	Allows definition of an arbitrary "invalid" value to be ignored
	Assumes all data is stored in memory
	For faster processing with less analysis detail, use xf_correlate_simple_d

USES:
	Detailed correlation statistics  on parallel arrays of data

DEPENDENCIES:
	float xf_prob_F(float F,int df1,int df2)

ARGUMENTS:
	int *x      : input, x-data array
	int *y      : input, y-data array
	long nn     : input, number of elements in x & y
	int setinv  : input, user-specified invalid value
	double *result : output, pre-allocated array to hold results - must allow at least 18 elements
	char *message  : output, pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error

	result array will hold statistics
	char array will hold message (if any)

	if r==0:
		check message (minimum correlation) - likely a vertical or horizontal line
		probability of "nan" will confirm this

	if F==99:
		indicates that r was nearly exxactly -1 or +1: F is arbitrarily assigned a large value

SAMPLE CALL:
	x=  xf_correlate_i(x,y,n,-1,result,message);
	if(x==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else if (!isfinite(result[1])) { fprintf(stderr,"*** %s/%s\n\n",thisprog,message);}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_l"><a href="#CODE">&#8679</a> xf_correlate_l</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and return details including F and p statistics
	- this version for long integer values of x and y
	NOTE THAT RETURN VALUE IS NGOOD, NOT ZERO AS FOR SOME OTHER CORRELATION FUNCTIONS
		- reason: cannot rely on double result[] to accurately record long-integer value of NGOOD

	Fills a "results" array with details from a Pearson's correlation
	Allows definition of an arbitrary "invalid" value to be ignored
	Assumes all data is stored in memory
	For faster processing with less analysis detail, use xf_correlate_simple_d

USES:
	Detailed correlation statistics  on parallel arrays of data

DEPENDENCIES:
	float xf_prob_F(float F,int df1,int df2)

ARGUMENTS:
	int *x      : input, x-data array
	int *y      : input, y-data array
	long nn     : input, number of elements in x & y
	int setinv  : input, user-specified invalid value
	double *result : output, pre-allocated array to hold results - must allow at least 18 elements
	char *message  : output, pre-allocated array to hold error message

RETURN VALUE:
	good pairs used in correlation, -1 on error

	result array will hold statistics
	char array will hold message (if any)

	if r==0:
		check message (minimum correlation) - likely a vertical or horizontal line
		probability of "nan" will confirm this

	if F==99:
		indicates that r was nearly exxactly -1 or +1: F is arbitrarily assigned a large value

SAMPLE CALL:
	x=  xf_correlate_i(x,y,n,-1,result,message);
	if(x==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	else if (!isfinite(result[1])) { fprintf(stderr,"*** %s/%s\n\n",thisprog,message);}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_simple_d"><a href="#CODE">&#8679</a> xf_correlate_simple_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and returns r
	- this version for double-preceision floating-point values of x and y
	Fills a "results" array with  slope, and intercept
	Ignores non-numeric values Nan and Inf
	Should only be used if there are 4 or more data points

USES:
	Simple correlation statistics on parallel arrays of data

DEPENDENCIES:
	None

ARGUMENTS:
	double *x      : input, x-data array
	double *y      : input, y-data array
	long nn        : input, number of elements in x & y
	double *result : output, pre-allocated array to hold results - must allow at least 3 elements

RETURN VALUE:
	Pearson's r (or NAN or 0 if there was a problem)
	if r==0, it may be because the data represented a vertical or horizontal line

	result array will hold slope and intercept

SAMPLE CALL:
	r=  xf_correlate_simple_d(x,y,n,result);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_simple_f"><a href="#CODE">&#8679</a> xf_correlate_simple_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and returns r
	- this version for floating-point values of x and y
	Fills a "results" array with  slope, and intercept
	Ignores non-numeric values Nan and Inf
	Should only be used if there are 4 or more data points

USES:
	Simple correlation statistics on parallel arrays of data

DEPENDENCIES:
	None

ARGUMENTS:
	float *x       : input, x-data array
	float *y       : input, y-data array
	long nn        : input, number of elements in x & y
	double *result : output, pre-allocated array to hold results - must allow at least 3 elements

RETURN VALUE:
	Pearson's r (or NAN or 0 if there was a problem)
	if r==0, it may be because the data represented a vertical or horizontal line

	result array will hold slope and intercept

SAMPLE CALL:
	r=  xf_correlate_simple_f(x,y,n,result);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_simple_i"><a href="#CODE">&#8679</a> xf_correlate_simple_i</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and returns r
	- this version for integer values of x and y
	Fills a "results" array with  slope, and intercept
	Non-numeric values, Nan and Inf should be removed before calling this function
	Should only be used if there are 4 or more data points

USES:
	Simple correlation statistics on parallel arrays of data

DEPENDENCIES:
	None

ARGUMENTS:
	int *x         : input, x-data array
	int *y         : input, y-data array
	long nn        : input, number of elements in x & y
	double *result : output, pre-allocated array to hold results - must allow at least 3 elements

RETURN VALUE:
	Pearson's r (or NAN or 0 if there was a problem)
	if r==0, it may be because the data represented a vertical or horizontal line

	result array will hold slope and intercept

SAMPLE CALL:
	r=  xf_correlate_simple_i(x,y,n,result);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_correlate_simple_l"><a href="#CODE">&#8679</a> xf_correlate_simple_l</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Pearson's correlation and returns r
	- this version for integer values of x and y
	Fills a "results" array with  slope, and intercept
	Non-numeric values, Nan and Inf should be removed before calling this function
	Should only be used if there are 4 or more data points

USES:
	Simple correlation statistics on parallel arrays of data

DEPENDENCIES:
	None

ARGUMENTS:
	int *x         : input, x-data array
	int *y         : input, y-data array
	long nn        : input, number of elements in x & y
	double *result : output, pre-allocated array to hold results - must allow at least 3 elements

RETURN VALUE:
	Pearson's r (or NAN or 0 if there was a problem)
	if r==0, it may be because the data represented a vertical or horizontal line

	result array will hold slope and intercept

SAMPLE CALL:
	r=  xf_correlate_simple_i(x,y,n,result);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_crit_T1"><a href="#CODE">&#8679</a> xf_crit_T1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION
	Use a look-up table to find the critical value from the Student's t-distribution
	http://easycalculation.com/statistics/t-distribution-critical-value-table.php

ARGUMENTS

	long df : degrees of freedom, (1-200)
	float alpha : desired significance level (.05, .02, .01, .005, .002, .001)
	int tails : number of tails for the test (1,2)

	NOTE: cannot provide 1-tailed critical value for alpha=0.1

RETURN VALUE

	The critical t-value, or a negative number signifying an error
		-1: df is less than 1
		-2: inappropriate alpha
		-3: inappropriate number of tails

</blockquote></pre>

<font color="Black"><h3 id="code-xf_curvestats1_d"><a href="#CODE">&#8679</a> xf_curvestats1_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION: Calculate statistics on a curve (single time-series, assumes fixed interval)
	COM:
		- Gerrard,et al., The Journal of Neuroscience (2008). 28(31):7883.7890
		- centre of mass (mathematical mean of observations)
		- this version uses a shifted copy of the curve (all-positive values) to avoid shifting mass to negative values when "y" is negative
		- the result is that for some curves the COM may not be exactly where you think  it should be
		- example: for a single sine-cycle, the upturn at the end will shift the COM to the right of the middle
	MEDIAN:
		- mid-point of summed observations
		- also uses the positive-shifted dataset, as per COM
	TEMPORAL BIAS:
		- Skaggs & McNaughton (1996). Science 271(5257): 1870-1873
		- normalized as per Gerrard et. al 2008
		- a measure normalized of asymmetry in the curve

USES:
	- characterization of a time-series

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *curvey : input holding y-values
	long nn : length of curvey
	double interval: interval between successive values of curvey
	double *result_d : pre-allocated array to hold results - should allow at least 16 elements
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result array will hold statistics
	char array will hold message (if any)

	result_d[0]= xymin;  x-value at the trough
	result_d[1]= ymin;   y-value at the trough
	result_d[2]= xymax;  x-value at the peak
	result_d[3]= ymax;   y-value at the peak
	result_d[4]= median; x-value dividing summed y-values in half
	result_d[5]= com;    centre of mass - i.e. the mean observation

</blockquote></pre>

<font color="Black"><h3 id="code-xf_curvestats2_d"><a href="#CODE">&#8679</a> xf_curvestats2_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION: Calculate statistics on a x/y curve
	- similar to xf_curvestats1_d but allows specification of x-values, and hence uneven sampling if necessary
	- also includes a temporal bias measure designed for detecting asymmetry in histograms

	COM:
		- Gerrard,et al., The Journal of Neuroscience (2008). 28(31):7883.7890
		- centre of mass (mathematical mean of observations)
		- this version uses a shifted copy of the curve (all-positive values) to avoid shifting mass to negative values when "y" is negative
		- the result is that for some curves the COM may not be exactly where you think  it should be
		- example: for a single sine-cycle, the upturn at the end will shift the COM to the right of the middle
	MEDIAN:
		- mid-point of summed observations
		- also uses the positive-shifted dataset, as per COM
	TEMPORAL BIAS:
		- Skaggs & McNaughton (1996). Science 271(5257): 1870-1873
		- normalized as per Gerrard et. al 2008
		- a measure normalized of asymmetry in the curve

USES:
	- characterization of a time-series or histogram

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *curvex : input holding x-values
	double *curvey : input holding y-values
	long nn        : length of curvex and curvey
	double *result_d : pre-allocated array to hold results - should allow at least 7 elements
	char *message    : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result array will hold statistics
	char array will hold message (if any)

	result_d[0]= xymin;  x-value at the trough
	result_d[1]= ymin;   y-value at the trough
	result_d[2]= xymax;  x-value at the peak
	result_d[3]= ymax;   y-value at the peak
	result_d[4]= median; x-value dividing summed y-values in half
	result_d[5]= com;    centre of mass - i.e. the mean observation
	result_d[6]= bias;   normalized temporal bias (d2-score)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_curvestats3_f"><a href="#CODE">&#8679</a> xf_curvestats3_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:John Huxter: 17 February 2015

	- based on xf_wavewidth.c, which was designed to detect compound waveform width for action potentials

	A function to find the peak and width in a curve
	Peak can be positive or negative
	Width is the width at the point at which a percentage of the peak is crossed
	For compound curves (multiple channels in sequence) the width of the channel containing the peak is used


USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *curve    : input array of values representing a curve
	int nn         : number of samples in the curve
	int nchan      : if a compound curve, the number of channels (eg. 4 for a tetrode waveform)
	float thresh   : threshold as a percentage of the max or min value (see sign, below)
	int sign       : whether thresholdhing should be set to maximum (1) or minimum (-1)
	float *results : pre-allocated array to hold the results of the analysis
	char *message  : pre-allocated array to hold error message

RETURN VALUE:
	index to the detected peak
	-1 on error

	result array will hold statistics
		result[0]=peak value
		result[1]=width at threshold
		result[2]=threshold used

	char array will hold message (if any)

SAMPLE CALL:




</blockquote></pre>

<font color="Black"><h3 id="code-xf_dateconv1"><a href="#CODE">&#8679</a> xf_dateconv1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	- convert a date to the day- or week-in-the-year
	- weeks are presumed to begin with Monday
USES:
	- convert a date to a number useable for plotting results

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	int sety      ; year (e.g. 2000)
	int setm      : month-in-year (e.g. 12)
	int setd      : day-in-month (e.g. 28)
	int setconv   : convert to week (1) or day (2)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	on success: week-in-year (0-52) or day-in-year (1-365)
	on error: -1
	message array will be filled if there was an error

SAMPLE CALL:
		char message[256];
		int z,year=2000,month=12,day=31;
		z= xf_dateconv1(year,month,day,1,message);
		if(z&#620) printf("week-in-year=%d\n",z);
		else { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_datemod1"><a href="#CODE">&#8679</a> xf_datemod1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Adjust a date/time array by adding or subtracting a number of days, hours, minutes or seconds
	- should accurately reflect lengths of months, leap years, etc
USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	int *input    : pre-allocated 6-item array input array
				input[0]: year
				input[1]: month
				input[2]: day
				input[3]: hour
				input[4]: minute
				input[5]: second
	int adjust    : adjustment to apply to one of the values
	char *field   : the field of to adjust (day,hour,min, or sec)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	input array will be adjusted

SAMPLE CALL:
	To get the date/time 90 minutes before 1 January 2000 10:30:15 AM

		char message[256];
		int i,x, mydate[6];
		mydate[0]=2000; mydate[1]=1; mydate[2]=1; mydate[3]=10; mydate[4]=30; mydate[5]=15;

		x= xf_datemod1(mydate,-90,"min",message)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_dateparse1"><a href="#CODE">&#8679</a> xf_dateparse1</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Convert a date-string into integer year month and day values
	- can convert different date-formats into the three digits for constructing the actual date
	- all input values must be numeric (e.g. December= 12, not DEC or similar)
	- years represented as two-digits will not be expanded (eg. 99 does not become 1999)

DEPENDENCIES:
	None

ARGUMENTS:
	char *date1   : date1, date-string in one of the following numeric formats...
	int format    : date1, format (1-4) 1: dd/mm/yyyy 2: mm/dd/yyyy 3: yyyy/mm/dd 4: yyyymmdd
	int *year     : output (pass to function as address): year
	int *month    : output (pass to function as address): month
	int *day      : output (pass to function as address): day
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	year, month and day will be assigned
	char array will hold message (if any)

SAMPLE CALL:
	char *date1="12/31/2000\0"
	int year,month,day;
	z= xf_dateparse1(date1,2,year,month,day,message);
	if(z==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

&#60TAGS&#62 string time &#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_decimate_f"><a href="#CODE">&#8679</a> xf_decimate_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Keep every "nth" point in an input (float)
	- can accept fractional decimation factors

USES:
	achieve exact downsampling of an input

DEPENDENCIES: none

ARGUMENTS:
	float *data    : input, array
	long ndata     : input, length of input array
	double winsize : the size of the decimation window (eg. 10.5)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	number of points in decimated reults or -1 on error

SAMPLE CALL:
	# to downsample a 10s input sampled at 500 Hz to 400 Hz
	#	- n= 10*500 = 5000
	#	- downsample factor is 500/400= 1.25

	n= xf_decimate_f(data,n,1.25,message);
	if(n&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

	# note that n should be 4000

</blockquote></pre>

<font color="Black"><h3 id="code-xf_decimate_s"><a href="#CODE">&#8679</a> xf_decimate_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Keep every "nth" point in an input (short)
	- can accept fractional decimation factors

USES:
	achieve exact downsampling of an input

DEPENDENCIES: none

ARGUMENTS:
	short *data    : input, array
	long ndata     : input, length of input array
	double winsize : the size of the decimation window (eg. 10.5)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	number of points in decimated reults or -1 on error

SAMPLE CALL:
	# to downsample a 10s input sampled at 500 Hz to 400 Hz
	#	- n= 10*500 = 5000
	#	- downsample factor is 500/400= 1.25

	n= xf_decimate_s(data,n,1.25,message);
	if(n&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

	# note that n should be 4000

</blockquote></pre>

<font color="Black"><h3 id="code-xf_dejump2_f"><a href="#CODE">&#8679</a> xf_dejump2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Remove jumpy points from a series
	- unlike filtering, will not alter the posx outside the "jumpy" events
	- points are invalidated (assigned to NAN) until one is found that doesn't look jumpy relative to the last good point
	- note that once enough time has elapsed, a series of displaced points can be considered non-jumpy again.

USES:
	Remove rapid changes in posx due to mis-measurement
	Can help to remove noise artefacts

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *posx  : pointer to array already holding event ids (eg. cell-numbers)
	long nn      : number of elements in the arrays
	double sfreq : sample-frequency of input (samples per second)
	float thresh : the threshold for rate-of-change, beyond which posx is reassigned to NAN

RETURN VALUE:
	Number of jumpy points invalidated
	No error return for this function

SAMPLE CALL:
	# in a video data record sampled t 25Hz, invalidate movement &#62 200cm/s
	njumps= xf_dejump2_f(posx, posy, nn, 25.0, 200.0)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_demean1_d"><a href="#CODE">&#8679</a> xf_demean1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a sliding boxcar-average normalization to a data series - local mean is subtracted from each datum
	Acts as a high-pass filter
	Uses a single-sample-step sliding window, so output is same length as input
	Data at the beginning and end of the input is adjsted by a fraction of the window size not less than 1/2

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
		- in such cases it is recommended to interpolate the input before passing to this function

USES:
	Signal analysis

DEPENDENCIES:
	None

ARGUMENTS:

	double *input   : pointer to array holding amplitude time series to be normalized
	long nn        : length of the input & output arrays
	long nwin1     : length of averaging window, +1 if even
				- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success, input[] will be overwritten
	-1 on error
	message array will hold explanatory text (if any)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_demean1_f"><a href="#CODE">&#8679</a> xf_demean1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a sliding boxcar-average normalization to a data series - local mean is subtracted from each datum
	Acts as a high-pass filter
	Uses a single-sample-step sliding window, so output is same length as input
	Data at the beginning and end of the input is adjsted by a fraction of the window size not less than 1/2

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
		- in such cases it is recommended to interpolate the input before passing to this function

USES:
	Signal analysis

DEPENDENCIES:
	None

ARGUMENTS:

	float *input   : pointer to array holding amplitude time series to be normalized
	long nn        : length of the input & output arrays
	long nwin1     : length of averaging window, +1 if even
				- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success, input[] will be overwritten
	-1 on error
	message array will hold explanatory text (if any)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_demean1_s"><a href="#CODE">&#8679</a> xf_demean1_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a sliding boxcar-average normalization to a data series - local mean is subtracted from each datum
	Acts as a high-pass filter
	Uses a single-sample-step sliding window, so output is same length as input
	Data at the beginning and end of the input is adjsted by a fraction of the window size not less than 1/2

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
		- in such cases it is recommended to interpolate the input before passing to this function

USES:
	Signal analysis

DEPENDENCIES:
	None

ARGUMENTS:

	short *input   : pointer to array holding amplitude time series to be normalized
	long nn        : length of the input & output arrays
	long nwin1     : length of averaging window, +1 if even
				- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success, input[] will be overwritten
	-1 on error
	message array will hold explanatory text (if any)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_density1_l"><a href="#CODE">&#8679</a> xf_density1_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the density of discrete events in non-overlapping windows
	Assigns memory for the density array
	Very similar to xf_smoothbox1_d

USES:
	- convert spike-times into a firing-rate timecourse
	- Convert a list of event times into a density time series

DEPENDENCIES:
	None

ARGUMENTS:
	long *etime   : input array of event times (sample numbers) - assumed to be in ascending order
	long nn       : total number of events
	long min      : minimum event time: -1= events[0]
	long max      : maximum event time: -1= events[nevents-1]
	double winsize: size of the sliding window (samples, fractional if necessary) in which to calculate density
	long nwin     : result: number of density-windows generated
	char *message : arrray to hold message in the event of an error

RETURN VALUE:
	on success:
		- pointer to the density array (time series)
		- nwin will be updated to reflect size of density array
	on error:
		NULL

SAMPLE CALL:
	density= xf_density1_l(time1,nn,0,-1,winsize,&nwin,message);
	if(density==NULL) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_density2_l"><a href="#CODE">&#8679</a> xf_density2_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the density (counts) defined by start-stop pairs of blocks of samples, using non-overlapping windows
	Assigns memory for the density array
	Very similar to xf_smoothbox1_d, derived from xf_density1_1

USES:
	- convert lost.ssp packet-loss definitions into a packet-loss time-series

DEPENDENCIES:
	None

ARGUMENTS:
	long *start1  : input array of start-times (sample numbers) - assumed to be in ascending order
	long *stop1   : input array of stop-times (sample numbers) - assumed to be in ascending order
	long nn       : total number of events
	long min      : minimum event time: -1= events[0]
	long max      : maximum event time: -1= events[nevents-1]
	double winsize: size of the sliding window (samples, fractional if necessary) in which to calculate density
	long nwin     : result: number of density-windows generated
	char *message : arrray to hold message in the event of an error

RETURN VALUE:
	on success:
		- pointer to the density array (counts, time series)
		- nwin will be updated to reflect size of density array
	on error:
		NULL

SAMPLE CALL:
	density= xf_density2_l(start1,stop1,nn,0,-1,winsize,&nwin,message);
	if(density==NULL) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_densitymatrix1_l"><a href="#CODE">&#8679</a> xf_densitymatrix1_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Determine the cumulative occurance of x/y values rounded to fill a matrix of fixed dimensions
	- note that x/y zero will correspond to the upper left corner of the matrix
	WARNING: do not use for repeated calls assign memory for the same array
		- consider using xf_densitymatrix2_l instead

USES:
	- create a density matrix of dwell-times from a series of x-y position data
	- create an action-potential density matrix from the x/y positions associated with cell firing

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *xdata : input holding x-position values data
	float *ydata : input holding y-position values data
	long nn      : number of x/y pairs in the input
	long setxbintot : desired width of the matrix (must be &#620)
	long setybintot : desired height of the matrix (must be &#621)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	pointer to matrix of setxbintot x setybintot values, or NULL on error
	char array will hold message (if any)

SAMPLE CALL:
	long *matrix=NULL;
	width=3; height=5;
	matrix= xf_densitymatrix1_f(xdata,ydata,nn,width,height,message);
	if(matrix==NULL)  { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	for(ii=0;ii&#60(width*height);ii++) {
		printf("%ld\t",matrix[ii]);
		if((ii+1)%width=0) printf("\n");
	}


</blockquote></pre>

<font color="Black"><h3 id="code-xf_densitymatrix2_l"><a href="#CODE">&#8679</a> xf_densitymatrix2_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Determine the cumulative occurance of x/y values rounded to fill a matrix of fixed dimensions
	- note that x/y zero will correspond to the upper left corner of the matrix
	- this version is safe for repeated calls - memory for output assigned by calling function

USES:
	- create a density matrix of dwell-times from a series of x-y position data
	- create an action-potential density matrix from the x/y positions associated with cell firing

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *xdata : input holding x-position values data
	float *ydata : input holding y-position values data
	long nn      : input number of x/y pairs in the input
	long *matrix : output preallocated array able to hold output of size (setxbintot x setybintot)
	long setxbintot : input desired width of the matrix (must be &#620)
	long setybintot : input desired height of the matrix (must be &#621)
	float *ranges : input pointer to ranges[4] array defining xmin,ymin,xmax,ymax, or NANs for auto-setting each range based on *xdata and *ydata
	char *message : onput pre-allocated array to hold error message

RETURN VALUE:
	status flag (0=OK, -1=ERROR)
	matrix array will be overwritten
	message array will hold message (if any)

SAMPLE CALL:
	long matrix[15];
	width=3; height=5;
	z= xf_densitymatrix1_f(xdata,ydata,nn,matrix,width,height,message);
	if(z=-1)  { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	for(ii=0;ii&#60(width*height);ii++) {
		printf("%ld\t",matrix[ii]);
		if((ii+1)%width=0) printf("\n");
	}


</blockquote></pre>

<font color="Black"><h3 id="code-xf_detectcycles2_f"><a href="#CODE">&#8679</a> xf_detectcycles2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>DESCRIPTION:
	Detect start peak & stop times for cycles (oscillations) in data
	Detection is on the trough (inflection)
	Peak-point is taken as the highest value
	Differences from xf_detectcycles1_f:
		- no sine-fit test of fit
		- above is presumed to have been handled by a preceeding filtering step
		- addition of peak(peak) output


USES:

DEPstopENCY TREE:
	No depstopencies

ARGUMENTS:
	float *data     : pointer to input (time series)
	size_t ndat     : number of elements in the data array
	size_t cmin 	: minimum duration of cycle to be included
	size_t cmax 	: maximum duration of cycle to be included
	size_t **cstart : address to array to hold results (cycle start-times) - calling function must free()
	size_t **cpeak  : address to array to hold results (cycle peak(peak)-times) - calling function must free()
	size_t **cstop  : address to array to hold results (cycle stop-times) - calling function must free()
	size_t *cycletot: address to variable (not an array) holding the total cycles detected

RETURN VALUE:
	0 on success, -1 on failure

SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_detectevents1_f"><a href="#CODE">&#8679</a> xf_detectevents1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>DESCRIPTION:
	Detect events in a series when a threshold is exceeded
	For each supra-threshold point, the function looks outward until the data drops below the half-threshold
	Edges of events (stop-start= width) are defined by the edge-threshold
	Data must drop below half-threshold before another event can be detected
	No event will be detected until data is found which does NOT exceed threshold


USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : input holding data
	long n1       : size of data array
	float thresh  : data sample must exceed this value for event detection to begin
	float edge    ; percentage of threshold to determine edge of the event (e.g. 0.5)
	int sign      : sign of detection (-1,0,+1 :  -1=lessthan +1=greaterthan, 0=either)
	long nmin     : minimum number of samples for which the half-threshold must be exceeded (0=no limit)
	long nmax     : maximum number of samples for which the half-threshold must be exceeded (0=no limit)
	long **estart : address for results array (event start-samples) - calling function must free()
	long **estop  : address for results array (event stop-samples) - calling function must free()
	char *message : arrray to hold message in the event of an error

RETURN VALUE:
	number of detected events (&#62=0) on success
	-1 on error
	result array will have been assigned memory and will hold event start and stop samples

SAMPLE CALL:
	# detect events where signal is less than three for between 200 and 2000 samples

		long *estart=NULL,*estop=NULL;

		nevents= xf_detectevents1_f(data,n,3,-1,200,2000,&estart,&estop,message);
		if(nevents&#600) {fprintf(stderr,"\n--- Error: %s\n\n",message); exit(1);}

		if(estart!=NULL) free(estart);
		if(estop!=NULL) free(estop)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_detectevents2_f"><a href="#CODE">&#8679</a> xf_detectevents2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>DESCRIPTION:
	Detect events in a series when a threshold is exceeded - must meet a duration criterion
	Edges of events (stop-start= length) are defined by the edge-threshold
	Data must drop below edge-threshold before another event can be detected
	No event will be detected until data is found which does NOT exceed threshold
	This function allocates memory for the results

	NOTE: Data should be high-pass filtered and/or z-scored before running this!

	Changes from xf_detectevents1_f
	- upper threshold accepted to allow event rejection
	- output now includes a measure of the peak-time within each event, instead of just the start & stop times

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : input holding data
	long n1       : size of data array
	float thresh  : data sample must exceed this value for event detection to begin
	float upper   : data within an event must remain below this multiple of the threshold - exceeding this value invalidates the event
	float edge    ; data must drop below this multiple of the threshold to determine the edge of the event (e.g. 0.5)
	int sign      : sign of detection (-1,0,+1 :  -1=lessthan +1=greaterthan, 0=either)
	long nmin     : minimum number of samples for which the half-threshold must be exceeded (0=no limit)
	long nmax     : maximum number of samples for which the half-threshold must be exceeded (0=no limit)
	long **estart : address for results array (event start-samples) - calling function must free()
	long **epeak  : address for results array (event peak-samples) - calling function must free()
	long **estop  : address for results array (event stop-samples) - calling function must free()
	char *message : arrray to hold message in the event of an error - calling function must allocate memory

RETURN VALUE:
	number of detected events (&#62=0) on success
	-1 on error
	result array will have been assigned memory and will hold event start and stop samples

SAMPLE CALL:
	# detect events where signal is less than three for between 200 and 2000 samples

		long *estart=NULL,*estop=NULL;

		nevents= xf_detectevents2_f(data,n,3,10,.5,-1,200,2000,&estart,&epeak,&estop,message);
		if(nevents&#600) {fprintf(stderr,"\n--- Error: %s\n\n",message); exit(1);}

		if(estart!=NULL) free(estart);
		if(epeak!=NULL) free(epeak);
		if(estop!=NULL) free(estop)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_detectevents3_lf"><a href="#CODE">&#8679</a> xf_detectevents3_lf</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>DESCRIPTION:
	Define start-stop sample-pairs (SSP) defining periods (events) when data falls within a range
	This is slightly different from detectevents1&2, which are geared towards peak and edge thresholds and define a time for the peak as well
	- must meet a duration criterion defined by tstamp
	- data must fall out-of-range before another event can be detected
	- this function allocates memory for the results
	- NOTE: for each start-stop pair...
		start = first sample meeting the criteria
		stop  = first sample NOT meeting the criteria thereafter (ie the sample after the last sample in the block)
		hence if start=stop, duration of event is zero

	UPDATE: 20.July.2016: fix adjustment to stop if last sample is good - DO NOT adjust the actual timestamp of the last sample!

USES:
	- define epochs when velociity meets a criteria

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *tstamp  : input timestamps used to asess duration of events, and to define start-stop pairs
	float *data   : input data
	long n1       : size of data array
	float min     : minimum data value for inclusion (nan = no limit = FLT_MIN)
	float max     : minimum data value for inclusion (nan = no limit = FLT_MAX)
	long mindur   : minimum duration of event (0 = no limit - should be in tstamp units)
	long **estart : address for results array (event start-samples) - calling function must free()
	long **estop  : address for results array (event stop-samples) - calling function must free()
	char *message : arrray to hold message in the event of an error - calling function must allocate memory

RETURN VALUE:
	number of detected events, &#62=0 on success
	-1 on error
	result arrays estart and estop will have been assigned memory and will hold event start and stop samples

SAMPLE CALL:
	# detect events where data is less than 5 for at least 10seconds, and timestamps reflected data sampled at 20k

	long kk,*estart=NULL,*estop=NULL;
	double min=nan, max=5, duration=10, samprate=20000;

	kk=(long)(duration*samprate);

	nevents= xf_detectevents2_f(tstamp,data,n1,min,max,kk,&estart,&estop,message);
	if(nevents&#600) {fprintf(stderr,"\n--- Error: %s\n\n",message); exit(1);}

	if(estart!=NULL) free(estart);
	if(estop!=NULL) free(estop)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_detectinflect1_f"><a href="#CODE">&#8679</a> xf_detectinflect1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-detect">detect</a>]<br>
<blockquote><pre>DESCRIPTION:
	Detect inflections in a series
	Assumes signal is filtered to reduce number of inflections to a reasonable number

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : input holding data
	long n1       : size of data array
	long **itime : address for time-stamp array (samples) - calling function must free()
	int **isign  : address for inflection-sign array (-1=negative, 1=positive) - calling function must free()
	char *message : arrray to hold message in the event of an error

RETURN VALUE:
	number of detected inflections (&#62=0) on success
	-1 on error
	result arrays *itime and *isign will have been assigned memory and will hold event times (sample) and sign (-1 or +1)

SAMPLE CALL:
	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62
	#include &#60math.h&#62
	int main (int argc, char *argv[]) {
		char message[1000];
		long *itime=NULL,n1=350,n2,ii;
		int *isign=NULL;
		float data[1000];
		double aa=M_PI/10;
		for(ii=0;ii&#60n1;ii++) data[ii]= sin(ii*aa);
		for(ii=0;ii&#60n1;ii++) printf("%ld %g\n",ii,data[ii]);
		n2= xf_detectinflect1_f(data,n1,&itime,&isign,message);
		if(n2&#600) {fprintf(stderr,"\n--- Error: %s\n\n",message); exit(1);}
		for(ii=0;ii&#60n2;ii++) printf("%ld\t%d\n",itime[ii],isign[ii]);
		if(itime!=NULL) free(itime);
		if(isign!=NULL) free(isign);
	}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_detrend1_d"><a href="#CODE">&#8679</a> xf_detrend1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION
	Remove linear trends from a data series

USES

ARGUMENTS
	double *y   : pointer to array holding input time-series, constant intervals assumed
	size_t nn  : number of elements in y[]
	double *result_d : array to hold results, initialized by calling function
		result_d[0]= intercept
		result_d[1]= slope
		result_d[2]= Pearson's r

RETURN VALUE
	0 on success
	1 on failure (impossible at present)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_detrend1_f"><a href="#CODE">&#8679</a> xf_detrend1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION
	Remove linear trends from a data series

USES

ARGUMENTS
	float *y   : pointer to array holding input time-series, constant intervals assumed
	size_t nn  : number of elements in y[]
	double *result_d : array to hold results, initialized by calling function
		result_d[0]= intercept
		result_d[1]= slope
		result_d[2]= Pearson's r

RETURN VALUE
	0 on success
	1 on failure

</blockquote></pre>

<font color="Black"><h3 id="code-xf_err1"><a href="#CODE">&#8679</a> xf_err1</h3></font>
[<a href="#tag-programming">programming</a>]<br>
<blockquote><pre>DESCRIPTION:
	Simple error-handling function (prints error message and exits)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *message : input message to print before exit

RETURN VALUE:
	none

SAMPLE CALL:
	x= xf_auc1_d(data, nn, interval, result, );
	if(x!=0) xf_err1("PROG,NAME","this is the error",1);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_eventadjust1_f"><a href="#CODE">&#8679</a> xf_eventadjust1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Align events to the inflection nearest the midpoint
	Calling function specifies whether inflection should be positive or negative
	Calling function specifies the maximum allowable shift

USES:
	Prevent possible cancellation of peaks and troughs when oscillatory events are averaged

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : the raw data containing events- should be filtered (smooth) in the event frequency range
	long ndata    : the number of samples in data
	long *etime   : sample-numbers in data representing event-times - typically the middle of the event
	long nevents  : the number of events in etime
	int sign      : detect nearest positive (1) or negative (-1) inflection
	long shiftmax : largest allowable shift (samples)
	char *message : arrray to hold message in the event of an error - calling function must allocate memory

RETURN VALUE:
	0 on success, -1 on error

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_expand1_d"><a href="#CODE">&#8679</a> xf_expand1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Expand a series of numbers so there are a user-defined number of elements [setn]
	Data is duplicated as required

	Alters input array
	NAN values will be ignored, but INF will affect the results

USES:
	- modifying different series of data so they are all the same length
	- making an irregular matrix of data have rows all the same length

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data: input, array of numbers to be resampled
	long nn: input, number of elements in data
	long setn: input, the new number of elements requested for data
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	Pointer to modified data array - NULL if memory allocation error occurs

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_expand1_f"><a href="#CODE">&#8679</a> xf_expand1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	Expand a series of numbers so there are a user-defined number of elements [setn]
	Data is duplicated as required

	Alters input array
	NAN values will be ignored, but INF will affect the results

USES:
	- modifying different series of data so they are all the same length
	- making an irregular matrix of data have rows all the same length

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data: input, array of numbers to be resampled
	long nn: input, number of elements in data
	long setn: input, the new number of elements requested for data
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	Pointer to modified data array - NULL if memory allocation error occurs

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filesize"><a href="#CODE">&#8679</a> xf_filesize</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Returns the size of a file in bytes - compatible with large files sizes (&#622GB)
	NOTE: for windows, use xf_filesize_win.cpp instead
</blockquote></pre>

<font color="Black"><h3 id="code-xf_fillinterp_itime"><a href="#CODE">&#8679</a> xf_fillinterp_itime</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Fill target array (valB) with interpolated values from source array (valA),
	based on where the target array times (timeB) fall relative to the source array (timeA)

	Invalid data points only assigned to B where it is out of range of A (beginning & end)

	This function is like hux_fillinterp except
		- times are unsigned long integers
		- a maximum number of invalid samples across which to interpolate is defined
		- totA and totB are long integers
		- invalid is a float

	This function is NOT appropriate for data with large number of invalid samples (eg. theta phase)
	- in this case, use similar routine, hux_fillprev instead


USES:
	Allows mapping of data from the source array onto a different time-series of samples
	E.g. assign interpolated position values to a series of neuronal action potential times

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long unsigned int *timeA	: input timestamps of the source array
	long unsigned int *timeB	: input time-stamps of the target array
	float *valA	: input data values, interpolated versions of which are sent to valB
	float *valB	: output data values
	int totA		: total number of values in the source array
	int totB		: total number of values in the target array
	int invalid 	: value to treat as invalid (typically -1)
	int max_invalid : maximum permissible number of invalid points to allow interpolation accross
	char *type  	: data type, "linear" or "circular" (0-360)

RETURN VALUE:
	The number of interpolated values generated (excluding invalid samples at start and end)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_fillinterp_lf"><a href="#CODE">&#8679</a> xf_fillinterp_lf</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Fill target array (B) with interpolated values from source array (A)
	- Uses timestamps for each array to find A's which fall before & after each B
	- Assigns interpolated value of A to B
	- Invalid data points only assigned to B where it is out of range of A (beginning & end)
	- NOT appropriate for data with large number of invalid samples

	- derived from hux_fillinterp.c and xf_fillinterp_itime.c
		- however, this function insists interpolation must use samples either side of the target, not the previous sample and one which coincidentally has the same timestamp as the target
		- also, user does not define an invalid value - NAN is taken as invalid

USES:
	- assigning low-sample-rate position values to high-sample-rate action-potiential data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	long *Atime : input holding timestamps (sample-numbers) for array A
	long *Btime : input holding timestamps (sample-numbers) for array B
	float *Aval	: the data for array A (source)
	float *Bval : the data for array B (destination)
	long Atot : total elements in array A
	long Btot : total elements in array B
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result array will hold statistics
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_bworth1_d"><a href="#CODE">&#8679</a> xf_filter_bworth1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a bi-directional, tweaked biquad Butterworth filter to an array of numbers
		- overwrites the original input array
		- high- and low-pass filters initialize differently to avoid edge effects

	Makes two passes at the data (forward & reverse), to avoid time-shifting
	Does this twice, as required, to do both low- and high-pass filtering
	High- and low-pass filters initialize differently to avoid edge effects

	Coefficient calculations based on public domain code originally
	posted by Patrice Tarrabia (http://www.musicdsp.org/showone.php?id=38)

	NOTE : interpolation should be applied first if needed to remove NANs or INFs
	NOTE : padding the array can help remove effects from large deflections at either edge
    	NOTE : normalizing data to the mean before filtering can reduce artefacts in the output


	NOTE: http://www.iowahills.com/A8FirIirDifferences.html
	IIR Zero Input Limit Cycles
	IIR filters differ from FIR filters in that some IIR filters can suffer from a phenomenon known as Zero Input Limit Cycles. This is a problem related to register size where the IIR filter is unable to clear its registers and its output can't settle at zero after the input goes to zero. The filter's output may oscillate indefinitely because a small residual signal continues to circulate within the filter.
	Of course, an ideal IIR filter's output will never settle at zero in theory, but this is only true if the registers have infinite precision. The truncation caused by limited register size will limit the length of the filters impulse response and should also prevent limit cycles. Notch and high pass IIR filters are most susceptible to this problem and will require extra register bits to prevent this phenomenon from occurring.

USES:
	To remove unwanted frequencies from data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *X         : data array to be filtered, fixed sample rate is assumed
	size_t nn         : length of X array
	float sample_freq : sample frequency (samples per second)
	float low_freq    : cut-off for the high-pass filter - set to 0 to skip this step
	float high_freq   : cut-off for the low-pass filter - set to 0 to skip this step
	float res:        :  resonance value (range 0-sqrt(2), typically sqrt(2) )
	                        NOTE: low values produce sharper rolloffs but can produce ringing in the output
	                        NOTE: high values produce gentle rolloffs but can dampen the signal
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_bworth1_f"><a href="#CODE">&#8679</a> xf_filter_bworth1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a bi-directional, tweaked biquad Butterworth filter to an array of numbers
		- overwrites the original input array
		- high- and low-pass filters initialize differently to avoid edge effects

	Makes two passes at the data (forward & reverse), to avoid time-shifting
	Does this twice, as required, to do both low- and high-pass filtering
	High- and low-pass filters initialize differently to avoid edge effects

	Coefficient calculations based on public domain code originally
	posted by Patrice Tarrabia (http://www.musicdsp.org/showone.php?id=38)

	NOTE : interpolation should be applied first if needed to remove NANs or INFs
	NOTE : padding the array can help remove effects from large deflections at either edge
    	NOTE : normalizing data to the mean before filtering can reduce artefacts in the output


	NOTE: http://www.iowahills.com/A8FirIirDifferences.html
	IIR Zero Input Limit Cycles
	IIR filters differ from FIR filters in that some IIR filters can suffer from a phenomenon known as Zero Input Limit Cycles. This is a problem related to register size where the IIR filter is unable to clear its registers and its output can't settle at zero after the input goes to zero. The filter's output may oscillate indefinitely because a small residual signal continues to circulate within the filter.
	Of course, an ideal IIR filter's output will never settle at zero in theory, but this is only true if the registers have infinite precision. The truncation caused by limited register size will limit the length of the filters impulse response and should also prevent limit cycles. Notch and high pass IIR filters are most susceptible to this problem and will require extra register bits to prevent this phenomenon from occurring.

USES:
	To remove unwanted frequencies from data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *X          : data array to be filtered, fixed sample rate is assumed
	size_t nn         : length of X array
	float sample_freq : sample frequency (samples per second)
	float low_freq    : cut-off for the high-pass filter - set to 0 to skip this step
	float high_freq   : cut-off for the low-pass filter - set to 0 to skip this step
	float res:        :  resonance value (range 0-sqrt(2), typically sqrt(2) )
	                        NOTE: low values produce sharper rolloffs but can produce ringing in the output
	                        NOTE: high values produce gentle rolloffs but can dampen the signal
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_bworth2_f"><a href="#CODE">&#8679</a> xf_filter_bworth2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a tweaked biquad Butterworth filter to an array of numbers
		- this version does not modify original input array (X)
		- consequently, it requires pre-allocation of memory for swap (Y) and output (Z)

	Makes two passes at the data (forward & reverse), to avoid time-shifting
	Does this twice, if required, to do both low- and high-pass filtering

	Coefficient calculations based on public domain code originally
	posted by Patrice Tarrabia (http://www.musicdsp.org/showone.php?id=38)

	NOTE : interpolation should be applied first if needed to remove NANs or INFs
	NOTE : padding the array can help remove effects from large deflections at either edge
           of the data, but is NOT required to compensate for data offset from zero
	NOTE: 2015_05_08: modified initialization for low-pass filter to reduce edge artefact incidence

USES:
	To remove unwanted frequencies from data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *X:           array holding input to be filtered, fixed sample rate is assumed
	float *Y:           array reserved for swapping values, memory must be pre-allocated by calling function
	float *Z:           array reserved for filtered output, memory must be pre-allocated by calling function
	size_t nn:          length of X and Z arrays
	float sample_freq:  sample frequency (samples per second)
	float low_freq:     cut-off for the high-pass filter - set to 0 to skip this step
	float high_freq:    cut-off for the low-pass filter - set to 0 to skip this step
							NOTE: if neither low_freq nor high_freq are set, data is copied unaltered to Z
	float res:          resonance value (typically 1, range 0-sqrt(2) )
	                        NOTE: low values produce sharper rolloffs but can produce ringing in the output
	                        NOTE: high values produce gentle rolloffs but can dampen the signal
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_bworth_matrix1_d"><a href="#CODE">&#8679</a> xf_filter_bworth_matrix1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a bi-directional, tweaked biquad Butterworth filter to an 2D matrix of numbers
		- overwrites the original input array
		- based on xf_filter_bworth1, but differs as follows...
			- filter is applied to each row
			- X is a pointer within the function, and nn is derived from the "width" argument
			- each row is de-meaned before filtering, and the mean re-applied afterwards
			- in this way mean differences between rows are preserved

	NOTE : interpolation should be applied first if needed to remove NANs or INFs

USES:
	Efficient filtering of time-series matrices - filter applied in time (rows)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *X         : data array to be filtered, fixed sample rate is assumed
	size_t nn         : length of X array
	float sample_freq : sample frequency (samples per second)
	float low_freq    : cut-off for the high-pass filter - set to 0 to skip this step
	float high_freq   : cut-off for the low-pass filter - set to 0 to skip this step
	float res:        :  resonance value (range 0-sqrt(2), typically sqrt(2) )
	                        NOTE: low values produce sharper rolloffs but can produce ringing in the output
	                        NOTE: high values produce gentle rolloffs but can dampen the signal
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_clip1_f"><a href="#CODE">&#8679</a> xf_filter_clip1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Clip values in an array exceeding certain limits
	A minimum number of sequencial valid data must be present in order to avoid clipping

USES:
	- restrict the data range in a data series
	- invalidate values exceeding a certain threshold

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data0:     array holding input to be filtered, fixed sample rate is assumed
	size_t nn:        length of data0 array
	size_t nwin:      minimum number of sequential valid points required to pass filter
	float min:        minimum value to keep
	float max:        maximum value to keep
	float newmin:     clipped value to replace numbers less than min
	float newmax:     clipped value to replace numbers more than max
	char message[]:	  message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_FIRapply1_f"><a href="#CODE">&#8679</a> xf_filter_FIRapply1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a Finite Impulse Response (FIR) filter to an array of data
	Overwrites input array
USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : input holding data
	long nn : size of data array
	double *coefs :  the set of FIR filter coefficients, pre-calculated by calling function
	int ncoefs : the number of coefficients
	int shift : correct data for phase-shift? 0=NO, 1=YES, 2=YES+start-up padding (recommended)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	data array will be modified
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_FIRapply1_s"><a href="#CODE">&#8679</a> xf_filter_FIRapply1_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a Finite Impulse Response (FIR) filter to an array of data (short version)
	Overwrites input array
USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : input holding data
	long nn : size of data array
	double *coefs :  the set of FIR filter coefficients, pre-calculated by calling function
	int ncoefs : the number of coefficients
	int shift : correct data for phase-shift? 0=NO, 1=YES, 2=YES+start-up padding (recommended)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	data array will be modified
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_FIRapply2_f"><a href="#CODE">&#8679</a> xf_filter_FIRapply2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a Finite Impulse Response (FIR) filter to an array of input
	Separate input and output arrays (input preserved)
USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *input : array holding input
	double *ouput : array (pre-allocated) to hold onput
	long nn : size of input array
	double *input : input holding input
	double *coefs :  the set of FIR filter coefficients, pre-calculated by calling function
	int ncoefs : the number of coefficients
	int shift : correct data for phase-shift? 0=NO, 1=YES, 2=YES+start-up padding (recommended)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	output array will be overwritten
	char array will hold message (if any)

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_FIRcoef1"><a href="#CODE">&#8679</a> xf_filter_FIRcoef1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Calculate Finite Impulse Response (FIR) filter coefficients
	Derived from the Iowa Hills Software collection:

		Iowa Hills Software, LLC
		http://www.iowahills.com/5FIRFiltersPage.html
		November 19, 2014

	This implimentation:
		- combines multiple functions and header-definitions into a single function
		- assumes corection to coefficients based on accurate 3dB cutoffs is desired
		- currently only includes a single windowing option (Kaiser), or "none"


USES:
	Calculate Finite Impulse Response (FIR) filter coefficients

DEPENDENCIES (included here):
	void BasicFIR(double *FIRcoef, double *tempcoef, int NumTaps, int PassType, double OmegaC, double BW, int WindowType, double WinBeta);
	void FIRFreqError(double *Coeff, int NumTaps, int PassType, double *OmegaC, double *BW);
	double Goertzel(double *Samples, int N, double Omega);
	double Bessel(double x);
	double Sinc(double x) ;
	No dependencies

ARGUMENTS:
	int NumTaps      : desired number of taps for the filter - 3-256, 41 is typical, more taps = better filtering
	int PassType     : 1=LP, 2=HP, 3=BP, 4=notch
	double OmegaC    : corner (LP,HP) or central (BP, notch) frequency as a proportion of Pi (2.0 * Hz/samplerate)
	double BW        : bandwidth as a proportion of Pi (2.0 * Hz/samplerate)
	char *WindowType : none,kaiser,sinc
	double WinBeta   : 0-10, used for the Kaiser window
	char *message    : character array to hold message

RETURN VALUE:
	pointer to array of coefficients, or NULL on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_mingood2_f"><a href="#CODE">&#8679</a> xf_filter_mingood2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Invalidate sections of good data which fail a minimum length requirement
	This version is designed to deal with multi-channel input data
	float version

USES:
	- conditioning step before interpolating
	- apply a general QC to "intermittent" data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data0      input array martix, row=sample, column=channel
	size_t nn:        length of data0 array (number of rows, i.e. multi-channel samples)
	size_t nchan:     number of channels (columns)
	size_t mingood:   minimum number of sequential valid points required to pass filter
	float setbad:     bad-value to look for (e.g SHRT_MAX)
	char message[]:	  message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_mingood2_s"><a href="#CODE">&#8679</a> xf_filter_mingood2_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Invalidate sections of good data which fail a minimum length requirement
	This version is designed to deal with multi-channel input data

USES:
	- conditioning step before interpolating
	- apply a general QC to "intermittent" data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	short *data0      input array martix, row=sample, column=channel
	size_t nn:        length of data0 array (number of rows, i.e. multi-channel samples)
	size_t nchan:     number of channels (columns)
	size_t mingood:   minimum number of sequential valid points required to pass filter
	short setbad:     bad-value to look for (e.g SHRT_MAX)
	char message[]:	  message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_notch1_f"><a href="#CODE">&#8679</a> xf_filter_notch1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a notch (band-stop) filter to an array of numbers
		- this version modifies the input array

	Makes two passes at the data (forward & reverse) - eliminates time-shifting, and improves
	attenuation in the notch band. Also doesn't take any more time than copying the Y array back to X

	The function COULD be faster if reverse filtering was eliminated and Y was
	pre-allocated by the calling function and usedas the output instead of overwriting X,
	however the notch width would have to be widened to get comparable amplitudereduction, with
	concommittant loss of frequency specificity

	NOTE : interpolation should be applied first if needed to remove NANs or INFs
	NOTE : padding  & de-meaning the array can help remove effects from large
	       deflections at either edge of the data and data offset from zero

	Coefficient calculations based on principals in chapter 6 of
	Introductory Digital Signal Processing with Computer Applications (2nd Edition, 1994)
	By Paul A. Lynn and Wolfgang Fuerst

USES:
	Removal of 50 or 60 Hz mains noise from recorded signals

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *X:           array holding input to be filtered, fixed sample rate is assumed
	size_t nn:          length of X array
	float sample_freq:  sample frequency (samples per second)
	float notch_freq:     the frequency to by cut (Hz)
	float notch_width:    width of the stop-band (Hz)
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_filter_notch2_f"><a href="#CODE">&#8679</a> xf_filter_notch2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:

	Apply a notch (band-stop) filter to an array of numbers
		- this version does not modify original input array
		- consequently, it requires pre-allocation of memory for swap and output

	Makes two passes at the data (forward & reverse), to avoid time-shifting

	NOTE : interpolation should be applied first if needed to remove NANs or INFs
	NOTE : padding  & de-meaning the array can help remove effects from large
	       deflections at either edge of the data and data offset from zero

	Coefficient calculations based on principals in chapter 6 of
	Introductory Digital Signal Processing with Computer Applications (2nd Edition, 1994)
	By Paul A. Lynn and Wolfgang Fuerst

USES:
	Removal of 50 or 60 Hz mains noise from recorded signals

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *X:           array holding input to be filtered, fixed sample rate is assumed
	float *Y:           array reserved for swapping values, memory must be pre-allocated by calling function
	float *Z:           array reserved for filtered output, memory must be pre-allocated by calling function
	size_t nn:          length of X and Z arrays
	float sample_freq:  sample frequency (samples per second)
	float notch_freq:     the frequency to by cut (Hz)
	float notch_width:    width of the stop-band (Hz)
	char message[]:	    message indicating success or reason for failure

RETURN VALUE:
	0 on success, -1 on fail

</blockquote></pre>

<font color="Black"><h3 id="code-xf_fishertransform2_d"><a href="#CODE">&#8679</a> xf_fishertransform2_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Fisher transformation for an array of Pearson's correlation coefficients
	Simply the inverse hyperbolic function of each value
	see http://en.wikipedia.org/wiki/Fisher_transformation

	NOTE: a limit of +-3.8 is put on the transform, which is sufficient accuracy for
	correlation coefficients to a precision of 0.001

	NOTE: for type-2 correlations (range 0-1), this translates to a range of 0 to 7.6


USES:
	Allows hypothesis testing for population correlation coefficients

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : input array of data (will be transformed)
	long n : number of elements in the array
	int type :
		1: correlations can range from -1 to 1
		2: correlations can range from 0 to 1

RETURN VALUE: NONE

	Oringinal input data will be transformed

</blockquote></pre>

<font color="Black"><h3 id="code-xf_fishertransformrev2_d"><a href="#CODE">&#8679</a> xf_fishertransformrev2_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Reverse the Fisher transformation for an array of Pearson's correlation coefficients
	see http://en.wikipedia.org/wiki/Fisher_transformation

	NOTE: for type-2 correlations (range 0-1), this translates to a range of 0 to 7.6

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : input array of data (will be transformed)
	long n : number of elements in the array
	int type :
		1: correlations can range from -1 to 1
		2: correlations can range from 0 to 1

RETURN VALUE: NONE

	Oringinal input data will be transformed

</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_angle1_f"><a href="#CODE">&#8679</a> xf_geom_angle1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
        Calculate angle "A" based on length of sides a,b,c
	    B
	 c / \a
          /   \
         A-----C
            b
</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_dist1"><a href="#CODE">&#8679</a> xf_geom_dist1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Take two cartesian coordinates and return distance
</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_distangle"><a href="#CODE">&#8679</a> xf_geom_distangle</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Take two cartesian coordinates and return distance (result[0]) and angle (result[1])
</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_linear1_f"><a href="#CODE">&#8679</a> xf_geom_linear1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Return the linear equation for two Cartesian coordinates
	- equation: y= slope*x + intercept
	- result[0]= slope (or NAN for vertical lines)
	- result[1]= intercept (or NAN for vertical lines)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_offset1_d"><a href="#CODE">&#8679</a> xf_geom_offset1_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the vertical offset of a point from the line joining two flanking points

USES:
	- surrogate for amplitude or AUC
	- useful for detecting amplitude of "local" peaks

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double x1      : line-point1, x
	double y1      : line-point1, y
	double x2      : line-point2, x
	double y2      : line-point2, y
	double x3      : point, x
	double x3      : point, y
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	offset on success, NAN error
	char array will hold message (if any)

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_offset1_f"><a href="#CODE">&#8679</a> xf_geom_offset1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the vertical offset of a point from the line joining two flanking points

USES:
	- surrogate for amplitude or AUC
	- useful for detecting amplitude of "local" peaks

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float x1      : line-point1, x
	float y1      : line-point1, y
	float x2      : line-point2, x
	float y2      : line-point2, y
	float x3      : point, x
	float x3      : point, y
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	offset on success, NAN error
	char array will hold message (if any)

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_geom_slope2_f"><a href="#CODE">&#8679</a> xf_geom_slope2_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the minimum & maximum windowed-slope in a series

USES:
	- Charactorization of evoked responses, synaptic responses, etc

DEPENDENCIES:
	- No dependencies

ARGUMENTS:
	float *data     : input holding data
	long n1         : size of data array
	long winsize    : size of window (samples) across-which to estimate slope
	double interval : units spanned by each sample, = 1/samplerate
	int test	: test to apply, to ignore a window or break
		0= none
		-1= ignore negative slopes
		1= ignore positive slopes
		-2= stop seeking on first positive slope
		2= stop seeking on first positive slope
		-3= stop seeking when slope starts getting more negative
		3= stop seeking when slope starts getting more positive
	double min	: the smallest (most negative) slope
	double max      : the largest (most positive) slope
	char *message : arrray to hold message in the event of an error

RETURN VALUE:
	success: number of slope estimates taken
	fail: -1, message[] will hold information
	min and max will be updated
</blockquote></pre>

<font color="Black"><h3 id="code-xf_getheader1"><a href="#CODE">&#8679</a> xf_getheader1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>DESCRIPTION:
	Extract an ASCII header from an ASCII or binary file
	- assumes the header ends in a keyword
	- stored header will include the keyword

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile  : the name of the input file (or "stdin")
	char *keyword : the keyword markning the end of the header
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	on sucess:  A pointer to the header - must be freed by calling function or main
	on failure: NULL
	char array will hold message (if any)

SAMPLE CALL:
	char *header=NULL,message[256];
	header= xf_getheader1(data.wfm,"WAVES_START",message );
	ifheader!=NULL) printf("%s\n",header);
	else { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_getindex1_d"><a href="#CODE">&#8679</a> xf_getindex1_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the index to a list-element given the min, max and number of elements
	Assumes elements in list are evenly spaced (eg. a series of timestamps)

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double min     : smallest value in series
	double max     : largest value in series
	long n         : number of elements in the series
	double value   : value to return the index to (will be rounded down to nearest integer)
	char *message  : pointer to pre-allocated array to hold error message if any

RETURN VALUE:
	index, or -1 on error

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_hist1d"><a href="#CODE">&#8679</a> xf_hist1d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Build a histogram (double *histx, double *histy) from an array of data data (double *data)

USES:
	Typically used in conjunction with xf_wint1, which can produce the data values necessary for the histogram

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : array of data data to generate histogram
	int n : size of the array
	double *histx : result-array, x-axis values for histogram - NOTE! must be initialised by calling function
	double *histy : result-array, y-values for histogram - NOTE! must be initialised by calling function
	int bintot : total number of bins in the histogram
	double min : define bottom of the data range - NOTE than min itself will also be included
	double max : define top of the data range - NOTE than max itself will also be included
	int format : the format of the histogram - 1=counts, 2=proportion (peak=1), 3=probability (sum of values=1)

RETURN VALUE:
	A long integer, the final number of data points in the modified histy array.
	This may be less than the original value of n, depending on the min and max settings

	The main result is modification of the histx and histy arrays, which will hold the values
	necessary to generate a histogram plot. Note that the values in the histx array
	will correspond with the middle of each bin, not the start.

SAMPLE CALL:
	int g1=1, g2=2;
	long ii,jj,kk,nn,result_l[32],nintervals;
	float winsize=0.01;
	double time[1001],group[1001],*intervals=NULL;
	// time and group data must be stored in memory first

	// find the intervals between events of class g1 and g2
	intervals= xf_wint1(time,group,n,g1,g2,winsize,result_l);  nintervals=result_l[0];

	// now generate values for the histogram
	xf-histd1(intervals,nintervals,histx,histy,100,-.05,.05,1) // 100ms wide histogram with 100 bins

</blockquote></pre>

<font color="Black"><h3 id="code-xf_hist1_l"><a href="#CODE">&#8679</a> xf_hist1_l</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Build a histogram (double *histx, double *histy) from an array of data (long *data)

USES:
	Typically used in conjunction with xf_wint1_l, which can produce the data values necessary for the histogram

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *data    : input array used to generate histogram
	int nn        : size of the array
	double *histx : result-array, x-axis values for histogram - NOTE! must be initialised by calling function
	double *histy : result-array, y-values for histogram - NOTE! must be initialised by calling function
	long bintot   : total number of bins in the histogram
	long min      : define bottom of the data range - NOTE than min itself will also be included
	long max      : define top of the data range - NOTE than max itself will also be included
	int format    : the format of the histogram - 1=counts, 2=proportion (peak=1), 3=probability (sum of values=1)

RETURN VALUE:
	Successs: the final sum of values in the modified histy array.
		- This may be less than the original value of nn, depending on the min and max settings
		- Modified histx and histy arrays, which will hold the histogram values
		- NOTE: values in histx[] represent the middle of each bin, not the start

SAMPLE CALL:
	long ii, g1=1, g2=2, winsize=1000, nintervals, bintot=100, min=-500, max=500;
	long time[1001],group[1001],*intervals=NULL;
	double histx[100],histy[100];
	// time and group data must be stored in memory first
	....
	// find the intervals between events of class g1 and g2
	intervals= xf_wint1_l(time,group,n,g1,g2,winsize,&nintervals);
	// now generate values for the histogram
	xf-hist1_l(intervals,nintervals,histx,histy,bintot,min,max,3);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_histburst1_d"><a href="#CODE">&#8679</a> xf_histburst1_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate burstiness in a histogram
	Adapted from xf_histbursty1d, John Huxter: 7 February 2011

	1. histogram is downsampled to 50bins focussed on the +-50ms zone
	2. this histogram is smoothed with a 10ms Gaussian kernel (central bin +-2 bins)
	3. cubic spline interpolation is used to up-sample to 200 bins
	4. the first positive inflection at time greater-than-zero is identified
	5. the time at which this peak drops to 75% amplitude is identified
		- this is a measure of the rate of falloff in the histogram
	6. this dropoff time is normalized to the potential time at which it could have occurred


	Important assumptions regarding the input histogram:
		- should range from -0.05 to +0.05 s (+-50ms)
		- must have at least 0.5 bins per ms - so a +-50ms window should have at least 50 bins
		- y-values in the histogram can be counts or probabilities - it shouldn't matter - but the array must be a double-float

		NOTE: scores based on fewer than 50 spikes in the histogram tend to be unreliable
		NOTE: a "bursty" cell should ideally have a peak-time less than 0.012s and a burstiness score &#62 0.75?

USES:

DEPENDENCIES:
	xf_bin1a_d
	xf_round1_d
	xf_smoothgauss1_d
	xf_spline1_d

ARGUMENTS:
	double *histx1 : input histogram x-values (typically time in seconds)
	double *histy1 : input histogram y-values (typically spike-counts)
	long nbins1    : number of x/y pairs in the histogram
	double *result_d : pre-allocated array to hold results - must allow at least 3 elements
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success
	-1 on warning (eg. no peak in the histogram)
	-2 error related to input histogram or parameters
	-3 fatal memory allocation error

	result array will hold statistics
	char array will hold message (if any)

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_histratio1_d"><a href="#CODE">&#8679</a> xf_histratio1_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Determine the ratio of events in two symmetrical zones of a histogram
	Originally based on xf_histrefract1_d (February 2009 [JRH])
	- however in this version zero itself contributes to the negative and positive sums (zero is special)

USES:
	- determine refractoriness of cell-firing to asess quality of spike-sorting
		- neurons have a 2ms refractory period
		- typically we compare the proportion of spikes in a +-15ms window falling within a +-2ms zone
		- focusing on the inner +-15ms of the histogram ensures that bursty and non-bursty cells are treated similarly
		- a ratio of &#620.08 should be used to automatically reject a histogram
		- a ratio of &#600.01 represents an exceptionally clean refractory period
		- NOTE: bintot must be such as to allow at least 1ms precision (eg. 100 bins convering a 100ms range)
		- NOTE: 50-75 spikes are required in the +-15ms window to make a good decision
		- NOTE: for asymmetrical histograms (e.g. cross-corelograms) good estimates require 35-50 spikes in any half

	- autocorrelograms:
		- determine the quality of cell isolation
		- estimate of burst-firing
	- cross-correlograms:
		- monosynaptic coupling

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *histx  : input array, histogram timestamps (seconds)
	double *histy  : input array, histogram values (typically spike-counts, but doubles allowed)
	long bintot    : number of bins in the input histogram
	double z1:     : the reference zone (seconds: typically 0.015)
	double z2:     : the comparison zone (seconds: typically 0.002) - should be smaller than zone1!
	double *result : output array, must allow at least 5 elements

RETURN VALUE:
	: the proportion of zone1 events occurring in zone2
	: -1 if there are no events in zone2

</blockquote></pre>

<font color="Black"><h3 id="code-xf_histratio2_d"><a href="#CODE">&#8679</a> xf_histratio2_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate statistics relating to the refractoriness of an auto- or cross-corellogram
	of the spiking for a cell or cell-pair. That is, the tendency for the +-2ms period in
	the middle of the histogram to be empty while the rest of the histogram is populated.
	This occurs because most neurons cannot fire 2 action potentials within 2ms.

	Modification of original code (calc_srefractoriness) written by Andrew Macpherson of PrismTC, August 2010
	Successor to xf_histrefract2_d (2017.02.15)

ARGUMENTS:
	double histy      : input, pointer to array containing histogram counts
	long nbins_tot    : number of bins used for histogram
	long nbins_c      : size of refractory period (bins, typically corresponding to 2ms)
	long nbins_s      : size of zone outside refractory period for comparison
	double *result_d  : results array (must be preallocated to hold 40 items)
				- diff: difference between the mean event-counts, central versus side
				- ratio: centre/(centre+side) - range 0-1, expected value depends on "nbins_c" & "nbins_s"
				- t-statistic: one-sided, based on diff, should be +ive if refractoriness exists
				- probability for the t-statistic

	char *message     : errort message (if any)

RETURN VALUE:
	- success: histogram total for the regions of interest (centre + left + right)
	- error: -1

SAMPLE CALL:
	refract = xf_histratio3_d(histy,100,2,8,result_d,message);
	- this assumes a 100 bin histogram, presumably covering a range of +-50ms (so 1ms per bin)
	- the refractory period is set as 2ms, so bins 48,49,50 &51 will constitute the refractory zone (+-2ms)
	- the comparison zone is the next 8 bins outside the refractory zone
		- for the left hand side, bins 40-47 (-10 to -3 ms)
		- for the right hand side, bins 52-59 (3 to 10 ms)


</blockquote></pre>

<font color="Black"><h3 id="code-xf_histrefract1_d"><a href="#CODE">&#8679</a> xf_histrefract1_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Determine simple refractoriness in a histogram (% of spikes in +-2ms vs +-15ms window)

USES:
	Appropriate for making QC decisions on autocorrelograms for spike firing of a given neuron

DEPENDENCY TREE:
	None

ARGUMENTS:
	double *tsec   : input, array of timestamps for histogram (seconds)
	double *val    : input, array of values for histogram (counts, typically, but could be proportion or probability)
	long bintot    : input, the number of tsec and val pairs comprising the histogram
	double *result : input, array of values representing the result - memory must be allocated by calling function
		result[0]= proportion (0-1) of 0-2ms spikes in the 0-15ms zone
		result[1]= proportion (0-1) of 0-2ms spikes in the total histogram
		result[2]= spike count in negative 0-15ms window
		result[3]= spike count in positive 0-15ms window
		result[4]= spike count in negative 0-2ms window
		result[5]= spike count in positive 0-2ms window
		result[6]= total spike count in histogram

RETURN VALUE:
	none

NOTES:
	Focusing on spikes within +-15ms of reference spike ensures that bursty and non-bursty cells are treated similarly

	A ratio of &#620.08 should be used to automatically reject a histogram
	A ratio of &#600.01 represents an exceptionally clean refractory period

	Total number of bins (bintot) must allow at least 1ms precision in calculation of times
	50-75 spikes are required in the 30ms window to make a good decision
		- however, it would also suffice if half the histogram has 35-50 spikes


</blockquote></pre>

<font color="Black"><h3 id="code-xf_histtheta1d"><a href="#CODE">&#8679</a> xf_histtheta1d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	John Huxter: 20 January 2011
	Calculate theta-modulation in a histogram
		- looks for negative and positive inflections
		- histogram should be smoothed and spline-interpolated first
		- histogram should be normalized to range from 0-1
</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp3_d"><a href="#CODE">&#8679</a> xf_interp3_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform linear interpolation across invalid data points
	- modifies the original array
	- expects NAN or INF to be used to designate invalid values
	- blocks of invalid numbers at top and bottom of record are filled with first and last valid datum, respectively

USES:
	Fill in gaps in an array of data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : array already holding the data
	long ndata : number of elements in the data array

RETURN VALUE:
	total points interpolated across
	-1: no valid data found

SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp3_f"><a href="#CODE">&#8679</a> xf_interp3_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform linear interpolation across invalid data points
	- modifies the original array
	- expects NAN or INF to be used to designate invalid values
	- blocks of invalid numbers at top and bottom of record are filled with first and last valid datum, respectively

USES:
	Fill in gaps in an array of data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data : array already holding the data
	long ndata : number of elements in the data array

RETURN VALUE:
	total points interpolated across
	-1: no valid data found

SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp3max_f"><a href="#CODE">&#8679</a> xf_interp3max_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform conditional linear interpolation across invalid data points
	- this version also allows user to specify the maximum number of values to interpret across
	- modifies the original array
	- expects NAN or INF to be used to designate invalid values
	- blocks of invalid numbers at top and bottom of record are filled with first and last valid datum, respectively

USES:
	Fill in gaps in an array of data, but not gaps which are too large

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data : array already holding the data
	long ndata  : number of elements in the data array
	long max    : maximum number of points to interpolate across, -1 = no limit

RETURN VALUE:
	total points interpolated across
	-1: no valid data found

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp4_d"><a href="#CODE">&#8679</a> xf_interp4_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform linear interpolation across invalid data points (double)
	- user specifies the invalid value to interpolate across
	- modifies the original array
	- invalid numbers at the start/end of the input can be filled with first/last valid datum, respectively

USES:
	fill in gaps in an array of data

DEPENDENCIES: none

ARGUMENTS:
	double *data  : input, array
	long ndata    : input, length of input array
	short invalid : invalid value for interpolation (typically FLOAT_MIN or FLOAT_MAX)
	int setfill   : edge-fill invalid values with nearest valid (0=none,1=start,2=end,3=both
	result[3]     : result indices
		result[0] = index to first good value (will be 0 if startsetfill is set)
		result[1] = index to last good value (will be ndata-1 if endsetfill is set)
		result[2] = total interpolated points

RETURN VALUE:
	0: success
	1: fail - no good data

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp4_f"><a href="#CODE">&#8679</a> xf_interp4_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform linear interpolation across invalid data points (float)
	- user specifies the invalid value to interpolate across
	- modifies the original array
	- invalid numbers at the start/end of the input can be filled with first/last valid datum, respectively

USES:
	fill in gaps in an array of data

DEPENDENCIES: none

ARGUMENTS:
	float *data   : input, array
	long ndata    : input, length of input array
	short invalid : invalid value for interpolation (typically FLOAT_MIN or FLOAT_MAX)
	int setfill   : edge-fill invalid values with nearest valid (0=none,1=start,2=end,3=both
	result[3]     : result indices
		result[0] = index to first good value (will be 0 if startsetfill is set)
		result[1] = index to last good value (will be ndata-1 if endsetfill is set)
		result[2] = total interpolated points

RETURN VALUE:
	0: success
	1: fail - no good data

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_interp4_s"><a href="#CODE">&#8679</a> xf_interp4_s</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform linear interpolation across invalid data points (short integer)
	- user specifies the invalid value to interpolate across
	- modifies the original array
	- invalid numbers at the start/end of the input can be filled with first/last valid datum, respectively

USES:
	fill in gaps in an array of data

DEPENDENCIES: none

ARGUMENTS:
	short *data   : input, array
	long ndata    : input, length of input array
	short invalid : invalid value for interpolation (typically SHRT_MIN or SHRT_MAX)
	int setfill   : edge-fill invalid values with nearest valid (0=none,1=start,2=end,3=both
	result[3]     : result indices
		result[0] = index to first good value (will be 0 if startsetfill is set)
		result[1] = index to last good value (will be ndata-1 if endsetfill is set)
		result[2] = total interpolated points

RETURN VALUE:
	0: success
	1: fail - no good data

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_jitter1_d"><a href="#CODE">&#8679</a> xf_jitter1_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Create a set of jittered x-values to apply to an input set of y-values

USES:
	Apply jitter to x-values in grouped data so points don't overlap in plot

DEPENDENCIES:
	xf_rand1_d

ARGUMENTS:
	double *yval  : input array, mean used for defining scaling for jitter
	long nn       : number of input/output items
	double centre : centre-value for result
	double limit  : limit for deviation from centre-value (absolute value)
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	pointer to array on success, NULL on error
	message array will hold explanatory text (if any)

SAMPLE CALL:
	long ii,nn=100;
	double *xval=NULL, yval[100];
	char message[1000],*thisprog="test\0";

	for(ii=0;ii&#60nn;ii++) yval[ii]= (double)ii;
	xval= xf_jitter1_d(yval,nn,5,0.25,message);
	if(xval==NULL) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	for(ii=0;ii&#60nn;ii++) printf("%g\t%g\n",xval[ii],yval[ii]);

&#60TAGS&#62 math &#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_kissfft1"><a href="#CODE">&#8679</a> xf_kissfft1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Perform a fast Fourier transfer on a time-series

USES:

DEPENDENCY TREE:

ARGUMENTS:

RETURN VALUE:

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_linecomment1"><a href="#CODE">&#8679</a> xf_linecomment1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Return the comment-status of an input line

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *line : input, pointer to a character array
	int &skip  : current status of skip
			: initialize to zero for first time the function is called
			: allows commenting to be carried over from previous lines contiaining a quote or /*
RETURN VALUE:
	Always zero

TEST PROGRAM:

	skip=0;
	while(fgets(line,MAXLINELEN,fpin)!=NULL) {
		xf_linecomment1(line,&skip);
		printf("%s",line);
	}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_lineparse1"><a href="#CODE">&#8679</a> xf_lineparse1</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Modify a line, parsing it into whitespace-delimited words, and modify an array of indices to each word

	The variable "nwords" will be modified to reflect the number of words on the line
	The "line" array will be modified, each white-space delimiter replaced by a NULL character

	NOTE:
		multiple whitespace is treated as a single whitespace, so "empty"
		words in a line will affect the index to all subsequent columns.
		Example: if the input file looks like this...
				a	b	c
				a		c

		... then word#2 will be "b" on line#1, but "c" on line#2

	NOTE:
		Leading white-space will insert a NULL at the beginning of the line,
		but start[0] will point to the first non-whitespace character on the line.
		This can be handy in space-delimited files where leading white-space signifies an empty field
		This can be detected using strlen(line), as opposed to strlen((line+start[0]))


	NOTE (4.November.2016)
		Text within quotes will be treated as a single word
		single-quotes within double-quotes (or vice-versa) will not trigger the start/end of quoted text
		Hence "don't exit" will be treated as a single word, the internal space and single-quote ignored
		- additional updates: new variable names, better use of memory


USES:
	provides a set of indices  to each column in a line
	advantage over strtok: finds all words in a line at once, COULD be modified to treat each delimiter as a separate word
	disadvantages over strtok: not as fast

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *line
		- input, pointer to a character array
	long *nwords
		- address to a long integer to hold the total number of words found

RETURN VALUE:

	Success: A pointer to a long-integer array holding the start locations of each word in line
		- memory is allocated for this array inside the function
		- the variable nwords will be updated to report the number of delimited words on the line

	Blank line: NULL, nwords=0;
	Memory allocation fail: NULL, nwords=-1


TEST PROGRAM:

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62

	long *start=NULL,nwords,i;
	char line[13]={"dog cat pig"};

	start= xf_lineparse1(line,&nwords);

	for(i=0;i&#60nwords;i++) printf("%s\n",line+start[i]);

	if(start!=NULL) free(start);
	exit(0);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_lineparse2"><a href="#CODE">&#8679</a> xf_lineparse2</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Modify a line, parsing it into delimited words, and modify an array of indices to each word
	Behaves much like the linux "cut" command
		- unlike strtok, serial delimiters are not treated as a single delimiter
		- hence two consecutive delimiters, or delimiters at the beginning or end of the line, signify a missing word
		- note: using strtok to identify words in a line is faster, but strtok is not appropriate for CSV files

USES:
	provides a set of indices to each column in a line
	suitable for reading particular columns from CSV files or other ASCII files where "blank" fields are possible


DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *line
		- input, pointer to a character array
	char *delimiters
		- input, delimiter characters to consider
	long *nwords
		- address to a long integer to hold the total number of words found

RETURN VALUE:

	Success: A pointer to a long-integer array holding the start locations of each word in line
		- memory is allocated for this array inside the function
		- the variable nwords will be updated to report the number of delimited words on the line
	Blank line: NULL, nwords=0;
	Memory allocation fail: NULL, nwords=-1

TEST PROGRAM:

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62
	long *start=NULL,nwords,i;
	char line[13]={"dog cat pig"};

	start= xf_lineparse2(line,"\t ",&nwords);

	for(i=0;i&#60nwords;i++) printf("%s\n",line+start[i]);
	if(start!=NULL) free(start);
	exit(0);

???TO DO: may be able to improve using search method more like lineparse1 (simple serial scan)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_lineread1"><a href="#CODE">&#8679</a> xf_lineread1</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	A safer version of fgets to read a line of unknown length from an ASCII file
	For files with lines ~ 4000 characters wide, read time is about 80% the speed of fgets alone
	Uses fgets and concatenates the results to the variable "line"
	Characters are read in buffers of length XF_LINEREAD1_BUFFSIZE (typically 1000)
		- If buffer length is less than the length of the line being read, multiple calls to fgets are made
		- the function checks if the buffer contains a newline - if so further calls to fgets are halted

	Memory reserved for "line" is expanded as required
	Blank lines are correctly returned
	Lines without a terminating newline are correctly returned
	Input must be NULL-terminated

	Last update: 18 February 2013 [JRH]

USES:

	Situations where fgets is inappropriate because maximum line length is unknown
	Example - reading large tables or matrices of data

DEPENDENCY TREE:

	No dependencies

ARGUMENTS:

	char *line
		- pointer to a character array
		- new memory will be allocated and will be overwritten
	long *maxlinelen
		- variable holding the most recent value for maxmimum line length
		- updated with the actual length of the line, if this exceeds the initial value
		- the calling function should pass the address (&) of the variable, function will read as a pointer (*)
		- if maxlinelen is set to "-1", this indicates a memory allocation error occurred
	FILE *fpin
		- pointer to input stream (typically a file or stdin)
		- updated by the function

RETURN VALUE:

	A pointer to a character array holding the new line - NULL if no line was read

TEST PROGRAM:

		// save function as xf_lineread1.c
		// save as "xe-test.c" in same folder as xf_lineread1.c
		// compile as follows: gcc -O3 -std=gnu99 xe-test.c xf_lineread1.c -o xe-test)

		#include &#60stdio.h&#62
		#include &#60stdlib.h&#62

		char *xf_lineread1(char *line, long *maxlinelen, FILE *fpin);

		int main (int argc, char *argv[]) {
			char *line=NULL,*pline;
			long maxlinelen=0;
			FILE *fpin;
			if(argc&#602) { fprintf(stderr,"USAGE: xe-test [filename] \n"); exit(0); }
			fpin=fopen(argv[1],"r");
			if(fpin==0) { fprintf(stderr,"File read error\n"); exit(1); }

			while((pline= xf_lineread1(line,&maxlinelen,fpin) )!=NULL) {
				if(maxlinelen&#600) { fprintf(stderr,"Memory allocation error\n"); exit(1); }
				else printf("%s",pline);
			}
			fclose(fpin);
			fprintf(stderr,"\nlongest line: %d characters\n",maxlinelen);
			if(line!=NULL) free(line);
		}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_linereadblock1"><a href="#CODE">&#8679</a> xf_linereadblock1</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Read a block of data replicates in which specfied key-columns do not change
	- blank lines will be ignored
	- Each call extracts a single block of data
		- the unchanging key-values
		- an array of "repeated-measures" values which are allowed to change within the block
		- an array of data for the block
	- Can be called multiple times until the end of the file is reached
	- 6.May.2019 [JRH]

DEPENDENCIES:
	xf_lineparse2

ARGUMENTS:
	long *par : array of control and results parameters
		par[0] status (output): set to -9 for first call, so function initialises keyprev[]
		par[1] ndata (output): number of data-points extracted
		par[2] nkeys (input): the number of key-colmns
		par[3] repcol (input): column-number holding the repeated-measures values
		par[4] datcol (input): column-number holding the data-values
		par[5] maxdat (input): maximum allowable size of the block
	double *keycurr  : output[nkeys] of current key-values
	double *keyprev  : input[nkeys] of key-values from previous call - use par[0]=-9 to initialize
	long *keycol     : input[nkeys] to hold the column-numbers
	double *rep1     : output[maxdat], repeated-measures-values for the block
	double *dat1     : output[maxdat], data for the block
	FILE *fpin       : file-pointer to input stream - files or stdin
	char *message 	 : pre-allocated array to hold error message

RETURN VALUE: none
	- prams[0] (status) will be updated:
		&#600: error (check contents of message)
		 0: end-of-file
		 1: block read successfully, there may be more
	- par[1] will contain the number of datapoints in the extracted block
	- keycurr[nkeys] will contain the fixed key-values for the block
	- keyprev[nkeys] will contain the fixed key-values for the block

TEST PROGRAM:
	nkeys= 3;
	maxdat= 1000;
	keycurr= malloc(nkeys*sizeof(*keyprev));
	keyprev= malloc(nkeys*sizeof(*keyprev));
	rep1= malloc(maxdat*sizeof(*rep1));
	dat1= malloc(maxdat*sizeof(*dat1));

	keycol[0]=5;keycol[1]=6;keycol[2]=7;
	par[0]=-9; par[1]=0; par[2]=nkeys; par[3]=repcol; par[4]=datcol; par[5]=setmaxdat;

	if(strcmp(infile,"stdin")==0) fpin=stdin;
	else if((fpin=fopen(infile,"r"))==0) {fprintf(stderr,"\n--- Error[%s]: file \"%s\" not found\n\n",thisprog,infile);exit(1);}
	while(++nn) {
		xf_linereadblock1(par,keycurr,keyprev,keycol,rep1,dat1,fpin,message);
		status= par[0]; ndata= par[1];
		if(status&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		for(ii=0;ii&#60ndata;ii++) {
			for(jj=0;jj&#60nkeys;jj++) printf("%g\t",keyprev[jj]);
			printf("%f\t%f\n",rep1[ii],dat1[ii]);
		}
		printf("\n");
		if(status==0) break; // end of file
		if(status==1) for(ii=0;ii&#60nkeys;ii++) keyprev[ii]= keycurr[ii];
	}
	if(strcmp(infile,"stdin")!=0) fclose(fpin);

&#60TAGS&#62file database&#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_lombscargle"><a href="#CODE">&#8679</a> xf_lombscargle</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Purpose
	=======
	Computes the Lomb-Scargle periodogram as developed by Lomb (1976)
	and further extended by Scargle (1982) to find, and test the
	significance of weak periodic signals with uneven temporal sampling.

	This subroutine calculates the periodogram using a slightly
	modified algorithm due to Townsend (2010) which allows the
	periodogram to be calculated using only a single pass through
	the input samples.
	This requires Nw(2Nt+3) trigonometric function evaluations (where
	Nw is the number of frequencies and Nt the number of input samples),
	giving a factor of ~2 speed increase over the straightforward
	implementation.

	Arguments
	=========
	t(input) double precision array, dimension (Nt)	
	 Sample times

	x(input) double precision array, dimension (Nt)
	 Measurement values

	w(input) double precision array, dimension (Nt)
	 Angular frequencies for output periodogram

	P(output) double precision array, dimension (Nw)
	 Lomb-Scargle periodogram

	Nt (input) integer
	 Dimension of input arrays

	Nw (output) integer
	 Dimension of output array

	Further details
	===============

	P[i] takes a value of A^2*N/4 for a harmonic signal with
	frequency w(i).
</blockquote></pre>

<font color="Black"><h3 id="code-xf_mae1_f"><a href="#CODE">&#8679</a> xf_mae1_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate mean absolute error (MAE) between two series, corrected by the range of series-1
	Less sensitive to ourliers than RMSE
	https://en.wikipedia.org/wiki/Mean_absolute_error
USES:
	Estimate the goodness of fit between two lines
DEPENDENCIES:
	None
ARGUMENTS:
	float *data1 : input array representing values for line #1
	float *data2 : input array representing values for line #2
	long nn : number of elements in each array
	double *result : pre-allocated array to hold results - must allow at least 6 elements
	char *message : pre-allocated array to hold error message
RETURN VALUE:
	MAE on success, INF on horizontal line for NAN on error
	char array will hold message (if any)
SAMPLE CALL:
	mae= xf_mae1_d(data1,data2,nn,message);
	if(!isfinite(mae)) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_matchclub1_ls"><a href="#CODE">&#8679</a> xf_matchclub1_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	- remove clusters from a club/t record which do not match the ID's specified in a list

USES:
	- reducing the size of a cluster record to make processing more efficient

DEPENDENCY TREE:
	long *xf_lineparse2(char *line,char *delimiters, long *nwords);

ARGUMENTS:
	char *list1 : pointer to CSV list of clusters to keep
	long *clubt : input array of cluster timestamps
	short *club : input array of cluster-IDs
	long nn     : total number of items in the clubt[] and club[]
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	on success:
		- the new number of clubt[] and club[] records
		- the clubt[] and club[] arrays themselves will be adjusted accordingly
	on failure:
		-1

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixavg1_d"><a href="#CODE">&#8679</a> xf_matrixavg1_d</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the average matrix from a multi-matrix array
	John Huxter - 4.March.2012
USES:
	Creating averages of 2-dimensional arrays - eg. density maps

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *multimatrix
		- input array already holding data for multiple matrices to be averaged
		- NOTE: values for each matrix should be normalized first
	int n_matrices
		- number of matrices
	long bintot
		- number of cells in each matrix
	char message[]
		- holds error message or other report
		- recommended pre-allocation of memory by calling function (eg. char message[256])

RETURN VALUE:
	A pointer to an array (newmatrix) of type double with xbins*ybins elements
	This variable must be initialized by the calling function and assigned value NULL
	This function will handle assigning sufficient memory
	If a memory allocation error occurs, a NULL is returned

SAMPLE CALL:

	new= xf_matrixavg1_d(multimatrix,nmatrices,bintot,message);

	if(new==NULL) {fprintf(stderr,"--- Error: %s\n",message) ; exit(1);}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixavg1_f"><a href="#CODE">&#8679</a> xf_matrixavg1_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the average matrix from a multi-matrix array
	John Huxter - 4.March.2012
USES:
	Creating averages of 2-dimensional arrays - eg. density maps

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *multimatrix
		- input array already holding data for multiple matrices to be averaged
		- NOTE: values for each matrix should be normalized first
	size_t n_matrices
		- number of matrices
	size_t bintot
		- number of cells in each matrix
	char message[]
		- holds error message or other report
		- recommended pre-allocation of memory by calling function (eg. char message[256])

RETURN VALUE:
	A pointer to an array (newmatrix) of type double with xbins*ybins elements
	This variable must be initialized by the calling function and assigned value NULL
	This function will handle assigning sufficient memory
	If a memory allocation error occurs, a NULL is returned

SAMPLE CALL:

	new= xf_matrixavg1_f(multimatrix,nmatrices,bintot,message);

	if(new==NULL) {fprintf(stderr,"--- Error: %s\n",message) ; exit(1);}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixbin1_d"><a href="#CODE">&#8679</a> xf_matrixbin1_d</h3></font>
[<a href="#tag-filter">filter</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Downsize an input array representing a 2D matrix to a new width and heght
	Alters the input array
	NAN and INF values will be ignored
	This function has no memory overhead

USES:
	- resampling an image or matrix to reduce resolution
	- modifying different matrices so they are all the same size

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *matrix1 : input array
	long nx1        : width of input
	long ny1        : height of input
	long nx2        : desired width
	long ny2        : desired height
	char *message   : array to hold error message

RETURN VALUE:
	0 on sucess, -1 on error

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixcoh1_d"><a href="#CODE">&#8679</a> xf_matrixcoh1_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the spatial coherence of a matrix
	- how well does one bin rate predict the 8 neighbouring bins
	- coherence = z-transform of correlation between each matrix element and the mean of surrounding elements
	- non-finite elements will be ignored

USES:

DEPENDENCIES:
	double  xf_correlate_simple_d(double *x, double *y, long nn, double *result_in);

ARGUMENTS:
	double *rate       : the input matrix array
	long width         : matrix width (number of elements)
	long height        : matrix height (number of elements)
	double *result_out : pre-allocated array to hold results (16-elements)
	char *message      : pre-allocated array to hold error message, if any

RETURN VALUE:
	- the spatial coherence in the matrix, or NAN on error
	- result array will hold additional statistics
		result_out[0]=

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixcontig1_l"><a href="#CODE">&#8679</a> xf_matrixcontig1_l</h3></font>
[<a href="#tag-matrix">matrix</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	- invalidate (set to zero) matrix bins not adjacent to other non-zero bins
	- designed for long-integer matrix arrays recording counts of events

USES:
	- allow programs to ignore isolated bins in a map

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *matrix1   : input, preallocated array matrix (counts)
	long setxbintot : input, width of array
	long setybintot : input, height of array
	long setcontig  : input, minimum adjacent non-zero bins required to keep a bin (must be 0-8)
	char *message   : output pre-allocated array to hold error message


RETURN VALUE:
	status flag (0=OK, -1=ERROR)
	matrix1 array will be overwritten
	message array will hold message (if any)

SAMPLE CALL:
	long matrix[15];
	width=3; height=5;
	z= xf_matrixcontig1_l(matrix,width,height,1,message);
	if(z=-1)  { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixexpand1_d"><a href="#CODE">&#8679</a> xf_matrixexpand1_d</h3></font>
[<a href="#tag-matrix">matrix</a>][<a href="#tag-transform">transform</a>]<br>
<blockquote><pre>DESCRIPTION:
	Expand an array of numbers representing a 2D matrix
	Rows and columns are duplicated to achieve the user-specified height and width
	NAN values will be ignored, but INF will affect the results
	Input array is unaltered
	NOTE: this function requires additional memory equivalent to at least the input array size

USES:
	- resampling an image or matrix to increase resolution
	- modifying different matrices so they are all the same size

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *matrix1 : input array
	long nx1        : width of input
	long ny1        : height of input
	long nx2        : desired width
	long ny2        : desired height
	char *message   : array to hold error message


RETURN VALUE:
	Pointer to modified matrix - NULL on error

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixflipx_d"><a href="#CODE">&#8679</a> xf_matrixflipx_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Flip a matrix in the y-dimaension

	Example: this matrix...

	0	1	2	3
	4	5	6	7
	8	9	10	11

	... will be flipped to ...

	3	2	1	0
	7	6	5	4
	11	10	9	8


USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *data1 : pointer to array of numbers representing the original matrix
				- sufficient memory must be allocated by calling program
				- this original memory will be freed
	long nx       : width of the matrix
	long ny       : height of the matrix
				- width and height must accurately reflect the total size of the data1 array

	NOTE: width and height are not swapped by this function, so if the calling function uses these
	variables after transposition, it is the responsibility of the calling function to do the swap

RETURN VALUE:

	A pointer to a FLIPPED version of the original numbers
	Returns NULL if a memory allocation error was encountered


SAMPLE CALL :
		matrix= xf_matrixflipx_d(matrix, width, height);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixflipy_d"><a href="#CODE">&#8679</a> xf_matrixflipy_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Flip a matrix in the y-dimaension

	Example: this matrix...

	0	1	2	3
	4	5	6	7
	8	9	10	11

	... will be flipped to ...

	8	9	10	11
	4	5	6	7
	0	1	2	3


USES:
	- converting cartesian to plotting coordinates or vice-versa

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *data1 : pointer to array of numbers representing the original matrix
				- sufficient memory must be allocated by calling program
				- this original memory will be freed
	long nx       : width of the matrix
	long ny       : height of the matrix
				- width and height must accurately reflect the total size of the data1 array

	NOTE: width and height are not swapped by this function, so if the calling function uses these
	variables after transposition, it is the responsibility of the calling function to do the swap

RETURN VALUE:

	A pointer to a FLIPPED version of the original numbers
	Returns NULL if a memory allocation error was encountered


SAMPLE CALL :
		matrix= xf_matrixflipy_d(matrix, width, height);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixpeak1_d"><a href="#CODE">&#8679</a> xf_matrixpeak1_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	- define a peak-zone of contiguous values exceeding a threshold in a 2D matrix
	- peak propogates out in an expanding radius from the highest un-masked element exceeding the threshold
	- propogation diagonally is prevented
	- simplified version of the old hux_findspot function

USES:
	- define a hippocampal place field
	- find a bright spot in a video frame
	- define a peak in a phase-amplitude coupling plot

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data1  : input array holding a matrix of values in which peak zone is to be found
	int *mask      : input/output array initialized by calling function and used to report peak detection
	long width     : width of the matrix
	long height    : height of the matrix
	float thresh   : minimum threshold to be exceeded for inclusion in the peak zone
	double *result : array initialized by calling function to hold results

	Regarding the mask array:
		- presumed to be zero at start
		- set to 1 on addition to the peak zone
		- if initially less than zero, that element in the data is ignored
			- allows successive calls to the funtion
			- set previously detected mask elements to -1 to allow detection of other peaks

	Regarding the results array:
		result[0]= number of elements in peak
		result[1]= x-position (zero-offset element) of max value
		result[2]= y-position (zero-offset element) of max value
		result[3]= x-position of centre of mass (left=0)
		result[4]= x-position of centre of mass (top=0)
		result[5]= mean value of elements inside peak zone
		result[6]= max value (value in the pixel which is the field kernal)

RETURN VALUE:
	1 on success, 0 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixread1_d"><a href="#CODE">&#8679</a> xf_matrixread1_d</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
		Read one or more matrices from an input
		Each matrix should be separated by a blank line or a line whos first character is "#"
		Data is stored as a continuous array of double-precision floating point numbers
		Automatically detects the number of rows and columns in the input
			- the first matrix is taken as the model - discrepencies result in errors
		The number of matrices and the number of rows and columns are stored

USES:
	storing 2-d blocks of ascii data into memory as a 1d array

DEPENDENCY TREE:

	No dependencies

ARGUMENTS:
	long *nmatrices - output variable, how many matrices were read
	long *ncols     - output variable, how many columns are on each row of each matrix
	long *nrows     - output variable, how many rows are in each matrix
	char *message   - holds error messages - should be defined by caliing funtion as message[256]
	FILE *fpin      - pointer to input stream (typically a file or stdin) - updated by the function

RETURN VALUE:
	- A pointer to an array holding the matrix, or multiple matrices packed together
	- NULL if no line was read
	- note that nmatrices, ncols and nrows will also be updated

SAMPLE CALL:
	data1= xf_matrixread1_d(&nmatrices1,&ncols1,&nrows1,message,fpin);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixread2_d"><a href="#CODE">&#8679</a> xf_matrixread2_d</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
		Read one or more matrices from an input
		Each matrix should be separated by a blank line or a line whos first character is "# followed by an identifier number"
		Data is stored as a continuous array of double-precision floating point numbers
		Automatically detects the number of rows and columns in the input
			- the first matrix is taken as the model - discrepencies result in errors
		The number of matrices and the number of rows and columns are stored

USES:
	storing 2-d blocks of ASCII data into memory as a 1d array

DEPENDENCIES:
	char *xf_lineread1(char *line, long *maxlinelen, FILE *fpin);

ARGUMENTS:
	char *infile     - name of the input file, or "stdin"
	long idcol	 - for lines starting with "#", the zero-offset column-number holding the id (typically "1")
	double **matrix1 - result, multi-matrix data - freed by calling function
	double **id1     - result, id's for each matrix - freed by calling function
	long *ncols      - result, how many columns are on each row of each matrix
	long *nrows      - result, how many rows are in each matrix
	char *message    - holds error messages - should be defined by calling funtion as message[256]
	FILE *fpin       - pointer to input stream (typically a file or stdin) - updated by the function

RETURN VALUE:
	- the number of matrices detected, or -1 on error
	- the matrix1[] array is filled
	- the id1[] array stores the identifiers for each matrix, presuming they are preceded by a "# &#60identifier&#62" line
	- the message[] array will hold any errors

SAMPLE CALL:
	char message[256];
	double *matrix1=NULL, *id1=NULL, *pmatrix;
	long nmatrices,ncols,nrows,ii,jj,kk,mm,idcol=1;
	nmatrices= xf_matrixread1_d(&matrix1,idcol,&id1,&ncols1,&nrows1,message,fpin);

	mm=5;
	pmatrix= matrix1+(mm*ncols*nrows); // select fifth matrix
	printf("# %g\n",id1[mm]); // print the identifier
	for(ii=0;ii&#60nrows;ii++) {
		for jj=0;jj&#60ncols;jj++) printf("%g ",pmatrix[ii*ncols+jj]);
		printf("\n");
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixread3_d"><a href="#CODE">&#8679</a> xf_matrixread3_d</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read one matrix from a single- or multi-matrix input
	Multiple matrices should be separated by a blank (\n) or header-line (#)
		- every encountered header-line updates the header array
		- if data has been read at this point, the function returns
		- therefore, the header is set for subsequent data on the next call
	Automatically detects the number of rows and columns in the input
		- row #1 is taken as the default number of columns
		- all rows must be the same width
	Stores the preceding and most recent header line (#)

USES:
	- Finding matrices for a given subject or group in a multi-matrix file

DEPENDENCIES:

	char *xf_lineread1(char *line, long *maxlinelen, FILE *fpin);
	long *xf_lineparse1(char *line,long *nwords);

ARGUMENTS:
	FILE *fpin      - input: pointer to input stream (typically a file or stdin) - updated by the function
	long *ncols     - output: number of columns on each row (pass as address)
	long *nrows     - output: number of rows (pass as address)
	char *header    - output[256]: header for the current matrix
	char *message   - output[256]: header for next matrix, or error message, if any

	NOTE: calling function must allocate at least 256-byetes each for header[] and message[]
	NOTE: header[] and message[] should be initialized to '\n\0' before first call to this function

RETURN VALUE:
	- on success:
		- A pointer to an array holding the matrix (NULL at end of file)
		- header[] contains the header preceeding the matrix
		- message[] contains the header for the next matrix, if there is one
	- on error:
		- ncols and nrows are set to -1
		- message[] describes the error

SAMPLE CALL:
	char header[256],message[256];
	long nrows=0,ncols=0,ii,jj,kk;
	FILE *fpin= fopen(infile,"r"))==0);
	header[0]='\n'  ; header[1]='\0';
	message[0]='\n' ; message[1]='\0';
	while(1) {

		matrix= xf_matrixread3_d(fpin,&width,&height,header,message);

		if(height&#600) {fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message);exit(1);}
		if(matrix1==NULL) break;
		printf("%s",header);
		for(ii=0;ii&#60height;ii++) {
			kk= ii*width;
			for(jj=0;jj&#60width;jj++) { if(jj&#620) printf(" ");	printf("%g",matrix1[kk+jj]); }
			printf("\n");
	}}
	if(strcmp(infile,"stdin")!=0) fclose(fpin);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixresample1_d"><a href="#CODE">&#8679</a> xf_matrixresample1_d</h3></font>
[<a href="#tag-matrix">matrix</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Resample a series of numbers representing a 2D matrix, so
	there are a user-defined number of rows and columns

	Rows and columns are split (new dimensions &#62 old dimensions)
	or binned & averaged (new dimensions &#62= old dimansions), accordingly

	Alters input array
	NAN values will be ignored, but INF will affect the results

	[JRH] 23 November 2015

USES:
	- resampling an image or matrix to reduce or increase resolution
	- modifying different matrices so they are all the same size

DEPENDENCY TREE:
	xf_bin1a_d
	xf_expand1_d

ARGUMENTS:
	double *martix1: input, array of numbers to be resampled - matrix format
	long nx1: original matrix width
	long ny1: original matrix height
	long nx2: original matrix width
	long ny2: original matrix height

RETURN VALUE:
	Pointer to modified matrix - NULL on error

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixrotate1_d"><a href="#CODE">&#8679</a> xf_matrixrotate1_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Rotate a 1-dimensional array of numbers  meant to be interpreted as a 2-dimentional matrix

USES:
	- image or map rotation
	- matrix algebra

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data1 (input)- pointer to array of numbers representing the original matrix
				- sufficient memory must be allocated by calling program
				- this original memory will be freed
	long *nx1 (input/output)- width of the matrix, to be modified depending on rotation
	long *ny1 (input/output)- height of the matrix, to be modified depending on rotation
				- nx1 and ny1 MUST reflect the total size of the data1 array
	int r (input) - rotation (90,180,270,-90,-180,-270)
				- 0,360, or any other value simply results in no changes
RETURN VALUE:

	A pointer to a rotated version of the original numbers
	Returns NULL if a memory allocation error was encountered
	NOTE: nx1 and ny1 will be also modified according to the rotation
	NOTE: if a valid value for "r" is set, the original memory for the matrix is freed


TEST PROGRAM :

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62

	int main (int argc, char *argv[]) {

		double *xf_matrixrotate1_d(double *data1, long *nx1, long *ny1, int r);
		double *matrix=NULL;
		long width=3,height=5,n=width*height,x,y;

		matrix=(double *)realloc(matrix,n*sizeof(double));
		for(x=0;x&#60n);x++) matrix[x]=(double)x;

		for(y=0;y&#60height;y++) { for(x=0;x&#60width;x++) printf("%g\t",matrix[y*width+x]);	printf("\n"); }
		printf("\n");

		matrix= xf_matrixrotate1_d( matrix, &width, &height, 90 );

		for(y=0;y&#60height;y++) { for(x=0;x&#60width;x++) printf("%g\t",matrix[y*width+x]);	printf("\n"); }
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixrotate1_f"><a href="#CODE">&#8679</a> xf_matrixrotate1_f</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Rotate a 1-dimensional array of numbers  meant to be interpreted as a 2-dimentional matrix

USES:
	- image or map rotation
	- matrix algebra

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data1 (input)- pointer to array of numbers representing the original matrix
				- sufficient memory must be allocated by calling program
				- this original memory will be freed
	long *nx1 (input/output)- width of the matrix, to be modified depending on rotation
	long *ny1 (input/output)- height of the matrix, to be modified depending on rotation
				- nx1 and ny1 MUST reflect the total size of the data1 array
	int r (input) - rotation (90,180,270,-90,-180,-270)
				- 0,360, or any other value simply results in no changes

RETURN VALUE:

	A pointer to a rotated version of the original numbers
	Returns NULL if a memory allocation error was encountered
	NOTE: nx1 and ny1 will be also modified according to the rotation
	NOTE: if a valid value for "r" is set, the original memory for the matrix is freed


TEST PROGRAM :

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62

	int main (int argc, char *argv[]) {

		float *xf_matrixrotate1_d(float *data1, long *nx1, long *ny1, int r);
		float *matrix=NULL;
		long width=3,height=5,n=width*height,x,y;

		matrix=(float *)realloc(matrix,n*sizeof(float));
		for(x=0;x&#60n);x++) matrix[x]=(float)x;

		for(y=0;y&#60height;y++) { for(x=0;x&#60width;x++) printf("%g\t",matrix[y*width+x]);	printf("\n"); }
		printf("\n");

		matrix= xf_matrixrotate1_d( matrix, &width, &height, 90 );

		for(y=0;y&#60height;y++) { for(x=0;x&#60width;x++) printf("%g\t",matrix[y*width+x]);	printf("\n"); }
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixrotate2_d"><a href="#CODE">&#8679</a> xf_matrixrotate2_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Rotate a 1-dimensional array of numbers  meant to be interpreted as a 2-dimentional matrix
	- unlike xf_matrixrotate1_d, makes an internal copy of data and modifies the original
	- therefore, safer for memory management and nested functions, but has a heavier computational load
USES:
	- image or map rotation
	- matrix algebra

DEPENDENCIES:
	None

ARGUMENTS:
	double *data1 : input, pointer to array of numbers representing the original matrix
	long *nx1     : input/output - width of the matrix, to be modified depending on rotation
	long *ny1     : input/output- height of the matrix, to be modified depending on rotation
	int r         : input - rotation (90,180,270,-90,-180,-270)

RETURN VALUE:
	0 on success
	-1 for invalid arguments
	-2 for memory allocation error
	NOTE: nx1 and ny1 will be also modified according to the rotation
</blockquote></pre>

<font color="Black"><h3 id="code-xf_matrixtrans1_d"><a href="#CODE">&#8679</a> xf_matrixtrans1_d</h3></font>
[<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Transpose a 1-dimensional array of numbers meant to be interpreted as a 2-dimentional matrix
	Note that this differs from rotation, because low columns become low rows ( & vice versa)
	This version deals with double-precision floating-point numbers

	Example: this matrix...

	0	1	2	3
	4	5	6	7
	8	9	10	11

	... will be transposed to...

	0	4	8
	1	5	9
	2	6	10
	3	7	11


USES:
	- table transposition - interchange rows and columns
	- matrix algebra

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *data1	: pointer to array of numbers representing the original matrix
						- sufficient memory must be allocated by calling program
						- this original memory will be freed
	long width		: width of the matrix
	long height 	: height of the matrix
						- width and height must accurately reflect the total size of the data1 array

	NOTE: width and height are not swapped by this function, so if the calling function uses these
	variables after transposition, it is the responsibility of the calling function to do the swap

RETURN VALUE:

	A pointer to a transposed version of the original numbers
	Returns NULL if a memory allocation error was encountered


SAMPLE CALL :

		matrix= xf_matrixtrans1_d(matrix, &width, &height);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_morletwavelet1_f"><a href="#CODE">&#8679</a> xf_morletwavelet1_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Create a simple Morlet wavelet

	Based on MATLAB functions energyvec.m and morelet_wav.m  by Ole Jensen, 1997-1998

	Original notes:
		% Create a Morlet wavelet 'y' with frequency resolution 'f' and temporal
		% resolution 't'. The wavelet will be normalized so the total energy is 1.
		% The 'width' defines the temporal and frequency resolution for the given
		% centre frequency 'f' by determining the number of cycles of the wavelet
		% itself (see Tallon-Baudry et al., J. Neurosci. 15, 722-734 (1997) or
		% Event-Related Potentials: A Methods Handbook, Handy (editor), MIT Press,
		% (2005))

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double freq   : central frequency of wavelet
	double srate  : sampling freq. of signal to be transformed with the wavelet
	int width     : the number of cycles in the mother wavelet (&#62= 5 recommended). This is then scaled and translated to filter for different frequencies. See Tallon-Baudry et al., J. Neurosci. 15, 722-734 (1997))
	size_t *nwav  : address to a variable to hold the resultant size (elements) of the wavelet (modified by this function)


RETURN VALUE:
	pointer to the wavelet, type = float, size=nwav
	NULL on failure

SAMPLE CALL:

	#include &#60math.h&#62
	#include &#60stdio.h&#62
	float *xf_morletwavelet1_f(double f, double srate, int width, size_t *nwavelet);
	int main() {
		double freq=8.0;
		double sr=24000;
		int width=7;
		size_t ii,nwav;

		float *wavelet = xf_morletwavelet1_f(freq,srate,width,&nwav);

		for(ii=0;ii&#60nwav;ii++) printf("%d	%g	%g\n",ii,wavelet[ii]);
		free(wavelet);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_morletwavelet2_f"><a href="#CODE">&#8679</a> xf_morletwavelet2_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Create a complex Morlet wavelet

	Based on MATLAB functions energyvec.m and morelet_wav.m  by Ole Jensen, 1997-1998

	Original notes:
		% Create a Morlet wavelet 'y' with frequency resolution 'f' and temporal
		% resolution 't'. The wavelet will be normalized so the total energy is 1.
		% The 'width' defines the temporal and frequency resolution for the given
		% centre frequency 'f' by determining the number of cycles of the wavelet
		% itself (see Tallon-Baudry et al., J. Neurosci. 15, 722-734 (1997) or
		% Event-Related Potentials: A Methods Handbook, Handy (editor), MIT Press,
		% (2005))

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double freq   : central frequency of wavelet
	double srate  : sampling freq. of signal to be transformed with the wavelet
	int width     : parameter which defines the mother wavelet. This is then scaled and translated to filter for different frequencies, &#62= 5 is suggested, see Tallon-Baudry et al., J. Neurosci. 15, 722-734 (1997))
	size_t *nwav  : address to a variable to hold the resultant size (elements) of the wavelet (modified by this function)


RETURN VALUE:
	pointer to the wavelet, type = complex float, size=nwav
	NULL on failure

SAMPLE CALL:

	#include &#60math.h&#62
	#include &#60stdio.h&#62
	#include &#60complex.h&#62
	complex float *xf_morletwavelet2_f(double f, double srate, int width, size_t *nwavelet);
	int main() {
		double freq=8.0;
		double sr=24000;
		int width=7;
		size_t ii,nwav;

		complex float *wavelet = xf_morletwavelet2_f(freq,srate,width,&nwav);

		for(ii=0;ii&#60nwav;ii++) printf("%d	%g	%g\n",ii,creal(wavelet[ii]),cimag(wavelet[ii]));
		free(wavelet);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_mtm_F"><a href="#CODE">&#8679</a> xf_mtm_F</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the F-statistic for a multi-taper power spectrum estimate

	This function is derived from the "get_F_values" function published here:
		Jonathan M. Lees and Jeffrey Park (1995)
		"MULTIPLE-TAPER SPECTRAL ANALYSIS: A STAND-ALONE C-SUBROUTINE"
		Computers & Geoscirnces Vol. 21, No. 2, pp. 199-236

	Changes (JRH, January 2013)
		- first argument is now a structure (complex Kiss-FFT output fft[].r fft[].i)  instead of separate arrays holding real and imaginary FFT output

USES:

DEPENDENCY TREE:
	requires "kiss_fftr.h" in order to define the complex data type "fft"

ARGUMENTS:
	double *sr	: (input) - real component of the FFT results
	double *si	: (input) - imaginary component of the FFT results
	int nf		: (input) - number of frequencies to be analyzed (typically 0.5 x length of the data the FFT was performed on)
	int nwin	: (input) - number of tapers
	float *Fval : (output) - holds the f-values [nf]
	double *tapsum	: (input) - sum of the taper values for each taper

RETURN VALUE:

SAMPLE CALL:
		get_F_values(ReSpec, ImSpec, num_freqs, nwin, Fval, tapsum);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_mtm_slepian1"><a href="#CODE">&#8679</a> xf_mtm_slepian1</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Get Slepian tapers (discrete prolate spheroidal sequences)

	This function is virtually unchanged from the "multitap" function published here:
		Jonathan M. Lees and Jeffrey Park (1995)
		"MULTIPLE-TAPER SPECTRAL ANALYSIS: A STAND-ALONE C-SUBROUTINE"
		Computers & Geoscirnces Vol. 21, No. 2, pp. 199-236

	Lees & Park in turn mke use of two functions translated to C from the public-domain EISPACK Fortran library:
		jtinvit_ (in EISPACK, tinvit)
		jtridib_ (in EISPACK, tridib)

	Note that the tapers produces are orthogonal - 0 is orthogonal to 1, 2 is orthogonal to 3, 4 is orthogonal to 5, etc.
	What that means is, for each pair of tapers, the sum of their products is zero.

USES:
	In multi-taper method (MTM) power spectral density estimation, use this function to derive a set of tapers to be used
	Repeated FFT analysis of the same data using multiple tapers
		a) reduces the impact of data "lost" at the edges when using a simple Hann window
		b) provides a more robust estimate of the power spectrum - better than smoothing a single-tapered spectrum

DEPENDENCY TREE:
	No external dependencies

ARGUMENTS:
	 int npoints : (input) number of points in data series
	 int ntapers : (input) number of tapers
	 float npi : (input) order of slepian functions
	 double *lamda : (result) vector of eigenvalues, size = ntapers - needed for adaptive averaging of spectra
	 double *tapers : (result) matrix of slepian tapers, packed in a 1D double array
	 double *tapsum : (result) sum(lambda)/sum(lambda-squared) - the adjusted sum of the eigenvectors, needed for calculating F-values


RETURN VALUE:

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_mtm_spectavg1"><a href="#CODE">&#8679</a> xf_mtm_spectavg1</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	This function is derived from "adwait" function published here:
		Jonathan M. Lees and Jeffrey Park (1995)
		"MULTIPLE-TAPER SPECTRAL ANALYSIS: A STAND-ALONE C-SUBROUTINE"
		Computers & Geoscirnces Vol. 21, No. 2, pp. 199-236

	Uses David Thomson's algorithm for calculating the adaptive spectrum estimate
	That is, averages multiple eigenspectra using adaptive weighting

	In practice this seems to better preserve sharp peaks in the spectra for known
	strong signals (eg. hippocampal theta oscillations) than simply averaging
	the spectra conventionally, although amplitude is reduced more.

USES:

DEPENDENCY TREE:
	No external dependencies

ARGUMENTS:
	double *sqr_spec : (input) - amplitude spectra [ntapers*npoints, where npoints=size of FFT window]
	double *lambda : (input) - vector of eigenvalues [ntapers]
	int ntapers : (input) - number of tapers
	int nfreq : (input) - number of frequencies to analyze, starting from zero (typically npoints/2)
	double *ares : (result) - weighted average spectrum [nfreq]
	double *degf : (result) - degrees of freedom (can be used for calculating F, later)
	double avar : (input) - variance in the original input (before FFT)

RETURN VALUE:

SAMPLE CALL:

	xf_mtm_spectavg1(sqr_spec, dcf, lambda, ntapers, nfreqs, amu, degf, avar);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_mullerize_d10"><a href="#CODE">&#8679</a> xf_mullerize_d10</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Determine rate cutoffs for Robert-Muller style 10-colour firing-rate maps
	A fixed proportion of non-zero-rate pixels assigned to each colour...
	Each step up the rate ladder has 80% of the pixels of the lower colour

DEPENDENCIES:
	xf_compare1_d

ARGUMENTS:
	double *data : the original data array
	long n : total elements in the input array
	double *result : pointer to an array with reserved memory for at least 16 elements to hold the cutoff values

USES:

RETURN VALUE:
	0 on success, -1 on memory allocation fail

	The result array is filled with cutoffs for bands of increasing values in the data

	result[] 	proportion	cumulative
	----------------------------------
	result[0] 	UNKNOWN 	UNKNOWN  - result[0] is always zero - cutoff for base-colour pixels
	result[1]	0.224059	0.224059
	result[2]	0.179247	0.403306
	result[3]	0.143398	0.546704
	result[4]	0.114718	0.661422
	result[5]	0.0917746	0.753197
	result[6]	0.0734197	0.826616
	result[7]	0.0587357	0.885352
	result[8]	0.0469886	0.932341
	result[9]	0.0375909	0.969932
	result[10]	0.0300727	1.000000

	To use this to determine the colour (z) of any given datum:

		z=0; for(j=0;j&#6010;j++) if(data[i]&#62result[j]) z=j+1



</blockquote></pre>

<font color="Black"><h3 id="code-xf_norm1_d"><a href="#CODE">&#8679</a> xf_norm1_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Normalize an array of double-precision floating-point numbers
	Data can be normalized in two ways:
		0. convert to values ranging from 0-1
		1. convert to z-scores
USES:
	Can make it easier to compare skewed datasets
	Good for analyzing trends in data with very different baselines

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : the original data - will be transformed!
	long nn : number of elements in the array - if N&#602 the data will not be altered.
	int normtype : the type of normalization
		0 for forcing data to a 0-1 range
		1 for producing z-scores

RETURN VALUE:
	None. This function modifies the data input. It should never fail provided
	N acurately reflects the memory pre-allocated for the contents of the data array

SAMPLE CALL
	xf_norm1_d(data,N,0)

</blockquote></pre>

<font color="Black"><h3 id="code-xf_norm2_d"><a href="#CODE">&#8679</a> xf_norm2_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Normalize an array of double-precision floating-point numbers
	Data can be normalized in two ways:
		0. convert to values ranging from 0-1
		1. convert to z-scores

	Similar to xf_norm1_d but NAN and INF are not included in calculations

USES:
	Can make it easier to compare skewed datasets
	Good for analyzing trends in data with very different baselines

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data : the original data - will be transformed!
	long ndata   : number of elements in the array - if N&#602 the data will not be altered.
	int normtype : the type of normalization
		0 for forcing data to a 0-1 range
		1 for producing z-scores

RETURN VALUE:
	The number of valid numerical data points in data
	OR
		-1: memory allocation error
		-2: no finite numbers in data
		-3: invalid normalization type

	This function modifies the data input. It should never fail provided N
	accurately reflects the memory pre-allocated for the contents of the data array

SAMPLE CALL
	x= xf_norm1_d(data,ndata,0)
	if(x==-1) { fprintf(stderr,"\b\n\t--- Error [%s]: insufficient memory\n\n",thisprog); exit(1); }
	if(x==-2) { fprintf(stderr,"\b\n\t--- Error [%s]: no valid numbers\n\n",thisprog); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_norm2_f"><a href="#CODE">&#8679</a> xf_norm2_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Normalize an array of double-precision floating-point numbers
	Data can be normalized in two ways:
		0. convert to values ranging from 0-1
		1. convert to z-scores

	Similar to xf_norm1_d but NAN and INF are not included in calculations

USES:
	Can make it easier to compare skewed datasets
	Good for analyzing trends in data with very different baselines

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data : the original data - will be transformed!
	long ndata   : number of elements in the array - if N&#602 the data will not be altered.
	int normtype : the type of normalization
		0 for forcing data to a 0-1 range
		1 for producing z-scores

RETURN VALUE:
	The number of valid numerical data points in data
	OR
		-1: memory allocation error
		-2: no finite numbers in data
		-3: invalid normalization type

	This function modifies the data input. It should never fail provided N
	accurately reflects the memory pre-allocated for the contents of the data array

SAMPLE CALL
	x= xf_norm1_f(data,ndata,0)
	if(x==-1) { fprintf(stderr,"\b\n\t--- Error [%s]: insufficient memory\n\n",thisprog); exit(1); }
	if(x==-2) { fprintf(stderr,"\b\n\t--- Error [%s]: no valid numbers\n\n",thisprog); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_norm3_d"><a href="#CODE">&#8679</a> xf_norm3_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Normalize an array of double-precision floating-point numbers
	Data can be normalized as follows:
		NORMALIZE TYPE-0: CONVERT TO A RANGE FROM 0 TO 1
		NORMALIZE TYPE-1: CONVERT TO Z-SCORES (use start-stop)
		NORMALIZE TYPE-2: difference from first valid sample (beginning at start)
		NORMALIZE TYPE-3: difference from mean (use start-stop)
		NORMALIZE TYPE-4: ratio of mean (use start-stop)

	- to use like previous versions of xf_norm, jj= xf_norm3_d(data,n,type,0,-1,message)

USES:
	Can make it easier to compare skewed datasets
	Good for analyzing trends in data with very different baselines

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data  : the original data - will be transformed!
	long ndata    : number of elements in the array
	int normtype  : the type of normalization (see above)
	long start    : first sample (0 to [ndata-1]) to use for normalization (-1= first valid sample)
	long stop     : last sample+1 (1 to ndata) to use for normalization (-1= last valid sample)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	on success: number of valid numerical data points in data
		- the input data will be modified
	on error:
		-1 - there is no valid data, or reference-zone is invalid
			- all input becomes NAN
			- message array will hold WARNING text
		-2 if invalid parameters were passed
			- input is unaltered
			- message array will hold ERROR text

SAMPLE CALL
	type=3; start=-1; stop=-1;
	ii= xf_norm3_d(data,ndata,type,start,stop,message);
	if(ii==-2) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	if(ii==-1) {
		if(setverb&#620) fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message);
		for(jj=0;jj&#60ndata;jj++) datval[jj]=NAN;
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padarray0_f"><a href="#CODE">&#8679</a> xf_padarray0_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is with zeros

	The original array will be modified
	NOTE: original array MUST be defined as float * in calling function
	NOTE: calling function MUST reallocate additional memory for original array before calling this function

USES:
	To create an aray of a specified size
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : array already holding data to be padded
	long nn       : number of elements in the array
	long npad     : size of the padding to be added
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
		positive integer: number of elements in the padded array
		-1: error: invalid type
		-2: error: invalid amount of padding

SAMPLE CALL:

	# pad an array of 1000 elements with 50 values at either end
	data= xf_padarray0_f(data,1000,50,3,message);
	if(data==NULL) {
		fprintf(stderr,"Error: %s\n",message);
		exit(1);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padarray1_f"><a href="#CODE">&#8679</a> xf_padarray1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is designed to gradually reduce the rate of change at either end of the array to zero
	Total change in padded region is scaled to a fraction of the total data range
	The original array will be modified
		- the modified array size will be n+npad (if type=1 or type=2) or n+(npad*2) (if type=3)
		- this function allocates additional memory for the padded array

USES:
	To prevent edge-effects when filtering the array
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data   : array already holding data to be padded
	long nn       : number of elements in the array
	long npad     : size of the padding to be added
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
	success: pointer to padded array
	failure: NULL

SAMPLE CALL:

	# pad an array of 1000 elements with 50 values at either end
	data= xf_padarray1_f(data,1000,50,3,message);
	if(data==NULL) {
		fprintf(stderr,"Error: %s\n",message);
		exit(1);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padarray2_f"><a href="#CODE">&#8679</a> xf_padarray2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is a reverse-copy of the data at either end, trended to zero using a cosine taper
	The original array will be modified
		- the modified array size will be n+npad (if type=1 or type=2) or n+(npad*2) (if type=3)
		- this function allocates additional memory for the padded array

USES:
	To prevent edge-effects when filtering the array
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float* data   : array already holding data to be padded
	long nn       : number of elements in the array
	long npad     : size of the padding to be added (must be &#60=n)
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
	success: pointer to padded array
	failure: NULL

SAMPLE CALL:

	# pad an array of 1000 elements with 50 values at either end
	data= xf_padarray2_f(data,1000,50,3,message);
	if(data==NULL) {
		fprintf(stderr,"Error: %s\n",message);
		exit(1);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padarray3_f"><a href="#CODE">&#8679</a> xf_padarray3_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is composed of the mean for the first and/or last npad values in the input array
	The original array will be modified
		- the modified array size will be n+npad (if type=1 or type=2) or n+(npad*2) (if type=3)
		- this function allocates additional memory for the padded array

USES:
	To prevent edge-effects when filtering the array
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float* data   : array already holding data to be padded
	long nn       : number of elements in the array
	long npad     : size of the padding to be added (must be &#60=n)
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
	success: pointer to padded array
	failure: NULL

SAMPLE CALL:

	# pad an array of 1000 elements with 50 values at either end
	data= xf_padarray3_f(data,1000,50,3,message);
	if(data==NULL) {
		fprintf(stderr,"Error: %s\n",message);
		exit(1);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padarray4_f"><a href="#CODE">&#8679</a> xf_padarray4_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is "sample-and-hold" : the first and/or last values in the input array
	Benefit: cannot introduce any sharp transitions or oscillations into the data
	The original array will be modified
		- the modified array size will be n+npad (if type=1 or type=2) or n+(npad*2) (if type=3)
		- this function allocates additional memory for the padded array
USES:
	To prevent edge-effects when filtering the array
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float* data   : array already holding data to be padded
	long* nn      : number of elements in the array, passed as address, will be updated
	long npad     : size of the padding to be added (must be &#60=n)
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
	success: pointer to padded array, nn variable will be updated
	failure: NULL

SAMPLE CALL:

	# pad an array of 1000 elements with 50 values at either end
	nn= 1000;
	data= xf_padarray4_f(data,&nn,50,3,message);
	if(data==NULL) { fprintf(stderr,"Error: %s\n",message);	exit(1);}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_padcos2_f"><a href="#CODE">&#8679</a> xf_padcos2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Pad an array of floating-point numbers with extra values at the beginning and/or end
	Padding is a reverse-copy of the data at either end, trended to zero using a cosine taper
	The original array will be modified
	Calling function must acknowledge that new array size will be n+npad (if type=1 or type=2) or n+npad+npad (if type=3)

USES:
	To prevent edge-effects when filtering the array
	Note: the array should subsequently be trimmed to remove the extra values

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float* data   : array already holding data to be padded
	long nn       : number of elements in the array
	long npad     : size of the padding to be added (must be &#60=n)
	int type      : type of  padding: 1=start, 2=end, 3=both
	char* message : array to hold reults message

RETURN VALUE:
	success: pointer to padded array
	failure: NULL

SAMPLE CALL:
	# pad an array of 1000 elements with 50 values at either end
	data= xf_padcos2_f(data,1000,50,3,message);
	if(data==NULL) {
		fprintf(stderr,"Error: %s\n",message);
		exit(1);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_parselist1_l"><a href="#CODE">&#8679</a> xf_parselist1_l</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:

	Convert a character string containing a list of positive numbers and/or ranges into an array of numbers
	Preserves input order
	Will not remove redundant entries
	Will not work with negative numbers

	Sample acceptable list formats:
		1,2,5,6,10
		1,3,5,7-20
		10-1,11,14,20-25


USES:
	Build a list of columns to extract from a table

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *line       : character array holding list
	char *delimiters : delimiters (quoted) for each item in the list
	long min       : minimum accepted value
	long max       : maximum accepted value
	long *nitems   : number of items in resulting list (pass as address to variable)
	char *message    : holds error message

RETURN VALUE:
	pointer to the list array, or NULL on error
	value for nitems will be overwritten

SAMPLE CALLS:

	char line[1000],message[1000];
	long *list=NULL,i,n;

	sprintf(line,"1,2,3,4,5");
	list= xf_parselist1_l(line,",",1,999,&n,message);
	if(list==NULL) {fprintf(stderr,"\b\n\t--- Error [%s] %s\n\n",thisprog,message); exit(1); }
	for(i=0;i&#60n;i++) printf("%ld\n",list[i]);
	free(list);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_pause1"><a href="#CODE">&#8679</a> xf_pause1</h3></font>
[<a href="#tag-misc">misc</a>]<br>
<blockquote><pre>DESCRIPTION:
	pause until a key is pressed
</blockquote></pre>

<font color="Black"><h3 id="code-xf_percentile1_d"><a href="#CODE">&#8679</a> xf_percentile1_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate percentile cutoffs for a distribution of double values

USES:
	Getting the median, finding outliers in a distribution

DEPENDENCIES:
	xf_compare1_d

ARGUMENTS:
	double *data  : array holding the input data
	long nn       : number of elements in the array
	double *result: a minimum 16-element array to hold the percentile results
	   result[0]  : 1st percentile
	   result[1]  : 2.5th percentile
	   result[2]  : 5th percentile
	   result[3]  : 10th percentile
	   result[4]  : 25th percentile
	   result[5]  : 50th percentile (median)
	   result[6]  : 75th percentile
	   result[7]  : 90th percentile
	   result[8]  : 95th percentile
	   result[9]  : 97.5th percentile
	   result[10] : 99th percentile
	char *message : string to hold error message on fail

RETURN VALUE:
	0  if successful, -1 if fail

SAMPLE CALL:
	if ( xf_percentile1_d(data,n,result) &#62=0) median=result[5];
	else { fprintf(stderr,"** Memory allocation error\n"); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_percentile1_f"><a href="#CODE">&#8679</a> xf_percentile1_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate percentile cutoffs for a distribution of double values

USES:
	Getting the median, finding outliers in a distribution

DEPENDENCIES:
	xf_compare1_d

ARGUMENTS:
	float *data   : array holding the input data
	long nn       : number of elements in the array
	double *result: a minimum 16-element array to hold the percentile results
	   result[0]  : 1st percentile
	   result[1]  : 2.5th percentile
	   result[2]  : 5th percentile
	   result[3]  : 10th percentile
	   result[4]  : 25th percentile
	   result[5]  : 50th percentile (median)
	   result[6]  : 75th percentile
	   result[7]  : 90th percentile
	   result[8]  : 95th percentile
	   result[9]  : 97.5th percentile
	   result[10] : 99th percentile
	char *message : string to hold error message on fail

RETURN VALUE:
	0  if successful, -1 if fail

SAMPLE CALL:
	if ( xf_percentile1_d(data,n,result) &#62=0) median=result[5];
	else { fprintf(stderr,"** Memory allocation error\n"); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_placeinfo1_l"><a href="#CODE">&#8679</a> xf_placeinfo1_l</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate spatial-information-content for place-fields
	- uses the adaptive binning methods described in Langston et al. 2010 (adapted from Skaggs & McNaughton,1998)
		- expand radius of binning until:  radius * dwell * sqrt(events) &#62= alpha
		- oddly, in the literture this is expressed as:  radius &#62= alpha / ( dwell * sqrt(events) )
		- alpha is a constant, which varies from publication (10^3 for Skaggs, 10^5 for Langston & O'Keefe)

	Pi = probability of being n bin i, = dwell (samples) in bin i divided by total dwell samples
	Ri = firing rate in bin i, = event/dwell
	R = mean firing rate = (event total) / (dwell total)

	- information content (how well does cell firing predict location - high info = small fields)
		= SUM {Pi*(Ri/R) log2*(Ri/R)}
		NOTE: log2(x) = log(x)/log(2)

USES:

DEPENDENCIES: none

ARGUMENTS:
	double *dwell       : position-sample-count array
	double *event       : event-count array
	long width          : width of array
	long height         : height of array
	long radmax         : maximum radius for adaptive binning (-1= auto, 0= central bin only)
	long alpha          : constant used to limit adaptive binning (typically 10^3 to 10^6, depending on the original binning or smoothing of the data)
	long *result_l      : array to hold outputs - should point to 8-element array
	char *message       : pre-allocated array to hold error message

RETURN VALUE:
	- spatial information content, or NAN on error
	- char array will hold message (if any)
	- result array will hold statistics
		result_l[0]= total dwell samples
		result_l[1]= total events
		result_l[2]= total non-zero dwell samples
		result_l[3]= radius limit (radmax)
		result_l[4]= largest radius used in adaptive binning (radbig)

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_placestats1_d"><a href="#CODE">&#8679</a> xf_placestats1_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-matrix">matrix</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate statistics on cell firing rate map pattern...

	Pi = probability of being n bin i, = dwell time in bin i divided by trial length
	Ri = firing rate in bin i
	R = mean firing rate over entire trial

	- cohererence of place cell firing (how well does one bin rate predict the neighbouring bin rate)
		coherence = z-transform of correlation between binrates and the mean of surrounding binrates,

	- sparsity is roughly equivalent to the proportion of the environment the cell is likely to be active in
		= (SUM{Pi*Ri})^2 * SUM(Pi*Ri^2)

	- information content (how well does cell firing predict location - high info = small fields)
		= SUM {Pi*(Ri/R) log2*(Ri/R)}
		NOTE: log2(x) = log(x)/log(2)

USES:

DEPENDENCIES:
	long    xf_stats3_d(double *data, long n, int varcalc, double *result_in);
	double  xf_correlate_simple_d(double *x, double *y, long nn, double *result_in);
	int     xf_percentile1_d(double *data, long n, double *result);

ARGUMENTS:
	double *dwell       : dwelltime array (make sure unvisited pixels are zero, not NAN)
	double *rate        : firing rate array
	long width          : width of array
	long height         : height of array
	double dwelltot     : total duration of time in all "valid" bins
	double *result_out  : array to hold outputs - should point to 32-element array
	char *message       : pre-allocated array to hold error message

RETURN VALUE:
	- total good dwell & rate values, or -1 on error
	- char array will hold message (if any)
	- result array will hold statistics
		result_out[0]= maxrate;
		result_out[1]= meanrate;
		result_out[2]= baserate;   // 10th percentile
		result_out[3]= medianrate; // 50th percentile
		result_out[4]= peakrate;   // 97.5th percentile = midpoint of 95th percentile
		result_out[5]= sdrate;
		result_out[6]= info_content;
		result_out[7]= sparsity;
		result_out[8]= coherence;

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_power_goertzel1_d"><a href="#CODE">&#8679</a> xf_power_goertzel1_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the amplitude of a frequency component in a signal, using the Goertzel algorithm
	Return a power estimate for a single window
	- this is essentially a DFT for the specified frequency
	- real-valued input is assumed
	- data should be interpolated to remove non-numeric values, NAN or INF

	http://en.wikipedia.org/wiki/Goertzel_algorithm
	http://netwerkt.wordpress.com/2011/08/25/goertzel-filter/

	Note that rather than the magnitude of the signal, this function calculates the amplitude
		- hence the results reflect the original amplitude of the input signal
		- each power magnitude is adjusted by (2.0/nwin) and the square-root is taken


USES:
	- Fast detection of a frequency in a signal


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	double *input :      data array to be filtered, fixed sample rate is assumed
	size_t nn :          size of the data array (number of samples)
	double sample_freq : sample frequency (Hz)
	double freq :        frequency of interest (Hz)


RETURN VALUE:
	success: 0
	failure: -1

</blockquote></pre>

<font color="Black"><h3 id="code-xf_power_goertzel1_f"><a href="#CODE">&#8679</a> xf_power_goertzel1_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Calculate the amplitude of a frequency component in a signal, using the Goertzel algorithm
	- this is essentially a DFT for the specified frequency
	- real-valued input is assumed
	- a window slides along the data one sample at a time
	- a Hann taper is applied to each window
	- performed as if zero-padding were applied to each end of the input
		- note that no padding is actually required

	http://en.wikipedia.org/wiki/Goertzel_algorithm

	Note: data should be interpolated to remove non-numberic values, NAN or INF

	Note: that rather than the magnitude of the signal, this function calculates the amplitude
		- hence the results reflect the original amplitude of the input signal
		- each power magnitude is adjusted by (0.5/nwin) and the sqare-root is taken



USES:
	- Fast detection of the energy envelope of a signal for phase-amplitude coupling
	- Detection of a frequency in a signal


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	float *input :       data array to be filtered, fixed sample rate is assumed
	float *power :       data array to hold results (calling function must reserve memory)
	size_t nn :          size of input and power arrays (number of samples)
	float sample_freq :  sample frequency (Hz)
	float freq :         frequency of interest (Hz)
	size_t nwin :        size of the window used to integrate (typically 5*sample_freq/freq - i.e. 5 wavelengths)
	char *message :      message indicating success or reason for failure


RETURN VALUE:
	success: 0
	failure: -1

</blockquote></pre>

<font color="Black"><h3 id="code-xf_power_goertzel2_d"><a href="#CODE">&#8679</a> xf_power_goertzel2_d</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the amplitude of a frequency component in a signal, using the Goertzel algorithm
	Output a power estimate for every input data point
	- this is essentially a DFT for the specified frequency
	- real-valued input is assumed
	- data should be interpolated to remove non-numberic values, NAN or INF
	- performed as if zero-padding were applied to each end of the input
	- note that no padding is actually required

	http://en.wikipedia.org/wiki/Goertzel_algorithm

	Note that rather than the magnitude of the signal, this function calculates the amplitude
		- hence the results reflect the original amplitude of the input signal
		- each power magnitude is adjusted by (2.0/nwin) and the square-root is taken


USES:
	- Fast detection of the energy envelope of a signal for phase-amplitude coupling
	- Detection of a frequency in a signal


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	double *input :      data array to be filtered, fixed sample rate is assumed
	double *power :      data array to hold results (calling function must reserve memory)
	size_t nn :          size of input and power arrays (number of samples)
	double sample_freq : sample frequency (Hz)
	double freq :        frequency of interest (Hz)
	size_t nwin :        size of the window used to integrate (typically 5/freq - i.e. 5 wavelengths)
	int dotaper :        apply a Hann taper (0=no, 1=yes)
	char *message :      message indicating success or reason for failure


RETURN VALUE:
	success: 0
	failure: -1

</blockquote></pre>

<font color="Black"><h3 id="code-xf_power_goertzel2_f"><a href="#CODE">&#8679</a> xf_power_goertzel2_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:

	Calculate the amplitude of a frequency component in a signal, using the Goertzel algorithm
	Output a power estimate for every input data point
	- this is essentially a DFT for the specified frequency
	- real-valued input is assumed
	- a window slides along the data one sample at a time
	- a Hann taper is applied to each window
	- performed as if zero-padding were applied to each end of the input
		- note that no padding is actually required

	http://en.wikipedia.org/wiki/Goertzel_algorithm

	Note: data should be interpolated to remove non-numberic values, NAN or INF

	Note: that rather than the magnitude of the signal, this function calculates the amplitude
		- hence the results reflect the original amplitude of the input signal
		- each power magnitude is adjusted by (2.0/nwin) and the square-root is taken



USES:
	- Fast detection of the energy envelope of a signal for phase-amplitude coupling
	- Detection of a frequency in a signal


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	float *input :       data array to be filtered, fixed sample rate is assumed
	float *power :       data array to hold results (calling function must reserve memory)
	size_t nn :          size of input and power arrays (number of samples)
	float sample_freq :  sample frequency (Hz)
	float freq :         frequency of interest (Hz)
	size_t nwin :        size of the window used to integrate (typically 5*sample_freq/freq - i.e. 5 wavelengths)
	char *message :      message indicating success or reason for failure


RETURN VALUE:
	success: 0
	failure: -1

</blockquote></pre>

<font color="Black"><h3 id="code-xf_precision_c"><a href="#CODE">&#8679</a> xf_precision_c</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Return the decimal precision of a number as written in characters

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *number : [input] character string representing the number

RETURN VALUE:
	The number of significant digits after the decimal, for example....

	number		precision

	 100		0
	 1.123		3
	 1.12340	4

SAMPLE CALL:

	int precision;
	double data=100.1234500;

	precision= xf_precision_d(data);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_precision_d"><a href="#CODE">&#8679</a> xf_precision_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Return the decimal precision of a number

	- bear in mind some numbers cannot be accurately represented in float/double
	- hence accurately calculating precision of some numbers will fail
	- for this reason the "max" argument allows the user to limit the search for zeros

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double number : [input] double-precision floating-point number to be analyzed
	int max       : [1-12] the maximum number of decimal places to consider
				- 8 recommended
				- might need to be lower for large numbers
				- 12 is the absolute maximum

RETURN VALUE:
	The number of significant digits after the decimal, for example....

	number		precision

	 100		0
	 1.123		3
	 1.12340	4

SAMPLE CALL:

	int precision;
	double data=100.1234500;

	precision= xf_precision_d(data,8);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_prob_F"><a href="#CODE">&#8679</a> xf_prob_F</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	F-test function: Calculate F-distribution probability given F,df1, and df2

	Based on betai function from...
	NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (2nd Edition)
	William H. Press, Saul A. Teukolsky, William T. Vetterling, & Brian P.
	Flannery. Cambridge University Press, 1992.
</blockquote></pre>

<font color="Black"><h3 id="code-xf_prob_T1"><a href="#CODE">&#8679</a> xf_prob_T1</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre></blockquote></pre>

<font color="Black"><h3 id="code-xf_qsortindex1_f"><a href="#CODE">&#8679</a> xf_qsortindex1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Sort an array of long integers using a quick-sort algorithm
	Modifies the input data array
	This function also modifies an array of indices so the user can know the original position of the sorted numbers

USES:
	rearranging data in numerical order

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data: array holding the data
	long *index: array of numbers representing the original order of the data, typically 0 to (n-1)
	long n: size of the array

RETURN VALUE:
	None

NOTE!
	- behaviour for non-numeric values, Inf and Nan is not specified
	- arrays with only one element will be unaltered
</blockquote></pre>

<font color="Black"><h3 id="code-xf_qsortindex1_l"><a href="#CODE">&#8679</a> xf_qsortindex1_l</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Sort an array of long integers using a quick-sort algorithm
	Modifies the input data array
	This function also modifies an array of indices so the user can know the original position of the sorted numbers

USES:
	rearranging data in numerical order

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *data: array holding the data
	long *index: array of numbers representing the original order of the data, typically 0 to (n-1)
	long n: size of the array

RETURN VALUE:
	None

NOTE!
	- behaviour for non-numeric values, Inf and Nan is not specified
	- arrays with only one element will be unaltered
</blockquote></pre>

<font color="Black"><h3 id="code-xf_qsortindex1_s"><a href="#CODE">&#8679</a> xf_qsortindex1_s</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Sort an array of short integers using a quick-sort algorithm
	Modifies the input data array
	This function also modifies an array of indices so the user can know the original position of the sorted numbers

USES:
	rearranging data in numerical order

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data: array holding the data
	long *index: array of numbers representing the original order of the data, typically 0 to (n-1)
	long n: size of the array

RETURN VALUE:
	None

NOTE!
	- behaviour for non-numeric values, Inf and Nan is not specified
	- arrays with only one element will be unaltered
</blockquote></pre>

<font color="Black"><h3 id="code-xf_rand1_d"><a href="#CODE">&#8679</a> xf_rand1_d</h3></font>
[<a href="#tag-synthetic_data">synthetic_data</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate a double-precision random number from zero to [setmax]
	- calls function random(), which returns a float, normalized by RAND_MAX (unsigned long int)
	- a correction is made if setmax &#62 RAND_MAX

	Note that the calling function should set the random seed if more than one call is to be made on a given date
	This is necessary to avoid producng the same random sequency multiple times

USES:
	Many

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double setmax : largest possible value desired

RETURN VALUE:
	The random number

SAMPLE CALL:

	#include &#60stdlib.h&#62
	#include &#60stdio.h&#62
	#include &#60time.h&#62   // needed for time() function
	#include &#60unistd.h&#62	// needed for getpid() function

	double xf_rand1_d(double setmax);

	int main (int argc, char *argv[]) {
		// set the random seed using the current time and process-ID
		srand(time(NULL) + getpid());
		// generate 10 random numbers from zero to 100
		for(int i=0;i&#6010;i++) printf("%d: %f\n",i,xf_rand1f(100.0));
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_d"><a href="#CODE">&#8679</a> xf_readbin1_d</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to double
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a double

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*double data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,udouble,double,uint,int,ulong,long,double,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(double *)malloc(ntoread*sizeof(double)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= ntoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_d(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%g\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_f"><a href="#CODE">&#8679</a> xf_readbin1_f</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to float
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a float

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*float data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,ufloat,float,uint,int,ulong,long,float,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(float *)malloc(ntoread*sizeof(float)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= ntoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_f(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%g\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_i"><a href="#CODE">&#8679</a> xf_readbin1_i</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to int
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a int

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*int data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,uint,int,uint,int,ulong,long,int,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(int *)malloc(ntoread*sizeof(int)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= ntoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_i(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%d\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_l"><a href="#CODE">&#8679</a> xf_readbin1_l</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to long
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a long

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*long data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,ulong,long,uint,int,ulong,long,long,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(long *)malloc(ntoread*sizeof(long)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= ntoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_l(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%g\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_s"><a href="#CODE">&#8679</a> xf_readbin1_s</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to short
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a short

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*short data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,ushort,short,uint,int,ulong,long,short,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(short *)malloc(ntoread*sizeof(short)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= ntoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_s(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%g\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin1_v"><a href="#CODE">&#8679</a> xf_readbin1_v</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file
	This version accepts a pointer to the input stream - suitable for repeat calls and stdin

	On each call:
		- calling function passes a pointer to a pre-allocated void buffer, which holds the input
		- a pointer of the appropriate data-type is then pointed at the buffer
		- parameters[2] reports the number of data read

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin2_v
		That function allows the system to determine the optimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	off_t parameters : parameters defining input and output
		parameters[0] = size of each datum (bytes)
		parameters[1] = number of values to be read
		parameters[2] = output, number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: success

	parameters[2] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	void *buffer=NULL; // storage for data from each call
	unsigned short *data=NULL; // pointer to buffer assuming input is ushort
	off_t datasize=sizeof(unsigned int); // size of each datum in bytes
	off_t blocksize=1000; // define amount of data to be read on each call
	if((buffer=(void *)realloc(buffer,(blocksize*datasize)))==NULL) {fprintf(stderr,"\n--- Error[%s]: insufficient memory\n\n",thisprog);exit(1);};

	params[0]=datasize
	params[1]=blocksize;
	while(!feof(fpin)) {
		x= xf_readbin1_v(fpin,buffer,params,message);
		if(x&#600)	{fprintf(stderr,"\n*** %s/%s\n\n",thisprog,message); exit(1);}
		nread=params[2];
		if(nread==0) break;
		data=(unsigned short *)buffer;
		for(ii=0;ii&#60nread;ii++) printf("%hu\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin2_f"><a href="#CODE">&#8679</a> xf_readbin2_f</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read simple binary file into memory, converting to float
	fseeko is used to determine memory requirements, so DO NOT USE WITH STDIN
	This version handles file-opening and conversion to float internally
	If you want flexibility in what the data is converted to, use xf_readbin1_v instead

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpin : pointer to input stream/file
	off_t *parameters : pointer to an array of parameters defining behaviour (see below)
	char *message : an array to hold diagnostic messages on return

		parameters[0] = data type (0-9) uchar,char,ushort,short,uint,int,ulong,long,float.double
		parameters[1] = number of bytes at the top of the file (header) to ignore
		parameters[2] = number of numbers to skip (bytes skipped calculated based on size of data type)
		parameters[3] = number of numbers to be read
			- if set to zero, function attempts to read all bytes after header and skipped numbers
			- if set to zero, will be reset to the number of numbers read before the function finishes

RETURN VALUE:
	pointer to float array holding numbers, or NULL on error

SAMPLE CALL:
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin2_i"><a href="#CODE">&#8679</a> xf_readbin2_i</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:

	Read simple binary stream into memory from a file, converting to int
	This version accepts a pointer to the input stream - suitable for repeat calls

	On each call:
		- calling function designates the destination array
		- a temporary void buffer is allocated to hold the read results
		- a pointer of the appropriate data-type is pointed at the buffer
		- the void buffer is copied, via the pointer, to the destination array, casting each number as a int

	NOTE:
		To read an entire file with one function call, (~5 times faster), use xf_readbin1_v
		That function allows the system to determine the obtimal block read size
		However, because it also requires pre-determining the size of the input, it is not suitable for reading from piped streams

USES:
	Reading a binary input stream of unknown size in chunks
	Suitable for reading binary input from stdin


DEPENDENCY TREE:
	No dependencies


ARGUMENTS:
	FILE *fpin : pointer to input stream/file - assumes stream has already been successfully opened and error-checked
	*void buffer : pointer to pre-allocated array for temporary storage of bytes
	*int data1  : pointer to pre-allocated array for final, converted version of the data
	off_t parameters : parameters defining input and output
		parameters[0] = data type (0-9) uchar,char,uint,int,uint,int,ulong,long,int,double
		parameters[1] = size of each datum (bytes)
		parameters[2] = number of values to be read
		parameters[3] = number of values actually read (overwritten by this function)
	char *message : pointer to character string which is written to IF an error is encountered


RETURN VALUE:
	-1: error
	0: no data read
	1: data read

	parameters[3] will hold the actual number of data points read
	this may be less than parameters[1] (ntoread) if this is the last block of data read from the file


SAMPLE CALL:
	setdatatype=0; // unsigned char
	datasize=sizeof(unsigned char);
	ntoread=1000; // define amount of data to be read on each call
	bytestoread=(size_t)(0.5 + (ntoread*datasize));

	buffer=(void *)malloc(bytestoread); // allocate memory
	data=(int *)malloc(ntoread*sizeof(int)); // allocate memory

	parameters[0]= setdatatype;
	parameters[1]= datasize;
	parameters[2]= bytestoread;
	parameters[3]= 0;

	while(!feof(fpin)) {
		x= xf_readbin1_i(fpin,buffer,data,parameters,message);
		if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
		else if(parameters[3]==0)break;
		else for(ii=0;ii&#60parameters[3];ii++) printf("%g\n",data[ii]);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin2_v"><a href="#CODE">&#8679</a> xf_readbin2_v</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Fast-read a binary stream into memory from a file  (NOT SUITABLE FOR STDIN)

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpin : pointer to input stream/file
	void **data : pointer to void which will be assigned memory for bytes of data
	size_t startbyte : zero-offset position at which to start reading (eg. to skip a 500-byte header, set to 500)
	size_t bytestoread : number of bytes to read (if set to zero, will read all)
	char *message : an array to hold diagnostic messages on return

RETURN VALUE:
	number of bytes read, or 0 on failure ( error recorded in message[] )

SAMPLE CALL:
--------------------------------------------------------------------------------
	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62

	char infile[256];
	char message[256];
	void *data=NULL;
	size_t ii,nn;
	fpin=fopen(infile,"r");
	nn = xf_readbin2_v(fpin,&data,0,0,message);
	fclose(fpin);
	for(ii=0;ii&#60nn;ii++) printf("%ld	%g\n",ii,data[ii]);
	free(data)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbin3_v"><a href="#CODE">&#8679</a> xf_readbin3_v</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION: [ 23 June 2015: JRH ]

	Read a flat binary file into memory in one or more blocks (fast!) (NOT SUITABLE FOR STDIN)
	Handles file-opening internally
		- for chunk-wise reading of data, use xf_readbin1_*
		- for internal conversion from one format to another, use xf_readbin2_*

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	char *infile  : name of file to read
	off_t *params : binary read parameters array
		params[0] = datasize, size of data type (bytes) - for multichannel data consider using nchans*sizeof(type)
		params[1] = headerbytes, number of bytes at the top of the file to ignore
		params[2] = nblocks,  number of blocks of data to read (set to 0 to read the entire file)
		params[3] = output, total values read, set by this function
	off_t *start  : array of [nblocks], start-record-numbers marking the beginning of each read-block
	off_t *toread : array of [nblocks], block-sizes (number of records in each block, if 0, read to file end)
	char *message : an array to hold diagnostic messages on return

RETURN VALUE:
	no errors:
		pointer to array holding numbers, needs to be cast by calling function
		params[3] overwritten by total nnumber of records read
	error:
		NULL

NOTES
	- Any error for any block will invalidate the entire result - UNDEFINED PARTIAL-FILE-READS UNSUPPORTED
	- fseeko is used to determine memory requirements- DO NOT USE WITH STDIN
	- *start and *toread are converted internally to bytes, according to [datasize]
	- *start and *toread must be initialized by the calling function to hold at least one value
	- If no errors are reported, the total number of values read will be the sum of *toread
	- If nblocks (params[2]) = 0,
		nblocks becomes 1
		start[0] becomes 0
		toread[0] becomes the (filesize-headerbytes)/datasize
	- Blocks are allowed to overlap, and any block can be set to read any part of the file
		- that is, every block-read begins with a seek to the start of the file

SAMPLE CALL: READ 3 BLOCKS OF BINARY FLOAT DATA
	char message[256], infile="data.bin";
	int datasize=sizeof(float);
	long ii, nn=0, nblocks=3, headersize=0, start[3]={0,100,200}, nrecords[3]={12,12,12};
	long params[4]={datasize,headersize,nblocks,nn}
	void *datvoid=NULL;
	float *datfloat=NULL;

	datvoid= xf_readbin3_v(infile,params,start,nrecords,message);
	if(datvoid==NULL) { fprintf(stderr,"\n\t--- Error[%s/%s]\n\n",thisprog,message); exit(1); }
	if(nn&#601) {fprintf(stderr,"\n\t--- Error [%s]: .club file %s is empty\n",thisprog,clufile);exit(1);}
	nn=params[3];
	pfloat=(float *)datvoid;
	for(ii=0;ii&#60nn;ii++) printf("%f\n",pfloat[ii]);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readbinx1"><a href="#CODE">&#8679</a> xf_readbinx1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read BINX format binary input from a file or stdin
	BINX format:
		1. 500-byte header in 3 parts - the header is generated only once
			a. Filetype
			b. Parameters
			c. Text description
		2. The data, all of one type

	Because any data-type may be read, calling function should define pointers to all types for potential use

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpin : pointer to input stream/file
	void **data : pointer to void which will be assigned memory for bytes of data
	long *params : an array of the file parameters obtained from othe file header
		params[0] : header-size
			NOTE: calling function should initialize to 0 on first call to
			indicate to THIS function that the header still needs to be read
			NOTE: initializing to 1 will result only a summary of the header being output
		params[1] : data-size - i.e. the number of bytes in each datum (1,2,4 or 8)
		params[2] : data-type (0-9 = uchar,char,ushort,short,uint,int,ulong,long,float,double)
		params[3] : depth of dimension-1 - if data is 1-dimensional, this is also the total data-points
		params[4] : depth of dimension-2
		params[5] : depth of dimension-3

	char *message : an array to hold diagnostic messages on return

RETURN VALUE:
	(unsigned long) number of data points read, or 0 on error

SAMPLE CALL:
--------------------------------------------------------------------------------

	char infile[256];
	char message[256];
	void  *data0=NULL;
	float *data1=NULL;
	unsigned long i,j,k,n,m,params[6];
	FILE *fpin

	sprintf(infile,"myfile.dat");

	// read the data
	fpin=fopen(infile,"r");
	params[0] = -1;
	n = xf_readbinx1(fpin,&data0,params,message);
	fclose(fpin);

	// set up some aliases for easy reading - lets say we know the data is 2-dimensional
	unsigned long datatype = params[2];
	unsigned long ndim1 = params[3];
	unsigned long ndim2 = params[4];

	// set appropriate pointer , convert data0 to float
	short *p3;
	int *p5;
	long *p7;
	if(datatype==3) { p3 = data0; for(i=0;i&#60n;i++) data1[i]=(float)p3[i]; } // short
	if(datatype==5) { p5 = data0; for(i=0;i&#60n;i++) data1[i]=(float)p5[i]; } // int
	if(datatype==7) { p7 = data0; for(i=0;i&#60n;i++) data1[i]=(float)p7[i]; } // long

	// outut the data and the column (i) and row (j) labels
	for(i=j=k=0;i&#60n;i++) {
		printf("%d\t%d\t%g\n",j,k,data1[i]);
		if(++j == ndim1) { j=0; if(++k ==ndim2) k=0; }
	}

	// free the memory
	free(data0)
	free(data1)

	READ THE HEADER in 3 parts (FILETYPE,PARAMS,DESCRIPTION) if it hasn't already been read!
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readclub1"><a href="#CODE">&#8679</a> xf_readclub1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read a binary cluster-timestamp file (.clubt) and its complimentary cluster-id file (.club)

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile1:  file containing long-int (64-bit) timestamps
	char *infile2:  file containing short-int (16-bit) cluster-IDs
	long **clubt:   unallocated pointer for tinmestamp array, passed by calling function as &clubt
	short **club:   unallocated pointer for cluster-ID array, passed by calling function as &club
	char *message:  character array to hold messages, error-related or otherwise.

RETURN VALUE:
	The number of cluster records read
	-1 on failure

SAMPLE CALL:
	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62
	#include &#60string.h&#62
	#define thisprog "test the function"
	int main (int argc, char *argv[]) {
		char message[1000],infile1[256],infile2[256];
		long *clubt=NULL,ii,nn;
		short *club=NULL;
		sprintf(infile1,argv[1]); sprintf(infile2,argv[2]);
		nn = xf_readclub1(infile1,infile2,&clubt,&club,message);
		if(nn==-1) { fprintf(stderr,"\n\t--- Error: %s\n\n",message); exit(1); }
		for(ii=0;ii&#60nn;ii++) printf("%ld\t%d\n",clubt[ii],club[ii]);
		exit(0);
	}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readnlx_ncs"><a href="#CODE">&#8679</a> xf_readnlx_ncs</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-neuralynx">neuralynx</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read Neuralynx CSC (.ncs) files into memory - continuously sampled data

DEPENDENCIES:
	neuralynx.h

ARGUMENTS:
	char *infile : name of the input file
	float eegscale : user-defined multiplier for data - can be negative to "flip" data
	float *result : pre-allocated array to hold results - must allow at least 4 elements
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	success:
		- pointer to a float array of the data values on success
		- results array will be filled as follows:

			result[0]= (float) recordtot : number of EEG records
			result[1]= (float) validsamps : number of EEG samples per record
			result[2]= (float) eegtot : number of EEG samples
			result[3]= (float) samprate : EEG record sampling rate - accounts for number of valid samples per record
	error:
		- NULL
		- message array will hold explanatory text (if any)

SAMPLE CALL:
	x= xf_auc1_d(data, nn, interval, result, );
	if(x!=0) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

&#60TAGS&#62 file neuralynx&#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readscore1"><a href="#CODE">&#8679</a> xf_readscore1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read a SCORE binary file containing continuously sampled data (EEG, LFP)
	Data is stored as unsigned characters

	35-byte header + 4000  bytes of data (unsigned char)

		Type 	Content			Bytes	Comment
		char 	name[9]			9
		char 	date[9]			9
		char 	time[9]			9
		char 	channel 		1
		char 	epoch_length	1
		char	sample_rate 	1
		char	artefact_def	1
		char 	score			1
		char 	EMG 			1
		short	temp			2


USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile			: name of the file to read
	unsigned char **data	: pointer for an unsigned character array initialized to *data=NULL, and passed as &data
	int headers				: output headers to stdout (0=NO, 1=YES)
	char *message			: character array to hold messages, error-related or otherwise.

RETURN VALUE:
	The number of data-point read for each of the channels - multiply by nchans to get the total data read
	Zero on failure

SAMPLE CALL:

	char message[1000], infile[256];
	int nchans=4;
	size_t n;
	unsigned char *data1=NULL;

	sprintf(infile,"mydata.txt");

	n = xf_readscore1_s(infile,&data1,0,message);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readscore_raw1"><a href="#CODE">&#8679</a> xf_readscore_raw1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read a binary SCORE record (RAW file format) containing a header and continuously sampled 8-bit data (EEG, LFP)
	Assumes data is stored as unsigned characters
	This version reads a single SCORE raw record, storing but not processing the header and the data

USES:

DEPENDENCY TREE: No dependencies

ARGUMENTS:
	FILE *fpin     : pointer to input stream
	char *header   : pre-allocated array to hold the block header
	size_t nheader : number of bytes (characters) in the header (typically 35)
	unsigned char *data    : pre-allocated array to hold the block data
	size_t ndata   : number of data bytes to read (sample-frequency x numbers-in-record x 1)
	char *message  : character array to hold messages, error-related or otherwise.

RETURN VALUE:
	 0: success
	-1: failure

SAMPLE CALL:
	char message[1000], header[35], infile[256];
	int samplefreq=400, duration=10, ndata=samplefreq*duration;
	while(!feof(fpin)) {
		x= xf_readscore_raw1(fpin,header,nheader,data,ndata,data,message);
		if(x&#600) {fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1);)
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readssp1"><a href="#CODE">&#8679</a> xf_readssp1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read a binary Start-Stop-Pair file (.ssp) or equivalent stdin
	Data is stored as long integers (64-bit)

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile:   name of the file to read
	long **start:   unallocated pointer for start array passed by calling function as &start
	long **stop:    unallocated pointer for stop array passed by calling function as &start
	char *message:  character array to hold messages, error-related or otherwise.

RETURN VALUE:
	The number of start-stop pairs read
	-1 on failure
	0 if input was empty

SAMPLE CALL:

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62
	#include &#60string.h&#62
	#include &#60math.h&#62
	#define thisprog "test-function"

	char message[1000],*infile;
	long *start=NULL,*stop=NULL
	long ii,nn;

	infile="mydata.txt\0";
	nn = xf_readscore1_s(infile,&start,&stop,0,message);
	if(nn==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	for(ii=0;ii&#60nn;ii++) printf("%ld\t%ld\n",start[ii],stop[ii]);

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readwave1_f"><a href="#CODE">&#8679</a> xf_readwave1_f</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Read .wfm files (multi-channel spike waveform means for clustered data)
	- updated: 6.February.2017 [JRH]
	- assumes file has header something like this...

		PROBE 0
		N_CHANNELS 16
		CHANNEL_LIST 7,10,6,8,4,11,5,9,3,12,1,14,2,13,0,15
		SAMPLES_PER_CHANNEL 40
		SAMPLES_PRE_PEAK 8
		SAMPLE_RATE 19531.25
		WAVES_START

	- ...with one row per cluster to follow...

		id   count  v[1]  v[2]  v[3]  v[4] ... v[n]

	- ... where n= N_CHANNELS x SAMPLES_PER_CHANNEL, and the order is defined by CHANNEL_LIST


DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile    : input, name of .wfm file to read
	short **id      : output, pointer to array for cluster-ids for each waveform
	long **count    : output, pointer to array for spike-counts for each waveform
	long **data     : output, pointer to array for actual waveforms
	short **chanlist: output, pointer to array for order of channels in waveform
	long *result_l  : output, array to hold statistics related to the data
	char *message   : output, a string array to hold the status message

RETURN VALUE:
	on success: the sample-rate (Hz) as read from the header
	on failure: -1

	- also...

	- data[] will be assigned memory and filled with mean multi-channel waveforms
	- count[] will record the number of orignal waveforms contributing to the mean
	- id[] will hold the cluster-id for each waveform
	- chanlist[] will hold, in depth-order, the original channels contributing to the waveforms
	- result_l[] will hold information on the data
		result_l[0]= total waveforms read
		result_l[1]= number of channels contributing to each compound waveform
		result_l[2]= the number of samples corresponding to the waveform on a single channel
		result_l[3]= the number of samples preceding the peak
		result_l[4]= the total samples in the multi-channel waveform
		result_l[5]= largest cluster-number
		result_l[6]= the probe-number

SAMPLE CALL:

	short *cluid=NULL,*chanlist=NULL;
	long *count=NULL,result_l[16];
	float *data=NULL;

	samprate= xf_readwave1_f(filename,&cluid,&count,&data,&chanlist,result_l,message);
	if(samprate&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

	for(ii=0;ii&#60result_l[0];ii++) printf("cluster[%ld]= %ld\n",ii,cluid[ii]);

	free(data);free(id);free(count);free(chanlist);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_readwinltp1_f"><a href="#CODE">&#8679</a> xf_readwinltp1_f</h3></font>
[<a href="#tag-file">file</a>][<a href="#tag-slice">slice</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Read WinLTP files (.PO or .APO) containing sweeps for slice electrophysiology


DEPENDENCIES:
	long *xf_lineparse1(char *line,long *nwords);

ARGUMENTS:
	char *setinfile  : input, name of the file to read
	char *setchan    : input, name of channel to read (typically AD0 or AD1)
	float **data1    : output, dynamically allocated array to hold data - calling function passes &data1 to this function
	double *result_d : output, array of info related to the file
	char *message    : output, a string array to hold the status message

RETURN VALUE:
	on success: nsamples, = the number of samples read for the channel
	on failure: -1
	- data1[] will be assigned memory and filled [nsamples] datapoints
	- result_d[] will hold information on the data
		result_d[0]= sample-interval (ms)
		result_d[1]= sample-rate (Hz)
		result_d[2]= duration of pre-stimulus baseline (ms)

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_readxyd1"><a href="#CODE">&#8679</a> xf_readxyd1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Read a binary position-timestamp file (.xydt) and its complementary x-y-direction triplet file (.xyd)

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *infile1: file containing long-int (64-bit) timestamps
	char *infile2: file containing floating-point (32-bit) position data in triplets (x,y,direction)
	long **post:   unallocated pointer for the timestamp array, passed by calling function as &post
	long **posx:   unallocated pointer for the x-position array, passed by calling function as &posx
	long **posy:   unallocated pointer for the y-position array, passed by calling function as &posy
	long **posd:   unallocated pointer for the direction array, passed by calling function as &posd
	char *message: character array to hold messages, error-related or otherwise.

RETURN VALUE:
	The number of posx-posy-posd triplets read
	-1 on failure

SAMPLE CALL:
	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62
	#include &#60string.h&#62
	#define thisprog "test the function"
	int main (int argc, char *argv[]) {
		char message[1000],infile1[256],infile2[256];
		long *post=NULL,ii,nn;
		float *posx=NULL,*posy=NULL,*posd=NULL;
		sprintf(infile1,argv[1]); sprintf(infile2,argv[2]);
		nn = xf_readxyd1(infile1,infile2,&posx,&posy,&posd,message);
		if(nn==-1) { fprintf(stderr,"\n\t--- Error: %s\n\n",message); exit(1); }
		for(ii=0;ii&#60nn;ii++) printf("%ld\t%f\t%f\t%f\n",posxt[ii],posx[ii],posy[ii],posd[ii]);
		exit(0);
	}

</blockquote></pre>

<font color="Black"><h3 id="code-xf_resample1"><a href="#CODE">&#8679</a> xf_resample1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Resample a series of numbers so there are a user-defined number of elements [setn]
	If actual n &#60 setn, data is split as required
	If acctual n&#62 setn, data is binned and averaged accordingly

	Alters input array
	NAN values will be ignored, but INF will affect the results

USES:
	- binning an array of number
	- modifying different series of data so they are all the same length
	- making an irregular matrix of data have rowa all the same length

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data: input, array of numbers to be resampled
	long n: input, number of elements in data
	long setn: input, the new number of elements requested for data

RETURN VALUE:
	Pointer to modified data array - NULL if n &#60 setn and memory allocation error occurs

SAMPLE CALL:

TO DO:
	- consider using a Gaussian kernal for resampling
</blockquote></pre>

<font color="Black"><h3 id="code-xf_resample1_d"><a href="#CODE">&#8679</a> xf_resample1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Resample a series of numbers so there are a user-defined number of elements [setn]
	If actual n &#60 setn, data is split as required
	If acctual n&#62 setn, data is binned and averaged accordingly

	Alters input array
	NAN values will be ignored, but INF will affect the results

USES:
	- binning an array of number
	- modifying different series of data so they are all the same length
	- making an irregular matrix of data have rowa all the same length

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data: input, array of numbers to be resampled
	long n: input, number of elements in data
	long setn: input, the new number of elements requested for data

RETURN VALUE:
	Pointer to modified data array - NULL if n &#60 setn and memory allocation error occurs

SAMPLE CALL:

TO DO:
	- consider using a Gaussian kernal for resampling
</blockquote></pre>

<font color="Black"><h3 id="code-xf_rewindow2_ls"><a href="#CODE">&#8679</a> xf_rewindow2_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Make new event-time and event-class arrays based on events inside windows centred on reference-class events
	Builds new time and class arrays using only data from the reference class and events in a window around them
	This function ensures no duplication of events, and the sequence of events is preserved
	Method:
	- identifies reference events
	- builds new array from events in a window around the reference event
	- cuts the window short if another reference-class event is encountered in the window
	- skips to next event falling outside the window and repeat
	- does not include events from previous windows when looking back

	12.November.2016 [JRH]: based on xf_rewindow1, 20 November 2011

USES:
	Speed up calculation of cross-correlations cells-pairs

ARGUMENTS:
	long  *t1    : input, array of event timestamps
	short *c1    : input, array of the class-ids for each event
	long   n1    : input, number of elements in t1 and c1
	short  id    : input, the class-id of events on which to centre the time windows
	long winsize : input, the size (samples) of the time-windows
	long  *t2    : output, preallocated array to store event times
	short *c2    : output, preallocated array to store event class-ids

RETURN VALUE:
	n2, the number of elements in the new time and class-id arrays

NOTES:
	t1 and c1 should be filled before calling this function
	t2 and c2 must have adequate memory allocated before calling this function.
	It should be possible for t2 and c2 to hold up the same number of elements as the input arrays

</blockquote></pre>

<font color="Black"><h3 id="code-xf_rms1_d"><a href="#CODE">&#8679</a> xf_rms1_d</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the root-mean-square (RMS) power in an array
	- This is the square root of the mean of the summed squared-values
	- NAN and INF values will be ignored

USES:
	Signal analysis

DEPENDENCIES:
	No dependencies

ARGUMENTS:

	double *input : pointer to array holding amplitude time series to be converted to RMS power
	long nn       : length of the input
	char *message : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	RMS value on success
	NAN on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_rms1_f"><a href="#CODE">&#8679</a> xf_rms1_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Calculate the root-mean-square (RMS) power in an array
	- This is the square root of the mean of the summed squared-values
	- NAN and INF values will be ignored

USES:
	Signal analysis

DEPENDENCIES:
	No dependencies

ARGUMENTS:

	float *input : pointer to array holding amplitude time series to be converted to RMS power
	long nn       : length of the input
	char *message : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	RMS value on success
	NAN on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_rms2_d"><a href="#CODE">&#8679</a> xf_rms2_d</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the root-mean-square (RMS) power in an array
	Uses a single-sample-step sliding window, so output is same length as input
	Output values will ramp up at the beginning and ramp down at the end
	More efficient than calculating RMS in 50% overlapping windows, but requires extra memory (length of data)

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
			- in such cases it is recommended to interpolate the input before passing to this function

USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *input   : pointer to array holding amplitude time series to be converted to RMS power
	double *output  : pointer to array holding the RMS result - calling function must allocate memory
	size_t nn      : length of the input & output arrays
	size_t nwin1   : length of the window in which to calculate RMS power
						- ideally 4-5 times the wavelength of a frequency of interest
						- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length

	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_rms2_f"><a href="#CODE">&#8679</a> xf_rms2_f</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the root-mean-square (RMS) power in an array
	Uses a single-sample-step sliding window, so output is same length as input
	Output values will ramp up at the beginning and ramp down at the end
	More efficient than calculating RMS in 50% overlapping windows, but requires extra memory (length of data)

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
	- in such cases it is recommended to interpolate the input before passing to this function

USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	float *input   : pointer to array holding amplitude time series to be converted to RMS power
	float *output  : pointer to array holding the RMS result - calling function must allocate memory
	size_t nn      : length of the input & output arrays
	size_t nwin1   : length of the window in which to calculate RMS power
						- ideally 4-5 times the wavelength of a frequency of interest
						- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length

	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_rollbuffer1_f"><a href="#CODE">&#8679</a> xf_rollbuffer1_f</h3></font>
[<a href="#tag-misc">misc</a>]<br>
<blockquote><pre>DESCRIPTION:
	"roll" the data in a circular buffer, typically to prepare for the addition of additional data

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpin : pointer to input stream/file
	void **buffer1 : pointer to circular buffer to be rolled
	size_t nbuff : number of elements in the buffer
	size_t offset : the amount (number of elements) by which to roll the buffer
	int type : the type of rolling...
		1) forward, entire buffer
		2) forward, dont fill the top with the bottom - use if the top is later to be filled with new data
		3) forward, only fill the top with the bottom - use if the bottom is later to be filled with new data
		4) backward, entire buffer
		6) backward, don't fill the bottom with the top - use if the bottom is later to be filled with new data
		6) backward, only fill the bottom with the top - use if the top is later to be filled with new data
	char *message : an array to hold diagnostic messages on return

RETURN VALUE:
	0 on success, -1 on error

SAMPLE CALL:

	nn=13; offset=3; type=1;
	for(ii=0;ii&#60nn;ii++) data[ii]=(float)ii;
	x= xf_rollbuffer1(data,nn,offset,type,message);
	if(x&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	for(ii=0;ii&#6013;ii++) printf("%ld\t%g\n",ii,data_f[ii]);

	0	10
	1	11
	2	12
	3	0
	4	1
	5	2
	6	3
	7	4
	8	5
	9	6
	10	7
	11	8
	12	9


--------------------------------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xf_round1_d"><a href="#CODE">&#8679</a> xf_round1_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Round a double-precision number to the nearest desired base

	* If input is not finite (INF or NAN) no rounding is attempted
	* Result may in fact have zeros added for a few decimal places after desired precision
		Example: 49.974998 rounded to 3 decimal places may become 49.975002
	* This is due to the use of nextafter() to increment the numbers slightly
	* This ensures that when using a formatted print to display the numbers, rounding is in the right direction
	* It also means that a precise input (50.000000) may become slightly less precise (50.000004)

REVISIONS:
	14 April 2014: fix rounding for negative numbers (subtract 0.5, don't add)
	4 November 2015: fix rounding for negative numbers (prevent negative numbers from rounding to zero)

	DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double input : input number
	double base : nearest number to round to  (eg. 0.1, 1, 100, 9 etc)
	int setdown : use standard rounding (0) or force to round down (1)

RETURN VALUE:
	The rounded number
	NOTE: if input is not finite (INF or NAN) no rounding is attempted

SAMPLE CALLS:
	x= round1_d( 105, 10,0); # rounds 105 to the nearest ten, so x=110
	x= round1_d( 105, 10,1); # rounds 105 down to the nearest ten, so x=100
</blockquote></pre>

<font color="Black"><h3 id="code-xf_round1_f"><a href="#CODE">&#8679</a> xf_round1_f</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Round a floating-point number to the nearest desired base

	* If input is not finite (INF or NAN) no rounding is attempted
	* Result may in fact have zeros added for a few decimal places after desired precision
		Example: 49.974998 rounded to 3 decimal places may become 49.975002
	* This is due to the use of nextafterf() to increment the numbers slightly
	* This ensures that when using a formatted print to display the numbers, rounding is in the right direction
	* It also means that a precise input (50.000000) may become slightly less precise (50.000004)

REVISIONS:
	14 April 2014: fix rounding for negative numbers (subtract 0.5, don't add)
	4 November 2015: fix rounding for negative numbers (prevent negative numbers from rounding to zero)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float input : input number
	float base : nearest number to round to  (eg. 0.1, 1, 100, 9 etc)
	int setdown : use standard rounding (0) or force to round down (1)

RETURN VALUE:
	The rounded number
	NOTE: if input is not finite (INF or NAN) no rounding is attempted

SAMPLE CALLS:
	x= round1_f( 105, 10,0); # rounds 105 to the nearest ten, so x=110
	x= round1_f( 105, 10,1); # rounds 105 down to the nearest ten, so x=100

</blockquote></pre>

<font color="Black"><h3 id="code-xf_round2_d"><a href="#CODE">&#8679</a> xf_round2_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Round an array of double-precision numbers to the nearest desired base

	* If input is not finite (INF or NAN) no rounding is attempted
	* Result may in fact have zeros added for a few decimal places after desired precision
		Example: 49.974998 rounded to 3 decimal places may become 49.975002
	* This is due to the use of nextafter() to increment the numbers slightly
	* This ensures that when using a formatted print to display the numbers, rounding is in the right direction
	* It also means that a precise input (50.000000) may become slightly less precise (50.000004)

REVISIONS:
	14 April 2014: fix rounding for negative numbers (subtract 0.5, don't add)
	4 November 2015: fix rounding for negative numbers (prevent negative numbers from rounding to zero)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double input : input array
	size_t nn : size of array
	double base : nearest number to round to  (eg. 0.1, 1, 100, 9 etc)
	int setdown : use standard rounding (0) or force to round down (1)

RETURN VALUE:
	zero (no errors possible)
	NOTE: input array is modified

SAMPLE CALLS:
	x= round2_d( array, 10000, 10,0); # if encountered, rounds 105 to the nearest ten, so x=110
	x= round2_d( array, 10000, 10,1); # if encountered, rounds 105 down to the nearest ten, so x=100

</blockquote></pre>

<font color="Black"><h3 id="code-xf_samplefreq1_d"><a href="#CODE">&#8679</a> xf_samplefreq1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate sample frequency for a series of timestamps ( 1 / median_sample_interval )

USES:


DEPENDENCIES:
	xf_compare1_d

ARGUMENTS:
	double *time: array holding the time-stamps
	long n1: number of elements in the time array - must be &#621
	char *message: string to hold error message on fail

RETURN VALUE:
	sample frequency, 0 if fail

SAMPLE CALL:
	samplefreq= xf_samplefreq1_d(time,n1,message);
	if(samplefreq==0) {
		fprintf(stderr,"Error: %s \n",message);
		exit(1);
	}
</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_club"><a href="#CODE">&#8679</a> xf_screen_club</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>][<a href="#tag-spikes">spikes</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen time-series club using start-stop pairs (keep club falling between the pairs)
	- NOTE: timestamps (clubt) will be adjusted, because they are part of the club/t parallel-array structure

USES:
	- keeping only chunks of club falling within certain time-windows

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start : input array of start-times used for screening
	long *stop  : input array of stop-times used for screening
	long nssp   : number of SSPs in total
	long *clubt : input array of club timestamps
	short *club : input array of club cluster-id's
	long nclub  : total number of items in the clubt[]] and club[] arrays
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	the number of clubt[] and club[] samples passing the screening (-1 on error)
	the original clubt[] and club[] arrays will typically be reduced

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_lf"><a href="#CODE">&#8679</a> xf_screen_lf</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen time-series data using start-stop pairs (keep data falling between the pairs)
	- NOTE: timestamps are not adjusted

USES:
	- keeping only chunks of data falling within certain time-windows

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start : input array of start-times used for screening
	long *stop  : input array of stop-times used for screening
	long nssp   : number of SSPs in total
	long *time1  : input array of data timestamps
	float *data : input array of data
	long ndata  : total number of items in the time[] and data[] arrays
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	success: - the number of data[] samples passing the screening
	         - the original data[] array will typically be reduced
	error: -1

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_ls"><a href="#CODE">&#8679</a> xf_screen_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen time-series data using start-stop pairs (keep data falling between the pairs)
	- NOTE: timestamps are not adjusted

USES:
	- keeping only chunks of data falling within certain time-windows

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start : input array of start-times used for screening
	long *stop  : input array of stop-times used for screening
	long nssp   : number of SSPs in total
	long *time1  : input array of data timestamps
	short *data : input array of data
	long ndata  : total number of items in the time[] and data[] arrays
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	success: - the number of data[] samples passing the screening
		 - the original data[] array will typically be reduced
	error: -1

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_ssp1"><a href="#CODE">&#8679</a> xf_screen_ssp1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen ldas5 SSP (start2-stop2 pair) data using a second set of start1-stop1 pairs (screen)
	- keep only pairs overlapping (mode 1) or not-overlapping (mode2) the screening pairs

USES:
	- selecting mutually inclusive sets of SSPs

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start1 : input array of start1-times used for screening
	long *stop1  : input array of stop1-times used for screening
	long nssp1   : number of screening SSPs in total
	long *start2 : input array of start-times to be screened
	long *stop2  : input array of stop-times to be screened
	long nssp2   : number of SSPs to be screened
	int mode     : keep (1) or reject (2) start2/stop2 pairs falling within start1/stop1 bounds
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	the number of start2/stop2 pairs passing the screening (new size of start2/stop2 arrays)
	-1 on error

	NOTE: modifies the input start2/stop2 arrays

SAMPLE CALL: keep only start2/stop2 pairs which fall within the boundaries defined by start1/stop1

	mm= xf_screen_ssp1(start1,stop1,nssp1,start2,stop2,nssp2,1,message);
	if(mm==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	nssp2=mm;

</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_ssp2"><a href="#CODE">&#8679</a> xf_screen_ssp2</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen ldas5 SSP (start1-stop1 pair) data using a second set of start1-stop1 pairs (screen)
	- keep only pairs overlapping (mode 1) or not-overlapping (mode2) the screening pairs
	- unlike xf_screen_ssp1, this function also adjusts a third timestamp (for example a midpoint or peak timestamp)

USES:
	- selecting mutually inclusive sets of SSPs

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start1 : input array of start1-times used for screening
	long *stop1  : input array of stop1-times used for screening
	long nssp1   : number of screening SSPs in total
	long *start2 : input array of start-times to be screened
	long *stop2  : input array of stop-times to be screened
	long *extra2 : additional input array to be included for screenening
	long nssp2   : number of SSPs to be screened
	int mode     : keep (1) or reject (2) start2/stop2 pairs falling within start1/stop1 bounds
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	the number of start2/stop2 pairs passing the screening (new size of start2/stop2 arrays)
	-1 on error

	NOTE: modifies the input start2/stop2 arrays

SAMPLE CALL: keep only start2/stop2 pairs which fall within the boundaries defined by start1/stop1

	mm= xf_screen_ssp1(start1,stop1,nssp1,start2,stop2,nssp2,1,message);
	if(mm==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
	nssp2=mm;

</blockquote></pre>

<font color="Black"><h3 id="code-xf_screen_xyd"><a href="#CODE">&#8679</a> xf_screen_xyd</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-screen">screen</a>]<br>
<blockquote><pre>DESCRIPTION:
	- screen ldas5 XYD(T) data using start-stop pairs (keep data falling between the pairs)
	- NOTE: timestamps (xydt) will be adjusted, because they are part of the xyd/t parallel-array structure

USES:
	- keeping only chunks of data falling within certain time-windows

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start : input array of start-times used for screening
	long *stop  : input array of stop-times used for screening
	long nssp   : number of SSPs in total
	long *xydt  : input array of xyd timestamps
	float *xydx : input array of x-values
	float *xydy : input array of y-values
	float *xydd : input array of direction-values
	long ndata  : total number of items in the time[] and data[] arrays
	char *message : pre-allocated array to hold error message


RETURN VALUE:
	the number of xyd(t) samples passing the screening (-1 on error)
	the original arrays will typically be reduced

SAMPLE CALL:
	mm= xf_screen_xyd(start1,stop1,nlist,xydt,xydx,xydy,xydd,nn,message);
	if(mm==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }


</blockquote></pre>

<font color="Black"><h3 id="code-xf_smooth2d_gaussd"><a href="#CODE">&#8679</a> xf_smooth2d_gaussd</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Uses a Gaussian kernal to smooth a 2-dimensional array of data
	Modifies array data[xbin][ybin]
	Note that if xsmooth=0 or ysmooth=0 the results may be unpredictable
	6 November 2012: fix so that xsmooth or ysmooth can now be zero
</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothbox1_d"><a href="#CODE">&#8679</a> xf_smoothbox1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a boxcar-averaging smoother to a data series
	Acts as a low-pass filter
	Uses a single-sample-step sliding window, so output is same length as input
	Data at the beginning and end of the input is adjsted by a fraction of the window size not less than 1/2

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
			- in such cases it is recommended to interpolate the input before passing to this function

	update: 2015 March 13: add correction for last sample

USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *input   : pointer to array holding amplitude time series to be smoothed
	double *output  : pointer to array holding the result - calling function must allocate memory
	size_t nn      : length of the input & output arrays
	size_t nwin1   : length of the window in which to calculate the average
						- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothbox1_f"><a href="#CODE">&#8679</a> xf_smoothbox1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a boxcar-averaging smoother to a data series
	Acts as a low-pass filter
	Uses a single-sample-step sliding window, so output is same length as input
	Data at the beginning and end of the input is adjsted by a fraction of the window size not less than 1/2

	NOTE: if input contains invalid values, NAN or INF, output will be invalid
			- in such cases it is recommended to interpolate the input before passing to this function

	update: 2015 March 13: add correction for last sample

USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	double *input   : pointer to array holding amplitude time series to be smoothed
	double *output  : pointer to array holding the result - calling function must allocate memory
	size_t nn      : length of the input & output arrays
	size_t nwin1   : length of the window in which to calculate the average
			- this value will be increased by 1 if not an odd number, or decreased if this exceeds the data length
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothbox2_d"><a href="#CODE">&#8679</a> xf_smoothbox2_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a boxcar-averaging smoother to a data series
	Acts as a low-pass filter
	Uses a single-sample-step sliding window
	Data at the beginning and end of the data (half-window) is replicated (sample-and-hold)
	This version uses an internal buffer so that the data array can be overwriten
		- hence, no memory required for an output array

	NOTE: if data contains invalid values, NAN or INF, output will be invalid
		- in such cases it is recommended to interpolate the data before passing to this function
USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data   : pointer to array holding time series to be smoothed
	size_t nn      : length of the data & output arrays
	size_t halfwin : half-window size of the smoothing window - final window will be (halfwin*2)+1
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	 0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothbox2_f"><a href="#CODE">&#8679</a> xf_smoothbox2_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Apply a boxcar-averaging smoother to a data series (acts as a low-pass filter)
	Uses a single-sample-step sliding window
	Data at the beginning and end of the data is the average of a fraction of a window looking forward/backward, respectively
	This version uses an internal buffer so that the data array can be overwriten
		- hence, no memory required for an output array

	NOTE: if data contains invalid values, NAN or INF, output will be invalid
		- in such cases it is recommended to interpolate the data before passing to this function
USES:
	Signal analysis

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data    : pointer to array holding time series to be smoothed
	size_t nn      : length of the data & output arrays
	size_t halfwin : half-window size of the smoothing window - final window will be (halfwin*2)+1
	char *message  : feedback returned to the calling function, which should allocate memory for this array (256 characters)

RETURN VALUE:
	 0 on success
	-1 on error

</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgauss0_d"><a href="#CODE">&#8679</a> xf_smoothgauss0_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Smooth a double float array of size "arraysize" using a Gaussian kernel
	- will ignore NaN and Inf values in input array (just passes them back)
	- this version only modifies a single sample in the array

ARGUMENTS:
	float *original   : pointer to data to be smoothed (memory must be pre-allocated)
	size_t arraysize  : number of elements in original array
	size_t index      : index to the sample to be smoothed
	int smooth        : half-size of smoothing window - full size = 2*smooth + 1
	double *result    : address of variable to hold the result (passed as &result)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgauss0_f"><a href="#CODE">&#8679</a> xf_smoothgauss0_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Smooth a float array of size "arraysize" using a Gaussian kernel
	- will ignore NaN and Inf values in input array (just passes them back)
	- this version only modifies a single sample in the array

ARGUMENTS:
	float *original   : pointer to data to be smoothed (memory must be pre-allocated)
	size_t arraysize  : number of elements in original array
	size_t index      : index to the sample to be smoothed
	int smooth        : half-size of smoothing window - full size = 2*smooth + 1
	double *result    : address of variable to hold the result (passed as &result)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgauss1_d"><a href="#CODE">&#8679</a> xf_smoothgauss1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Smooth a double float array of size "arraysize" using a Gaussian kernel
	Will ignore NaN and Inf values in input array (just passes them back)
ARGUMENTS:
	float *original	: pointer to data to be smoothed (memory must be pre-allocated)
	size_t arraysize   : number of elements in original array
	int smooth      : half-size of smoothing window - full size = 2*smooth + 1

New version - May 13 2011: will not adjust NaN or Inf entries
New version - Nov 6 2012:  eliminate error reporting in-function and thisfunc variable
New version - June 30 2013: uses size_t for array length
</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgauss1_f"><a href="#CODE">&#8679</a> xf_smoothgauss1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Smooth a float array of size "arraysize" using a Gaussian kernel
	Will ignore NaN and Inf values in input array (just passes them back)
ARGUMENTS:
	float *original	: pointer to data to be smoothed (memory must be pre-allocated)
	size_t arraysize   : number of elements in original array
	int smooth      : half-size of smoothing window - full size = 2*smooth + 1

New version - May 13 2011: will not adjust NaN or Inf entries
New version - Nov 6 2012:  eliminate error reporting in-function and thisfunc variable
New version - June 30 2013: uses size_t for array length
</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgauss2_d"><a href="#CODE">&#8679</a> xf_smoothgauss2_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Uses a Gaussian kernal to smooth a 2-dimensional array of data
	Modifies array data[xbin][ybin]

8 March 2013:
	new name  xf_smoothgauss2_d
	no longer accepts an "invalid" argument
	assumes NAN or INF are invalid instead

6 November 2012: fix so that xsmooth or ysmooth can now be zero

</blockquote></pre>

<font color="Black"><h3 id="code-xf_smoothgaussd"><a href="#CODE">&#8679</a> xf_smoothgaussd</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION:
	Smooth a double-precision float array of size "arraysize" using a Gaussian kernel
	New version (May 13 2011) will ignore NaN and Inf values in input array (just passes them back)
ARGUMENTS:
	float *original	: pointer to data to be smoothed (memory must be pre-allocated)
	int arraysize   : number of elements in original array
	int smooth      : half-size of smoothing window - full size = 2*smooth + 1
	char message    : string to hold messages upon return

New version - May 13 2011: will not adjust NaN or Inf entries
New version - Nov 6 2012:  eliminate error reporting in-function and thisfunc variable
</blockquote></pre>

<font color="Black"><h3 id="code-xf_spearmans1_f"><a href="#CODE">&#8679</a> xf_spearmans1_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION :
	Find the Spearman's rank correlation for pairs of data

USES:


DEPENDENCIES:
	xf_qsortindex1_f(xdat2,xrank,ndata);

ARGUMENTS:
	float *data1   : array of voltage values for multi-channel dataform #1
	float *data2   : array of voltage values for multi-channel dataform #2
	long ndata     : the number of elements in data1 and data2
	char *message  : a string array to hold a status message

RETURN VALUE:
	on success: Spearman's rho
	on failure: NAN
</blockquote></pre>

<font color="Black"><h3 id="code-xf_spectdenoise1_d"><a href="#CODE">&#8679</a> xf_spectdenoise1_d</h3></font>
[<a href="#tag-matrix">matrix</a>][<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-spectra">spectra</a>]<br>
<blockquote><pre>DESCRIPTION:
	Remove noise from a spectral-matrix (time x freq)
 	- noise=  single-timepoint decrease/increase that span many adjacent frequencies
 	- timeseries for each freq. converted to Z-scores for thresholding
 	- outputs a modified matrix with noise-timepoints set to NAN
	- percentages for positive and negative threhold crossings are calculated separately

USES:
	cleaning up spectral matrices

DEPENDENCIES:
	xf_matrixrotate2_d

ARGUMENTS:
	double *matrix1 : input holding matrix
	long width      : number of columns (time)
	long height     : number of rows (frequencies)
	double setclip  : max permissable value for z-score calculation (-1=noclip) - avoids skewing of the z-scores by extreme outliers
	double setz     : Z-score threshold for noise at each freq (typically 1)
	int setsign     : detect negative (-1) or positive (+1) threshold crossings, or both (0)
	double setper   : % of adjacent freq &#62 sd needed to invalidate timepoint (typically 25)
	int setrotate   : specify if input is rotated 90-degrees so row=time (0=NO 1=YES)
	char *message   : pre-allocated array to hold error message

RETURN VALUE:
	number of invalidated frequencies (columns) on success, -1 on error
	char array will hold message (if any)

SAMPLE CALL:
	noisecount= xf_spectdenoise1_d(matrix,nn,width,height,-1,3,25,0,0,message);
	if(noisecount==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

&#60TAGS&#62matrix,signal_processing,spectra&#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_spline1_d"><a href="#CODE">&#8679</a> xf_spline1_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Performs SPLine INTerpolation, based on the splint and spline functions from Numerical Recipes in C
		xin[] and yin[] are the original X and Y arrays, of size "nin"
		xout[] will be filled with n="nout" evenly spaced values filling the original range
		yout[] will be filled with the interpolated arrays of size "nout"
		
NOTE_1: Sufficient memory must be pre-alocated for xout and yout, based on the size of nout
</blockquote></pre>

<font color="Black"><h3 id="code-xf_sspsplit1_l"><a href="#CODE">&#8679</a> xf_sspsplit1_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	- split start-stop pairs into smaller sub-windows of fixed size

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *start   : pointer to original start array
	long *stop    : pointer to original stop array
	long nssp     : number of elements in start[] & stop[]
	long winsize  : size of sub-windows (samples)
	long **start  : unallocated pointer for results start array passed by calling function as &start2
	long **stop   : unallocated pointer for results stop array passed by calling function as &start2
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	success:
		- new size of start[] and stop[] arrays
		- start[] and stop[] arrays will be modified
	error:
		-1
		message array will hold error message

SAMPLE CALL:
	nn = xf_sspplit1_l(&start,&stop,nssp,25,&start2,&stop2,message);
	if(nn&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_stats1_d"><a href="#CODE">&#8679</a> xf_stats1_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate summary statistics on an array of numbers (double-precision floating-point)
	This is the fastest of the stats family of functions - mean only is calculated
	Option to use high-precision calculation for large datasets (setlarge)
		- here the mean is first calculated by breaking the double-values into integer and fractional parts
		- then the individual dibberences from the  mean are calculated
		- the sums used for calculating the standard deviation are also similarly adjusted
	NOTE: no check for invalid values (NAN or INF)
USES:
	Getting the mean of a data set
DEPENDENCY TRcc:
	No dependencies
ARGUMENTS:
	double *data1: array holding the data
	long nn: number of elements in the array
	int large: a flag specifying the method for dealing with large datasets
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large datasets
	double *result_d: array to hold result of calculations
RETURN VALUE:
	zero
SAMPLE CALL:
	xf_stats1_d(data,n,1,result_d); mean=result_d[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_stats2_d"><a href="#CODE">&#8679</a> xf_stats2_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate summary statistics on an array of numbers (double-precision floating-point)
	Option to use high-precision calculation for large datasets (setlarge)
		- here the mean is first calculated by breaking the double-values into integer and fractional parts
		- then the individual differences from the  mean are calculated
		- the sums used for calculating the standard deviation are also similarly adjusted
	NOTE: no check for invalid values (NAN or INF)
USES:
	Getting the mean, stdev, etc. of a data set
DEPENDENCY TREE:
	No dependencies
ARGUMENTS:
	double *data1: array holding the data
	long n: number of elements in the array
	int large: a flag specifying the method for dealing with large datasets
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large datasets
	double *result_d: array to hold result of calculations
RETURN VALUE:
	zero
SAMPLE CALL:
	xf_stats2_d (data,n,1,result_d); mean=result_d[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_stats2_f"><a href="#CODE">&#8679</a> xf_stats2_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate summary statistics on an array of numbers (floating-point)
	Option to use high-precision calculation for large datasets (setlarge)
		- here the mean is first calculated by breaking the double-values into integer and fractional parts
		- then the individual differences from the  mean are calculated
		- the sums used for calculating the standard deviation are also similarly adjusted
	NOTE: no check for invalid values (NAN or INF)
USES:
	Getting the mean, stdev, etc. of a data set
DEPENDENCY TREE:
	No dependencies
ARGUMENTS:
	float *data1    : array holding the data
	long nn         : number of elements in the array
	int large       : a flag specifying the method for dealing with large datasets
		              1 = traditional fast computational formula
		              2 = two-pass method, slower but not prone to overflow errors with very large datasets
	float *result_f : array to hold result of calculations
RETURN VALUE:
	zero
SAMPLE CALL:
	xf_stats2_f (data,nn,1,result); mean=result[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_stats3_d"><a href="#CODE">&#8679</a> xf_stats3_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate summary statistics on an array of numbers (double-precision floating-point)
	Similar to xf_stats2_d, but NAN or INF values are treated as missing values and do not affect results

USES:
	Getting the mean, stdev, etc. of a data set

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data1: array holding the data
	long n1: number of elements in the array
	int setlarge: a flag specifying the method for calculating the mean and variance
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large datasets
	double *result_d: array to hold result of calculations

RETURN VALUE:
	The number of valid data-points used in calculations (finite numbers, not NAN or INF)
	On error:
		-1: insufficient number of samples
		-2: memory allocation error
		-3: no valid numbers in data

SAMPLE CALL:
	xf_stats3_d(data,n1,1,result); mean=result[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_stats3_f"><a href="#CODE">&#8679</a> xf_stats3_f</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate summary statistics on an array of numbers (floating-point)
	Similar to xf_stats2_f, but NAN or INF values are treated as missing values and do not affect results

USES:
	Getting the mean, stdev, etc. of a data set

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *data1: array holding the data
	long n1: number of elements in the array
	int setlarge: a flag specifying the method for calculating the mean and variance
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large datasets
	float *result_f: array to hold result of calculations

RETURN VALUE:
	The number of valid data-points used in calculations (finite numbers, not NAN or INF)
	On error:
		-1: insufficient number of samples
		-2: memory allocation error
		-3: no valid numbers in data

SAMPLE CALL:
	xf_stats3_f(data,n1,1,result); mean=result[0];
</blockquote></pre>

<font color="Black"><h3 id="code-xf_strcat1"><a href="#CODE">&#8679</a> xf_strcat1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	- safe concatenation of two input strings, using a delimiter of choice
	- allocates sufficient memory for the expanded string before calling strcat

ARGUMENTS:
	char *string1   : first input string - the one to be lengthened
	char *string2   : second input string - to be added to string1, must be defined
	char *delimiter : the delimiter to put between them, must be defined

RETURN VALUE:
	Pointer to the lengthened string1, or NULL on failure

</blockquote></pre>

<font color="Black"><h3 id="code-xf_strcut1"><a href="#CODE">&#8679</a> xf_strcut1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Find the portion of string before or after a delimiter
	User determines whether the first or last delimiter is used
	User determines whether the preceeding or following portion of the input string is returned

USES:
	Find the extention of a filename, or the directory specified in a full-path filename

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *input : pointer to a character array
	char delimiter : delimiter which separates "input" into "pre" and "post" portions
	int firstlast : consider only the first (1) or last (2) delimiter in "input"
	int prepost : return the portion of "input" preceding (1) or following (2) the delimiter

RETURN VALUE:
	A pointer to a new string which is no longer than the input string.

	NULL is returned if the input string is empty or the delimiter is not found
	and "prepost" is set to "2" (i.e. user requested all text following the
	delimiter).

	An exact copy of "input" is returned if the delimiter is not found and
	"prepost" is set to "1" (i.e. user requested all text preceding the
	delimiter)

SAMPLE CALL:
	char *extension = xf_strcut1( filename, '.', 2,2);
--------------------------------------------------------------------------------
</blockquote></pre>

<font color="Black"><h3 id="code-xf_strescape1"><a href="#CODE">&#8679</a> xf_strescape1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Replace literal escape sequences in a string with the appropriate ascii codes
	A slash followed by any of the following will be replaced by it's escape character:

		\\  (back-slash)
		\'  (single-quote)
		\"  (double-quote)
		\b  (back-space)
		\n  (new-line)
		\f  (form-feed)
		\t  (tab)
		\?  (question mark)

USES:
	Converting command-line arguments

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *string
		- input, pointer to a null-terminated character array

RETURN VALUE:
	A pointer to the converted string
	- always same length or shorter than original

</blockquote></pre>

<font color="Black"><h3 id="code-xf_strkey1"><a href="#CODE">&#8679</a> xf_strkey1</h3></font>
[<a href="#tag-string">string</a>][<a href="#tag-database">database</a>]<br>
<blockquote><pre>DESCRIPTION:
	- scans a NULL-terminated string for value-text which follows a user-specified key
	- stores the output to a NULL-terminated string

USES:
	Get the value associated with a keyword in a file header

DEPENDENCIES:
	None

ARGUMENTS:
	char *input    : input, null-terminated array to scan (can contain newlines)
	char *key      : input, null-terminated keyword to find, newlines ignored
	int word       : input, white-space delimited item-number (after key) to store (-1 = everything up to the newline)
	char *output   : output, the stored text

RETURN VALUE:
	- length of output, or 0 on error (key not found or word not found)
	- the output array will hold the result

SAMPLE CALL:
	- say a long header string contains a line -Resolution = 400 x 250 pixels
	- the "trigger" is "-Resolution" and the data we want is "250" (4th word)

	int data; char header[2025],output[2025];
	x= xf_strkey1(header, "-Resolution", 4, output)&#620)
	if(x&#60=0) { fprintf(stderr,"ERROR: key or word not found\n"); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_strncat1"><a href="#CODE">&#8679</a> xf_strncat1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	- safe n-character concatenation of two input strings, using a delimiter of choice
	- allocates sufficient memory for the expanded string before calling strcat

ARGUMENTS:
	char *string1   : first input string - the one to be lengthened
	char *string2   : second input string - to be added to string1, must be defined
	size_t nn       : number of bytes from string2 to append (0=all)
	char *delimiter : the delimiter to put between them, must be defined, can be ""

RETURN VALUE:
	Pointer to the lengthened string1, or NULL on failure

</blockquote></pre>

<font color="Black"><h3 id="code-xf_strstr1"><a href="#CODE">&#8679</a> xf_strstr1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Find first or last occurrence of characters ("needle") in a longer string ("haystack")

ARGUMENTS:
	char *haystack : pointer to a character array to be searched
	char *needle   : the string of characters to be found in haystack
	int setcase    : should the search be case sensitive (1) or not (0)
	int firstlast  : find the first (1) or last (2) "needle" in "haystack"

RETURN VALUE:
	Position of needle in haystack: 0= first character
	-1 if needle not found
	-2 if haystack is an empty string
	-3 if needle is an empty string
	-4 if an invalid value for "setcase" was used
	-5 if an invalid value for "firstlast" was used

Modified Feb.10 2010: removed reference to external function hux_error : direct error handling instead
Modified August 9 2011: remove text reporting, rename to xf_, add error return values
Modified May 21 2016: return long, not int

</blockquote></pre>

<font color="Black"><h3 id="code-xf_strsub1"><a href="#CODE">&#8679</a> xf_strsub1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	String substitution function
	Replaces str1 with str2 in source

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *source : pointer to the input string
	char *str1 : substring to be replaced
	char *str2 : the replacement substring - if "", str1 will simply be removed

RETURN VALUE:
	Returns a pointer to a new string of characters

SAMPLE CALL:


</blockquote></pre>

<font color="Black"><h3 id="code-xf_strtod1"><a href="#CODE">&#8679</a> xf_strtod1</h3></font>
[<a href="#tag-string">string</a>]<br>
<blockquote><pre>DESCRIPTION:
	Convert a string to a double float number
	Returns "NAN" if string is non-numeric
	Defines NAN if necessary (for Windows)

USES:
	Testing if input is numeric

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *str : input character array (eg. 123, NAN, or abc)

RETURN VALUE:
	A double-precision floating-point number

		str 	returns
		---------------
		123 	123
		NAN 	NAN
		INF 	INF
		abc 	NAN

SAMPLE CALL:

	char input[64]="123.456";
	double aa

	aa= xf_strtod1(input);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_taperhann_d"><a href="#CODE">&#8679</a> xf_taperhann_d</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION:
	Create a Hann taper window function (array)

USES:
	Tapering for use with FFT

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long setn     : size of taper window (number of elements, must be &#62=3)
	int setnorm   : normalize taper to the mean:
				0=NO (traditional, applying taper reduces amplitude by half)
				1=YES (used by LDAS, preserves amplitude)
	float setpow  : power to raise the taper
				1 is standard
				higher values increase slope
				0 sets all values to "1" - i.e. no taper
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	- pointer to taper 0 on success, NULL on error
	- char array will hold message (if any)
	- calling function must free memory for taper

SAMPLE CALL:

</blockquote></pre>

<font color="Black"><h3 id="code-xf_template"><a href="#CODE">&#8679</a> xf_template</h3></font>
[<a href="#tag-programming">programming</a>][<a href="#tag-ldas">ldas</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate negative and positive area under the curve - typically fr a time-series

USES:

DEPENDENCIES:
	None

ARGUMENTS:
	double *data : input holding data
	size_t nn : size of data array
	double interval:  the interval between samples, for integrating area
	double *result : pre-allocated array to hold results - must allow at least 6 elements
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	result array will hold statistics
	message array will hold explanatory text (if any)

SAMPLE CALL:
	x= xf_auc1_d(data, nn, interval, result, );
	if(x!=0) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

&#60TAGS&#62 programming ldas &#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_trimdigits_d"><a href="#CODE">&#8679</a> xf_trimdigits_d</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Discard "redundant" digits in a number, depending on the number of digits_to_keep
	Eg. if digits_to_keep=3:
		124596 becomes 124000
		12.456 becomes 12.4
		0.0051970 becomes 0.005
	This is useful for simplifying numerical displays
</blockquote></pre>

<font color="Black"><h3 id="code-xf_ttest2_d"><a href="#CODE">&#8679</a> xf_ttest2_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Independent 2-sample Student's t-value

USES:
	Testing statistical differences between two groups of data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data1: array holding the X-data
	double *data2: array holding the Y-data
	long n1: number of elements in data1
	long n2: number of elements in data2
	int varcalc: a flag specifying the method for calculating the variance
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large data1sets
	double *result_d: array to hold result of calculations ( t= result_d[0] )

RETURN VALUE:
	 0: success
	-1: fewer than 2 values in one or both of the input data arrays
	-2: fewer than 2 valid values in one or both of the input data arrays
	-3: memory allocation error

SAMPLE CALL:
	xf_ttest2_d(data1,data2,n1,n2,1,result_d);
	t=result_d[0];

TO DO: rather than make a temporary array, if varcalc method is "1" we can do the calculations on the fly
TO DO: to facilitate this, introduce a new (unique) variable reflects the number of valid points
TO DO: make filtering for non_finite numbers an option - could save a step

</blockquote></pre>

<font color="Black"><h3 id="code-xf_ttest3_d"><a href="#CODE">&#8679</a> xf_ttest3_d</h3></font>
[<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate the Paired 2-sample Student's t-value

USES:
	Testing statistical differences between two groups of data

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *data1: array holding the X-data
	double *data2: array holding the Y-data
	long n: number of data1/data2 pairs
	int varcalc: a flag specifying the method for calculating the variance
		1 = traditional fast computational formula
		2 = two-pass method, slower but not prone to overflow errors with very large data1sets
	double *result_d: array to hold result of calculations ( t= result_d[0] )

RETURN VALUE:
	 0: success
	-1: fewer than 2 values in one or both of the input data arrays
	-2: fewer than 2 valid values in one or both of the input data arrays
	-3: memory allocation error

SAMPLE CALL:
	xf_ttest3_d(data1,data2,n,1,result_d);
	t = result_d[0];
	df = result_d[1];
	good_data = result_d[2];
	mean_difference = result_d[3];

TO DO: rather than make a temporary array, if varcalc method is "1" we can do the calculations on the fly
TO DO: to facilitate this, introduce a new (unique) variable reflects the number of valid points
TO DO: make filtering for non_finite numbers an option - could save a step
</blockquote></pre>

<font color="Black"><h3 id="code-xf_unique_d"><a href="#CODE">&#8679</a> xf_unique_d</h3></font>
[<a href="#tag-math">math</a>][<a href="#tag-stats">stats</a>]<br>
<blockquote><pre>DESCRIPTION:
	Return an array of the unique elements in an array

USES:

DEPENDENCIES:
	None

ARGUMENTS:
	double *data  : input data array
	long *nn      : address to size of data array (pass as &nn)
	char *message : pre-allocated array to hold error message

RETURN VALUE:
	pointer to unique array on success, NULL on error
	nn will be updated
	message array will hold explanatory text (if any)

SAMPLE CALL:
	x= xf_auc1_d(data, nn, interval, result, );
	if(x!=0) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

&#60TAGS&#62 math stats &#60/TAGS&#62
</blockquote></pre>

<font color="Black"><h3 id="code-xf_velocity1"><a href="#CODE">&#8679</a> xf_velocity1</h3></font>
[<a href="#tag-math">math</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate an array of velocity values using Bob Muller's "cord" method
	- define size of window (seconds) : recommend 0.4 seconds = 10 samples at 25Hz
	- velocity is integrated across the cord joining the start & end of the window
	- one velocity estimate is generated for every position, aligned to the middle of each cord
	- the very beginning and end of the velocity array is filled with the nearest calculated velocity value
	- based on old CRUNCH function hux_posvel
	- NOTE: if there are NANs in the input, interpolation should be applied to velocity result

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *posx     : input array of x-position values (cm)
	float *posy     : input array of y-position values (cm)
	float *velocity : output array of velocity values (cm/second) - must be preallocated by calling function (nn elements)
	long nn         : total number of position samples (and velocity output values)
	double winsecs  : size (seconds) of window for velocity integration (0.4 recommended)
	double samprate : sample rate of video record (samples/second)
	char *message   : pre-allocated array to hold error message

RETURN VALUE:
	0 on success, -1 on error
	message array will describe error, if any

SAMPLE CALL:
	x= xf_velocity1(posx,posy,velocity,10000,0.4,25,message);
	if(x==-1) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavecor1_f"><a href="#CODE">&#8679</a> xf_wavecor1_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION :
	Find the mean cross-channel waveform correlation for a multi-channel waveform
	- correlation calculated for every possible pair of channels, and average is taken
	- will ignore non-finite values within a channel

USES:
	A measure of the degree to which the mena waveform for a clas of action-potentials is noise
	- that is, noise tends to be common to all channels, so the correlation between channels will be very high (&#620.99)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *wave    : array of voltage values representing a multi-channel waveform
	long nchan     : the number of channels in the compound-waveform (eg. 4 for a tetrode waveform)
	long spklen    : the number of samples from each channel: length(wave)= nchan*spklen
	char *message  : a string array to hold a status message

RETURN VALUE:
	on success: mean Pearson's r
	on failure: NAN


</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavecor2_f"><a href="#CODE">&#8679</a> xf_wavecor2_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION :
	Find the correlation of peak-values the mean multi-channel waveforms for two cells
	- this is a proxy for the similarity in the multi-channel profile for two cells (the "tetrode effect")
	- this should be more reliable than using all the samples from each channel
	- that's because there can be a lot of variability unrelated to the action potential itself
	- will ignore non-finite values within a channel

USES:
	Determine whether two cells are actually the same cell based on the similarity of their multi-channel profile

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *wave1   : array of voltage values for multi-channel waveform #1
	float *wave2   : array of voltage values for multi-channel waveform #2
	long nchan     : the number of channels in the compound-waveform (eg. 4 for a tetrode waveform)
	long spklen    : the number of samples from each channel: length(wave)= nchan*spklen
	long zero      : the within-channel sample-number representing the peak (zero-offset, must be &#60spklen)
	char *message  : a string array to hold a status message

RETURN VALUE:
	on success: Pearson's r
	on failure: NAN

</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavefilt1_f"><a href="#CODE">&#8679</a> xf_wavefilt1_f</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-filter">filter</a>]<br>
<blockquote><pre>DESCRIPTION :
	- Butterworth-filter each channel in a multi-channel waveform
	- 1. linear interpolation is used to remove NAN or INF values
		- omitted if all samples in a channel are NAN or INF
	- 2. subtract the channel-mean
	- 3. apply the bidirectional filter
	- 4. normalize each channel to the first sample in that channel

USES:
	Remove unwanted components of a waveform before calculatting peak, width etc.

DEPENDENCIES:
	xf_interp3_f
	xf_filter_bworth1_f

ARGUMENTS:
	float *wave    : array of voltage values representing a multi-channel spike waveform
	int nchan      : the number of channels (eg. 4 for a tetrode waveform)
	int spklen     : samples comprising the spike on each channel
	float setrate  : the sample-rate of the input
	float setlow   : the low-frequency cutoff (0= no low-cut filtering)
	float setlow   : the high-frequency cutoff (0= no high-cut filtering)
	char *message  : pre-allocated array to hold feedback

RETURN VALUE:
	0 if no problems, -1 if there was an error (no valid data)

	*wave will contain the within-channel filtered data

</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavepeak1_f"><a href="#CODE">&#8679</a> xf_wavepeak1_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION :
	John Huxter: 16 June 2017

	Finds the channel containing the peak, and the value of it,
	in a multi-channel waveform

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:

	float *wave    : array of voltage values representing a spike waveform
	int wavelen    : samples in waveform
	int nchan      : if a compound waveform, the number of channels (eg. 4 for a tetrode waveform)
	int sign       : determines if peak should be negative (-1) or positive (+1)
	float *resultf : an array [2] to hold the results


RETURN VALUE:
	the channel containing the peak, or -1 on error

	resultf[0] = the peak value (negative or positive, depending on sign)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavepeak2_f"><a href="#CODE">&#8679</a> xf_wavepeak2_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION :
	For a multi-channel waveform file, find:
	 	1. The peak channel
			- depending on sign, this is the channel with the smallest or largest value at time zero
		2. The minimum and maximum value at peak-time
			- compares values across channels at time zero
		3. The min/max ratio
			- similarity between min and max, corrected for whether the values are &#60 or &#62 zero

	NOTE: unlike xf_wavepeak1, this function assumes the peak is near a known position in the waveform
	NOTE: recommend use of xf_wavefilt1_f to filter the waveforms before detecting the peak

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	float *wave    : array of voltage values representing a multi-channel waveform
	long nchan     : the number of channels in the compound-waveform (eg. 4 for a tetrode waveform)
	long spklen    : the number of samples from each channel: length(wave)= nchan*spklen
	long setzero   : the sample-number within each channel corresponding to time-zero (the detected peak)
	int sign       : whether the original spike-detection was for negative (-1) or positive (1) events
	float *resultf : an array to hold the output
	char *message  : a string array to hold a status message

RETURN VALUE:
	- on success: the channel containing the peak (negative or positive, depending on "sign")
	- on failure: -1

	- resultf[0]: at time zero, smallest (sign=-1) or largest (sign=1) value
	- resultf[1]: cross-channel minimum value at time zero (peak)
	- resultf[2]: cross-channel maximum value at time zero (peak)
	- resultf[3]: the difference between the minimum and maximum
	- resultf[4]: the adjusted min:max ratio (0-1)
		- the ratio of the smallest deflection from zero relative to the largest
		- values approaching 1 indicate indentical signals on all channels
		- values approaching -1 are increasingly different, -1 being the maximum difference for values on opposite sides of zero
</blockquote></pre>

<font color="Black"><h3 id="code-xf_wavewidth3_f"><a href="#CODE">&#8679</a> xf_wavewidth3_f</h3></font>
[<a href="#tag-stats">stats</a>][<a href="#tag-signal_processing">signal_processing</a>]<br>
<blockquote><pre>DESCRIPTION :
	Find the width of the peak (at a % of the peak amplitude) on one channel of a multi-channel waveform
	- needs to know the peakchan (use xf_wavepeak2_f for example)
	- scans within that channel for the minimum or maximum, depending on sign
	- NOTE: this function scans the waveform for the peak - it does not take a "time-zero" argument"
	- NOTE: input should be interpolated and filtered (no NAN or INF values)
		- xf_wavefilt1_f() can be used to interpolate and filter
		- note that if a channel is dead (all NANs), interpolation will not fix the problem
		- in this case, that channel should not be passed to this function!
	- NOTE: the value for setwidth would be 0.25 according to Csicsvari et al, 1999
		- however, the the halfwidth (0.5) may be more reliable, because depending on filtering, some waveforms never return to 25%
USES:

DEPENDENCIES:
	None

ARGUMENTS:
	float *wave     : array of voltage values representing a multi-channel spike waveform
	int nchan       : the number of channels (eg. 4 for a tetrode waveform)
	int spklen      : samples in each channel (individual spike waveforms)
	int peakchan    : the channel containing the peak
	int sign        : determines if detected peak should be negative (-1) or positive (+1)
	double setthres : the proportion of peak-amplitude at which to calculate the width (eg. 0.5 = 50%, i.e. half-width)
	float *resultf  : an array [3] to hold the results
	char *message   : pre-allocated array to hold error message

RETURN VALUE:
	0 if no problems, -1 if there was an error (no valid data)

	resultf[0] = width at (setwidth*100)% of the peak value
	resultf[1] = the peak value (negative or positive, depending on sign)
	resultf[2] = setwidth x peak_value (where the width is calculated)
</blockquote></pre>

<font color="Black"><h3 id="code-xf_window1_l"><a href="#CODE">&#8679</a> xf_window1_l</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Fill an array with start-indices for a series of equally-spaced or equal-sized windows
	Assumes data is zero-offset (i.e. the first window will always start at index zero)
	[JRH, 18 March 2013]

USES:
	defining windows for stepwise analysis of data
	eg. defining windows for short-time FFT

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long n: the total number of elements in the data to be windowed
	long winsize: the desired size of the windows (number of elements)
	int equalsize: 	a flag specifying whether all windows should be exactly the same size
			set to 0 to preserve equal-spacing
			set to 1 to ensure all windows are the same size
				- i.e. if the last window has &#60 winsize elements, the start-index is adjusted backwards
				- adjustment only happens if n is not an exact multiple of nwin
	*nwin: the total number of windows detected (size of the window-index array which is returned)
		this value will be adjusted by the function
			- if nwin is -1 upon return, this indicates a memory allocation error
			- if nwin is 0 upon return, this indicates insufficient data for even a single window

RETURN VALUE:
	A pointer to an array of type long integer which indicates the start-index of each window

SAMPLE PROGRAM: define windows for a dataset of 10 elements, where each window should be 3 elemnts long:

	#include &#60stdio.h&#62
	#include &#60stdlib.h&#62

	long i,nwin,n=10,winsize=3,*windex=NULL;
	windex=xf_window1_l(n,winsize,&nwin,1);
	for(i=0;i&#60nwin;i++) printf("%ld\n",windex[i]);
	free(windex);

	//output looks like this... note last window starts at 7, preserving nwin size of 3 for the last window
	//	0
	//	3
	//	6
	//	7


</blockquote></pre>

<font color="Black"><h3 id="code-xf_wint1"><a href="#CODE">&#8679</a> xf_wint1</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate interval between two classes of events in a sliding event-centred window

USES:
	Typically used as the first step to generate auto- and cross-corellograms for
	neuronal spike-trains. Typically used in conjuction with function xf_hist1

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	double *tsec : array already holding timestamps (seconds) for each event
	int *group : array already holding event ids (eg. cell-numbers)
	long n : number of elements in the arrays
	int g1 : the id for the reference event
	int g2 : the id for the event the timing of which is to be compared with g1
	float winsize : the size of the window centred on each event, within which to find intervals
	long *result_l : results array - result_l[0] will holds the number of intervals found

RETURN VALUE:
	A pointer to an array of type double with result_i[0] elements
	This variable must be initialized by the calling function and assigned value NULL
	Te function will handle assigning sufficient memory

SAMPLE CALL:
	int g1=1, g2=2;
	long result_i[32];
	float winsize=0.01;
	double time[1001],group[1001],*intervals=NULL;
	// time and group data must be stored in memory first
	// now find the intervals between events of class g1 and g2
	intervals=xf_wint1(time,group,n,g1,g2,winsize,result_l);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_wint1_ls"><a href="#CODE">&#8679</a> xf_wint1_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate interval between two classes of events in a sliding event-centred window
	The function will handle assigning sufficient memory
	NOTE: function assumes time values are in ascending order

USES:
	Typically used as the first step to generate auto- and cross-corellograms for
	neuronal spike-trains.

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *time : array already holding timestamps for each event
	long *group : array already holding event ids (eg. cell-numbers)
	long nn : number of elements in the arrays
	long g1 : the id for the reference event
	long g2 : the id for the event the timing of which is to be compared with g1
	long winsize     : the size of the window centred on each event, within which to find intervals
	long *nintervals : results, number of intervals detected (pass to function as address)

RETURN VALUE:
	Success:
		A pointer to an array of interval values with nintervals elements
		Value for nintervals will be overwritten
		NOTE: pointer will be NULL if nintervals=0 (non-match of group to g1 and g2)
	Failure:
		NULL, with nintervals set to -1 (if memory allocation fails)

SAMPLE CALL:
	long time[1001], group[1001], g1=1, g2=2, winsize=150, nintervals=0, *intervals=NULL;;
	// time and group data must be stored in memory first
	intervals= xf_wint1_l(time,group,n,g1,g2,winsize,&nintervals);
	if(nintervals==-1) { fprintf(stderr,"\n--- Error [%s/xf_wint1_l]: memory allocation error\n\n",thisprog);exit(1);}
	else if(nintervals==0) { fprintf(stderr,"--- Warning [%s]: no intervals for groups %d vs. %d\n",thisprog,g1,g2); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_wint2_di"><a href="#CODE">&#8679</a> xf_wint2_di</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:

	Calculate interval between two classes of events in a list of predefined time windows
	Time windows must be non-overlapping
	Returns pointer to array holding a list of intervals
	NOTE!! Both events and windows must be time-ordered

ARGUMENTS (9 TOTAL):
	time: array holding the time of the events
	group: array holding the class of the events
	n: the total number of events
	g1: the class of event providing the reference times
	g2: the class of event whose times, relative to g1, are used to build the interval list
	wint1, wint2: arrays holding matching start & end times for each window
	nw: the number of windows
	result_l: result array to hold the nintsal number of elements in *intervals

SAMPLE CALL:
	int g1=1, g2=2, nevents=1000,nwin=64, result_i[32];
	double time[1001],group[1001],winstarts[65],winends[65],*intervals=NULL;

	intervals=hux_wint(time,group,nevents,g1,g2,wstarts,winends,nwin,result_l)

EXAMPLE USE:
	to obtain the values for a spike cross-correlation histogram, for a pair of cells,
	looking only in discrete time windows corresponding to theta cycles, sleep periods, running, etc
</blockquote></pre>

<font color="Black"><h3 id="code-xf_wint3_ls"><a href="#CODE">&#8679</a> xf_wint3_ls</h3></font>
[<a href="#tag-signal_processing">signal_processing</a>][<a href="#tag-stats">stats</a>][<a href="#tag-time">time</a>]<br>
<blockquote><pre>DESCRIPTION:
	Calculate interval between either of two classes of events in a sliding event-centred window
	The function will handle assigning sufficient memory
	NOTE: function assumes time values are in ascending order

USES:
	Determine the effect on the autocorrelogram if two classes of events were combined

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	long *time : array already holding timestamps for each event
	long *group : array already holding event ids (eg. cell-numbers)
	long nn : number of elements in the arrays
	long g1 : the id for the reference event1
	long g2 : the id for the reference event2
	long winsize     : the size of the window centred on each event, within which to find intervals
	long *nintervals : results, number of intervals detected (pass to function as address)

RETURN VALUE:
	Success:
		A pointer to an array of interval values with nintervals elements
		Value for nintervals will be overwritten
		NOTE: pointer will be NULL if nintervals=0 (non-match of group to g1 and g2)
	Failure:
		NULL, with nintervals set to -1 (if memory allocation fails)

SAMPLE CALL:
	long time[1001], group[1001], g1=1, g2=2, winsize=150, nintervals=0, *intervals=NULL;;
	// time and group data must be stored in memory first
	intervals= xf_wint2_ls(time,group,n,g1,g2,winsize,&nintervals);
	if(nintervals==-1) { fprintf(stderr,"\n--- Error [%s/xf_wint1_l]: memory allocation error\n\n",thisprog);exit(1);}
	else if(nintervals==0) { fprintf(stderr,"--- Warning [%s]: no intervals for groups %d vs. %d\n",thisprog,g1,g2); }

</blockquote></pre>

<font color="Black"><h3 id="code-xf_writebin1_v"><a href="#CODE">&#8679</a> xf_writebin1_v</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Write a simple binary stream from memory to file, regardless of the data format
	This version accepts a pointer to the output stream - suitable for multiple calls to write

USES:
	Simple binary file writing

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpout     : pointer to output stream
	void *data0     : pointer to array holding data, cast as (void *) by the calling function
	size_t nn       : number of elements in data0
	size_t datasize : byte-size of data0, as defined by the calling function, usually using sizeof())
	char *message   : an array to hold diagnostic messages on return

RETURN VALUE:
	0 on success, -1 on error

SAMPLE CALL:
		i= xf_writebin1_v(stdout,(void *)data1,nn,sizeof(float),message);
		if(i!=0) { fprintf(stderr,"\b\n\t*** %s\n\n",message); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_writebin2_v"><a href="#CODE">&#8679</a> xf_writebin2_v</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Write a simple binary stream from memory to file
	This version handles file-opening and closing, and can handle any data type

USES:
	Simple binary file writing

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	outfile         : output file name or "stdout"
	void *data0     : pointer to array holding data, cast as (void *) by the calling function
	size_t nn       : number of elements in data0
	size_t datasize : byte-size of data0, as defined by the calling function, usually using sizeof())
	char *message   : an array to hold diagnostic messages on return

RETURN VALUE:
	0 on success, -1 on error

SAMPLE CALL:
		i= xf_writebin2_v("stdout",(void *)data1,nn,sizeof(float),message);
		if(i!=0) { fprintf(stderr,"\b\n\t*** %s\n\n",message); exit(1); }
</blockquote></pre>

<font color="Black"><h3 id="code-xf_writebinx1"><a href="#CODE">&#8679</a> xf_writebinx1</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	Create BINX format binary output from an array in memory
	BINX format:
		1. 500-byte header in 3 parts - the header is generated only once
			a. Filetype
			b. Parameters
			c. Text description
		2. The data, all of one type

	Calling function defines the data-size, data-type, and number of elements (depth) in up to 3 dimensions

USES:

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	FILE *fpin : pointer to output stream/file
	void *data : pointer to the array of numbers
	size_t *params : the file parameters
		params[0] : headersize, filled by this function on first call. NOTE: calling function should initialize to 0 on first call to indicate to THIS function that the header still needs to be written
		params[1] : data-size - i.e. the number of bytes in each datum (1,2,4 or 8)
		params[2] : data-type (0-9 = uchar,char,ushort,short,uint,int,ulong,long,float,double)
		params[3] : depth of dimension-1 - if data is 1d, this is also the total data-points
		params[4] : depth of dimension-2
		params[5] : depth of dimension-3
	size_t ntowrite : number of data to write. NOTE: may be diffrerent from total data in file as indicated in header, if function is called multiple times to add data
	char *message : an array to hold diagnostic messages on return

RETURN VALUE:
	data-points written, or 0 on error

SAMPLE CALL:
--------------------------------------------------------------------------------
	Suppose we have an array of short integers acquired by sampling 16 recording
	channels 1000 times. Acquisition systems will typically interlace the data
	from each channel, and the total samples will number 16,000.

	In this instance the data shouldbe treated as 2-dimensional, with a depth of
	16 in dimension-0, and a depth of 1000 in dimension-1

	char outfile[256];
	char message[256];
	size_t params[6],z;

	sprintf(outfile,"stdout");
	fpout=fopen(infile,"wb");

	dsize=sizeof(short);
	params[1]=2; 	# 2-bytes per datum
	params[2]=3; 	# datatype short
	params[3]=16;	# 1st dimension (channel) is 16 elements deep
	params[4]=1000;	# 2nd dimension (sample-number) is 1000 elements deep
	params[5]=0;	# 3rd dimension undefined

	nn = xf_writebinx1(fpout,data,params,message);

	fclose(fpout);
 		sprintf(describe,"\nBYTES:   TYPE   DESCRIPTION\n");
		ii=1;
		kk=sizeof(size_t);
		jj=ii+(hsize1-1); sprintf(describe,"%s%03ld-%03ld: (char) file type\n",describe,ii,jj); ii+=hsize1;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) header length\n",describe,ii,jj); ii+=kk;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) bytes in each datum (1|2|4|8)\n",describe,ii,jj); ii+=kk;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) data type (0-9 = uchar,char,ushort,short,uint,int,usize_t,size_t,float,double)\n",describe,ii,jj); ii+=kk;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) depth, dim1\n",describe,ii,jj); ii+=kk;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) depth, dim2\n",describe,ii,jj); ii+=kk;
		jj=ii+(kk-1); sprintf(describe,"%s%03ld-%03ld: (size_t) depth, dim3\n",describe,ii,jj); ii+=kk;
		sprintf(describe,"%s%03ld-%03d: (char) this file description\n",describe,ii,BINX_HEADERSIZE);
</blockquote></pre>

<font color="Black"><h3 id="code-xf_writewave1_f"><a href="#CODE">&#8679</a> xf_writewave1_f</h3></font>
[<a href="#tag-file">file</a>]<br>
<blockquote><pre>DESCRIPTION:
	- Write .wfm files (multi-channel spike waveform means for clustered wmean)

DEPENDENCY TREE:
	No dependencies

ARGUMENTS:
	char *outfile : name of .wfm file to write
	short *id     : pointer to array for cluster-ids for each waveform
	long *wn      : pointer to array for spike-counts for each waveform
	float *wmean  : pointer to array for actual waveforms
	short *wchans : pointer to array for order of channels in waveform
	long *params  : array holding additional statistics related to the wmean
	long makez    : if &#620, make a "NAN" line specifying &#60makez&#62 spikes in cluster zero
	double srate  : sample rate of input
	char *message : output, a string array to hold the status message

RETURN VALUE:
	on success: the sample-rate (Hz) as read from the header
	on failure: -1

SAMPLE CALL:
	z= xf_writewave1_f(filename,&cluid,&wn,&wmean,&wchans,params,19531.25,0,message);
	if(z&#600) { fprintf(stderr,"\b\n\t*** %s/%s\n\n",thisprog,message); exit(1); }
</blockquote></pre>
</font>
</body>
</html>
